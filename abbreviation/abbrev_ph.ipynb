{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17123/17123 [00:00<00:00, 22427.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from modules import read_from_allfiles\n",
    "import re\n",
    "\n",
    "docs = read_from_allfiles.doc_from_allfiles()\n",
    "alltexts = ''.join(docs)\n",
    "abbs = []\n",
    "matches = re.finditer(r'\\(([a-zA-Z\\u0391-\\u03c9][a-zA-Z\\d\\-–\\/\\u2215]+)\\)', alltexts) #greek = re.compile(r'[\\u0391-\\u03c9]') # ギリシャ文字\n",
    "# matches = re.finditer(r'\\(([a-zA-Z\\u0391-\\u03c9][^\\s\\^\\{\\}\\.\\,\\;\\:\\(\\)\\[\\]]+?)s?\\)', alltexts)\n",
    "for match in matches:\n",
    "    if not re.match(r'[a-z]+', match.group(1)):\n",
    "        abbs.append(match.group(1))\n",
    "\n",
    "abb_list = list(set(abbs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/anaconda3/lib/python3.7/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      " 97%|█████████▋| 97/100 [09:58<00:21,  7.31s/it]"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "### df_aip2018, df_jap2005, df_aps2018 are obtained from MySQL server\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm as tqdm\n",
    "from gensim.models.phrases import Phrases , Phraser\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import pickle\n",
    "\n",
    "\n",
    "### wordを含む文を抽出\n",
    "def ext_text_with_unit(word, doc):\n",
    "    # word serach\n",
    "    wsearch = re.compile(fr'[\\002d\\s](\\({word}s?\\))[\\W]')\n",
    "\n",
    "    ext_texts = []\n",
    "    matches = re.finditer(wsearch, doc)\n",
    "    if re.search(wsearch, doc):\n",
    "        for m in matches:\n",
    "            wis = m.start(1)\n",
    "            wie = m.end(1)\n",
    "            i = wis\n",
    "            dis = wis\n",
    "            while i > 0:\n",
    "                if doc[i:i+1]=='.':\n",
    "                    dis = i+1\n",
    "                    break\n",
    "                i -= 1\n",
    "            j = wie\n",
    "            die = wie\n",
    "            while j < len(doc):\n",
    "                if doc[j:j+1]=='.':\n",
    "                    die = j\n",
    "                    break\n",
    "                j += 1\n",
    "            ext_texts.append(doc[dis:die])\n",
    "                   \n",
    "    return ext_texts\n",
    "\n",
    "\n",
    "## text処理 for phrases\n",
    "def pre_pro_text(text):\n",
    "    \n",
    "    phrases = [] # gensim.phrases用\n",
    "    \n",
    "    re_blacs = re.compile(r'([\\(\\[“].+?[\\)\\]”])') # (phrase), [phrase]\n",
    "    re_blac = re.compile(r'([\\(\\[“][^\\s]+[\\)\\]”])') # (word), (“word”), [word] no spaces available inside blackets\n",
    "    re_spases = re.compile(r'([\\.\\,\\;\\:]\\s)') # . , ; : \n",
    "\n",
    "    # (word word) のカッコ内側にスペースを入れる (word)は除く\n",
    "    blacs = re.finditer(re_blacs, text)\n",
    "    for bl in blacs:        \n",
    "        if not re.match(re_blac, bl.group(0)):  \n",
    "            bs = bl.group(0).replace('(', '( ').replace(')', ' )').replace('[', '[ ').replace(']', ' ]')\n",
    "            text = text.replace(bl.group(0), bs)  \n",
    "\n",
    "    # [.,;:] + スペースの前にスペースを入れる（分割用）\n",
    "    text = text.replace('. ', ' . ').replace(', ', ' , ').replace(': ', ' : ').replace('; ', ' ; ').replace('.\\n', ' .\\n')\n",
    "    text = text.replace('.] ', ' . ] ').replace(',] ', ' , ] ').replace(':] ', ' : ] ').replace(';] ', ' ; ] ')\n",
    "    text = text.replace('.\\n', ' .\\n').replace(',\\n', ' ,\\n').replace(':\\n', ' :\\n').replace(';\\n', ' ;\\n')\n",
    "\n",
    "    # Phrases用コーパス        \n",
    "    text = re.sub(r'\\[[\\d\\,\\-–\\s]+\\]', '', text) # []文献番号削除　[111]とかも消えるが多分問題ない？\n",
    "    text = re.sub(r'\\s[\\.\\,\\;\\:]\\s', '\\n', text) # スペース + [.,;:] + スペースで改行を入れる 記号をまたいだ複合語を作成しないため\n",
    "    text = re.sub(r'\\. \\n', '\\n', text) # \n",
    "    tlist = re.split(r'\\n', text)\n",
    "    for l in tlist:\n",
    "        l = re.split(r'\\s', l)\n",
    "        if len(l) > 1:\n",
    "            phrases.append(list(filter(lambda x: x != '', l)))\n",
    "\n",
    "    return (phrases)\n",
    "\n",
    "# bigram, trigram, quadtgram学習\n",
    "def train_phrases(text_lists):\n",
    "    mn = 1 # usually 5 \n",
    "    th = 3\n",
    "\n",
    "    bigram = Phrases(text_lists, min_count=mn, threshold=th)\n",
    "    trigram = Phrases(bigram[text_lists], min_count=mn, threshold=th)\n",
    "    quadgram = Phrases(trigram[bigram[text_lists]], min_count=mn, threshold=th)\n",
    "\n",
    "    bigram_ = Phraser(bigram)\n",
    "    trigram_ = Phraser(trigram)\n",
    "    quadgram_ = Phraser(quadgram)\n",
    "    \n",
    "    return (bigram_, trigram_, quadgram_)\n",
    "\n",
    "\n",
    "# bigram, trigram, quadtgram変換\n",
    "def ext_phrases(train_data, texts):\n",
    "    (bigram_, trigram_, quadgram_) = train_data\n",
    "    bi_texts = bigram_[texts]\n",
    "    tr_texts = trigram_[bi_texts]\n",
    "    qd_texts = quadgram_[tr_texts]\n",
    "    \n",
    "    return qd_texts\n",
    "\n",
    "\n",
    "ph_dic = {}\n",
    "words = abb_list[0:100]\n",
    "\n",
    "for word in tqdm(words):\n",
    "    try:\n",
    "        ext_texts = ext_text_with_unit(word, alltexts)\n",
    "        ex_phrases = pre_pro_text(''.join(ext_texts))\n",
    "        train_data = train_phrases(ex_phrases)\n",
    "        phrases = ext_phrases(train_data, ex_phrases)\n",
    "        all_phrases = list(chain.from_iterable(phrases))\n",
    "        ex_phrases =  set([p for p in all_phrases if re.search(fr'_\\({word}s?\\)', p)])\n",
    "        ph_dic[word] = ex_phrases\n",
    "    except:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
