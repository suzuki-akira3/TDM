Reconstructing latent dynamical noise for better forecasting observables
I propose a method for reconstructing multi-dimensional dynamical noise inspired by the embedding theorem of Muldoon et_al [Dyn. Stab. Syst. 13, 175 (1998)] by regarding multiple predictions as different observables. Then, applying the embedding theorem by Stark et_al [J. Nonlinear Sci. 13, 519 (2003)] for a forced system, I produce time series forecast by supplying the reconstructed past dynamical noise as auxiliary information. I demonstrate the proposed method on toy models driven by auto-regressive models or independent Gaussian noise.
I. INTRODUCTION
A typical problem in time series analysis is to forecast the future values of observable given its past series. When we restrict ourselves to a deterministic system, the embedding theorems by Takens [8] and Sauer et_al [9] ensure that, generally, one can reconstruct the states for the underlying dynamics from these restricted observations by delay coordinates, and thus one can forecast its future based on the reconstructed states. When a system is a linear stochastic system, one may use the auto-regressive linear model [7] to forecast the future values for the observable. Thus, a remaining problem is how to forecast the future values when a time series is generated from a nonlinear stochastic system. Namely, my goal is to reconstruct the underlying states as well as past dynamical noise realizations based on the limited observations for forecasting the future observable values more accurately. Therefore, I do not intend to predict the current dynamical noise itself. I rather try to estimate the previous dynamical noise so that I can improve time series forecasts for the future observables.
A nonlinear stochastic system might be modelled, in general, as a nonlinear system on an m-dimensional manifold with parameters generated according to a stochastic process. As far as I have noticed, there exist two embedding theorems that can be used under such a circumstance: One of the embedding theorems is by Muldoon et_al [1], within which one can consider more than 2m-dimensional observations at two separated times to reconstruct the n-dimensional dynamical noise and m-dimensional state; the other one is by Stark et_al [2], within which one can forecast the future values of the observable given the past series of observable and the reconstructed dynamical noise. But, suppose here that we can observe a scalar time series only, and thus we cannot have access to (2m + 1)-dimensional observations directly. Under such a circumstance, I propose to create such observations by using (2m + 1) or more different time series predictions, which we call prediction coordinates. This point is the key for the rest of the story.
II. BACKGROUND
I start this paper by describing my setup. Let f:M×N→M be a dynamical system, on the m-dimensional manifold M, depending on a parameter on the n-dimensional manifold N. Letting p(t)∈N be realization of a parameter at time t, we have z(t + 1) = f(z(t),p(t + 1)). Let g:M→R be an observation function for the dynamical system. We denote the observation at time t by x(t) = g(z(t)). For convenience, I use z(t + 1) = f_{p}_{(}_{t}_{+ 1)}(z(t)) and z(t+b)=f_{p(t+b)p(t+b−1)⋯p(t+1)}(z(t))=f_{p(t+b)}(f_{p(t+b−1)}(⋯(f_{p(t+1)}(z(t)))⋯)). Then, delay coordinates here can be written by
Under mild technical conditions, it is a generic property that Φ_{f,g} is embedding [2]. This theorem means that one can reproduce z(t) by observing the sequence of observables if the noise realization of {p(t)} is given. Because we assume that f(z, p) is a diffeomorphism in terms of z when p is fixed, z(t) has one-to-one correspondence with z(t+d) given {p(t)}. Thus, in the later part, we describe delay coordinates backward. Therefore, if one can identify dynamical noise {p(t)}, one can better forecast the future values of the observable based on its past values.
Thus, to use this theorem, it is important to reconstruct a series of dynamical noise {p(t)}. For this purpose, I use the following theorem by Muldoon et_al [1] Let v:M→R^{d} be another “high-dimensional” observation of z(t). I also assume that f(·,p) is a diffeomorphism for each p∈N and f(z,·) be an embedding for each z∈M. Then, it is generic that
is an embedding [1]. Furthermore, if we fix any z∈M and consider a generic projection π:R^{2d}→R^{d}, then π(Θ(z,·)):N→R^{d} becomes an embedding.
The problem here is how to construct the function v. My solution is to employ multiple predictions. In this context, I found that there is a paper which reconstructs a one-dimensional driving force by taking a difference between a one-step prediction and the truth [10]. My difference with this existing literature is that I use multiple predictions so that I can accommodate multi-dimensional dynamical noise.
III. METHOD
Here is a recipe of the proposed method. See Fig. 1 for the zoomed picture of the proposed method. We assume that we observe a scalar value x(t) sequentially. Let T be the length of time series and q be the maximum forecast steps for the resulting final forecasts. Then, the following calculation is conducted at each time t, which increases monotonically along the time. First, we prepare a set of one-step time series predictions x̂{i}(t) using infinite-dimensional delay coordinates (InDDeCs) [13]. By the analogy of Ref [12], this InDDeCs also reconstructs state variables as well as values for the parameter, simultaneously [14]. The InDDeCs can be defined as
where I inserted x(s) = 0 when s≤0. The distance between time points s→{i}(t_{1}) and s→{i}(t_{2}), in the L_{1}-norm, can be written as
In this paper, I use various decaying factors λ_{i}=i/(I+1)∈(0,1) for i=1,2,…,I. Based on the definition, the distance d(s→{i}(t_{1}+1),s→{i}(t_{2}+1)) for a step ahead can be written as
Thus, we can use this formula for calculating distances by recycling the previous distances. I also use a method of analogue [15] based on the information up to time t to generate prediction coordinates. (When the algorithm is started, I set d(s→{i}(τ),s→{i}(0))=0 for −T/4≤τ<0.) Namely, we look up K = 10 nearest neighbors, if not mentioned, and average their time successors to predict the future values of observable x(t). If I use a mathematical expression, the prediction can be written as
where J_{K}(t) represents a set of time indices for K nearest neighbors between time period of [t−T/4,t−1] in the above L_{1} norm of the InDDeCs with the decaying factor λ_{i}. Such distance sequences can be stored as
and updated as
for u=1,2,…,T/4. Second, we array each one-step prediction {x̂{i}(t)} for time t and {x̂{i}(t+1)} for time t + 1 to form a 2I-dimensional prediction coordinates y→(t) of
By Casdagli [16] and Hegger et_al [12], the delay coordinates with a large embedding dimension can hold the information of states as well as dynamical noise. Together with the embedding theorem by Whiteney [17] or Muldoon et_al [1], it is natural to consider that y→(t) contains the information of the underlying state as well as the recent sequence of dynamical noise {p(τ)|τ≤t}. Third, we combine the reconstructed dynamical noise described by the 2I-dimensional prediction coordinates y→(t) with delay coordinates v→(t)=(x(t−d+1),x(t−d+2),…,x(t)) of the actual observations {x(s)|s=t,t−1,…,t−d+1} to form combined coordinates of W(t)={v→(t),1ay→(t)} inspired by Stark et_al [2] so that W(t), in general, uniquely identifies z(t– d + 1) given the history of {p(t−s)|s=0,1,…,d−2}. Here, a is a constant for the reconstructed dynamical noise. I use I = 19 and a = 2I if not mentioned. I choose the parameter a in this way so that the effect of dynamical noise is in the same order as one of delay coordinates. If there is serial dependence among {p(t)}, W(t) would help us to forecast the future values of observable x(t) better. Even if there is no serial dependence on {p(t)}, estimating the past parts of {p(t)} would help us to forecast the future values of the observable better as I will discuss later. Thus, last as the fourth step, we use a series of W(t) to forecast the future values of x(t + s), where s > 0 by a method of analogue using L = 10 nearest neighbors. Namely, a final s steps ahead forecast x̂(t+s|t) for s = 1, 2,…,q at time t is given by
where J_{L}(t) denotes a set of nearest neighbors chosen in the L_{1}-norm between the time period of [T/4, t – q] in combined coordinates W(t) for time t. Notice that in the first step, I use the term predict, while in the fourth step, I use the term forecast. Throughout the paper, I am distinguishing these two terms consistently.
Previously, a similar framework has been used by Monroig et_al [11] to estimate the states. A big difference between their work and the current work is that I prepare a set of predictions to obtain a coordinate system described by y→(t), which eventually encodes the information of time varying parameter p(t). Thus, I regard different predictions as forming different coordinates to obtain the 2I-dimensional vector.
Because we are using the embedding theorem by Stark et_al [2] we should also have d≥2m+1.
IV. EXAMPLES
Let us look at some numerical examples. I first consider the following Hénon map [3] driven by a source of dynamical noise p_{0}(t) which is now generated by the auto-regressive linear model [7]:
where η_{0}(t) follows the Gaussian distribution with the mean 0 and the standard deviation 1. In addition, I set σ_{1} = 0.07 if not mentioned. I generated a time series of length 10 000 by observing z_{1}(t). For each time, I started to use the first quarter of time points as an initial database to issue predictions for the later three quarters, construct prediction coordinates, and thus reconstruct the past dynamical noise. When I look at the values of prediction coordinates subtracted by the corresponding actual values, they were correlated with the original dynamical noise (see Fig. 2). In the hundred examples tested, the means for the means and the standard deviations for the correlation coefficients between the original dynamical noise and its 19 elements of y_{i}(t) – z_{1}(t) for i=1,2,…,19 were –0.3688 ± 0.1097, which is significantly different from 0 (P < 0.001). Thus, when I used the prediction coordinates combined with delay coordinates and forecast the future values for the observable in the second half of the time series, the time series forecasts tended to show the smaller forecast errors than the case where I only used the delay coordinates for forecasting the future values for the observable [see Figs. 3(a) and 3(b)]. For example, when I compare the forecast time series with the original as shown in Fig. 4, the local minima exhibited at the 8983th, 8987th, and 8993th points look much closer to the truth in the proposed method than in the three-dimensional delay coordinates, which correspond to an over-embedding [12] in the best time interval [Fig. 4(a)], while in the worst time interval, there was not much difference between the proposed method and the over-embedding [Fig. 4(b)].
My second example is the Ikeda map [4] driven by an auto-regressive linear process
where
and
I observed z_{1} to generate scalar time series.
When I used a one-step time series prediction by the InDDeCs, I could reconstruct the dynamical noise as shown in Fig. 5. The means for the means and the standard deviations between the absolute values for the correlation coefficients between the actual dynamical noise and its reconstruction y_{i}(t) – z_{1}(t) for i=1,2,…,19 were –0.0707 ± 0.0140, which is also significantly different from 0 (P < 0.001). But, the difference between the actual value and its one-step forecast could not be a good index for evaluating the accuracy for the reconstruction of dynamical noise because the reconstruction might be valid only locally, and thus may not have good correlation with the actual values globally.
When I forecast the future values in the second half of the time series, I could see some improvements by the proposed method compared with the three-dimensional delay coordinates [Figs. 6(a) and 6(b)]. When I looked at the best example of one step forecasts, the proposed forecasts have been improved, especially at the 9816th, the 9832th, and the 9837th points [Fig. 7(a)], while in the worst example, there was not much difference between the proposed method and the over-embedding [Fig. 7(b)]. Therefore, the results seem to be consistent with the first case of the Hénon map. Hence, our reconstruction for past dynamical noise could be valid locally sufficiently to improve time series forecasts.
My third example is the following Ikeda map [4] driven by two sources of dynamical noise:
where
and
where η_{1}(t) and η_{2}(t) follow the Gaussian distribution with the mean 0 and the standard deviation 1. I observe z_{1}(t) to forecast its future values.
The results are presented in Figs. 8(a) and 8(b). As similar to the first and second examples, the forecasts have been improved for the short-term forecasts.
My fourth example is the Rössler model driven by an auto-regressive linear model
and
where η_{3}(t) follows the Gaussian distribution with mean 0 and standard deviation 1. In addition, I set Δt = 0.01 and sample z_{1}(tΔt) every 0.2 unit time to generate scalar time series. Furthermore, I set σ_{2} = 0.03 initially.
The results are shown in Figs. 9(a) and 9(b). In the Rössler model as well, the forecast errors tend to be smaller for one step ahead forecasts in the proposed method than those obtained in the four-dimensional delay coordinates, which should also be regarded as an over-embedding [12] case. For this example, it seems that longer step forecasts are not so skillful for the proposed method compared with the over-embedding.
My fifth example is the Lorenz model driven by, also, an auto-regressive linear model
and
Here, η_{4}(t) follows the Gaussian distribution with mean 0 and standard deviation 1. Moreover, I set Δt = 0.01 and sample z_{1}(tΔt) every 0.05 unit time for obtaining scalar time series.
The results are shown in Figs. 10(a) and 10(b). I can see the tendency that the forecast errors by the proposed method tend to be smaller than those by the four-dimensional delay coordinates in this example of the Lorenz model as well. Since the difference did not start converging at 10 steps ahead, we probably could forecast further steps more accurately with the proposed method.
My results did not change match even when I replaced the auto-regressive models of {p_{i}(t)} for i = 0,1,2,3,4 with independent Gaussian noise of mean 0 and standard deviation 1 as shown in panels (c) and (d) of Figs. 6 and 8–10 except for the Hénon map example [see Figs. 3(c) and 3(d)]. Even when {p_{i}(t)} for i = 1, 2, 3, 4 are the independent Gaussian noise, I can still improve the forecast errors in the examples of the Ikeda map, the Rössler model, and the Lorenz model because by estimating the dynamical noise and reflecting the estimation in the time series forecast, I can reduce the uncertainties for the past values of the observable for one step before or older.
Here is an intuitive analytic explanation on why the forecast has been improved. Let G(z(t),{p(τ)|τ≤t}) be d-dimensional delay coordinates as
In addition, we define infinite-dimensional delay coordinates G_{λ}(z(t),{p(t)}) as
In the proposed method, we have the following diagram:
Here F_{λ} represents one step ahead prediction by the method of analogue in the space of the InDDeCs with λ. Therefore, if F_{λ}°G_{λ}(z(t_{1}),{p(τ)|τ≤t_{1}}) and F_{λ}°G_{λ}(z(t_{2}),{p(τ)|τ≤t_{2}}) are close for various λ, then z(t_{1}) and z(t_{2}) are close, while the recent past {p(τ)|τ≤t_{1}}) and {p(τ)|τ≤t_{2}} are also close.
Under these “equivalences”, we approximate the first component of G°f_{p(t2+1)}°G^{−1}(G(z(t_{2}),{p(τ)|τ≤t_{2}})) by the Taylor expansion as
Thus, |G_{1}°f_{p(t2+1)}(z(t_{2}),{p(τ)|τ≤t_{2}})−G_{1}°f_{p(t1+1)}(z(t_{1}),{p(τ)|τ≤t_{1}})| can be upper bounded as
I note that the second term on the right hand side of Eq. (28) cannot be bounded tightly when there is no correlation in dynamical noise because for this sake we need the information of the future observables. However, the first and the third terms can be bounded better due to the above equivalences, and hence the uncertainty for the forecast would be reduced in general. Thus, if ∂G_{1}°f_{p(t+1)}∂p_{j}(t−k)(z(t_{1}),{p(τ)|τ≤t_{1}})≠0, or a generic case, estimating the past dynamical noise would bound the forecast errors more tightly due to the third term for the right hand side of Eq. (28), and thus could improve the forecasts better. An exception is the case of the Hénon map shown in Figs. 3(c) and 3(d), where
[observe the first element of Eq. (11)] and the estimation for the previous dynamical noise in the third term for the left hand side of Eq. (28) does not affect the accuracy of the forecast. Judging from the results in Figs. 3(c) and 3(d), the additional information by the proposed method rather aggravated the time series forecasts in the Hénon map example.
My results are robust even if I change the length of time series or I add some observational noise. To show this, let me go back to the model of Eqs. (16)–(19). When I looked at the one-step forecast errors, I found that the one-step forecast errors of the proposed method tended to become smaller than those of the reconstruction using only the delay coordinates [see Figs. 11(a) and 11(b)] when the length of time series is more than or equal to 500. When I compared the proposed method with the InDDeCs with λ_{1}, the proposed method shows the better forecast performance consistently [Figs. 11(a) and 11(b)].
When I set the length of time series to 10 000 and added observational noise, the proposed method showed the smaller forecast errors than the delay coordinates except for the case under which the signal-to-noise ratio is 1 [Figs. 11(c) and 11(d)].
The most important part could be how to choose the parameter I, which is the number of time series predictions for constructing prediction coordinates. When I varied the parameter I for the model of Eqs. (16)–(19), I found that the forecast errors have improved until I = 2, but later the forecast performance was stable and almost constant [Figs. 11(e) and 11(f)]. This finding is consistent with the fact that I am currently using two dimensional dynamical noise.
Even if the embedding dimension d is varied, I keep obtaining the robust results that the proposed method tends to yield the smaller forecast errors than the usual delay coordinates [Figs. 12(a) and 12(b)]. For example, although the difference between the proposed method and the delay coordinates becomes smaller when the embedding dimension becomes 3 or higher, the difference is negative and different from 0 statistically significantly (P < 0.001). In addition, see Fig. 13 for the examination on this topic with the other systems, where I obtained the similar results.
In addition, when I changed the numbers of neighbors K and L for the predictions and forecasts, I obtained similar results as shown in Figs. 12(c)–12(f), respectively.
Furthermore, when I changed the level of dynamical noise σ_{1} in the above Hénon map, I found that the proposed method is more effective when the level is stronger [see Figs. 14(a) and 14(b)]. When σ_{1}≥0.08, I could not run the simulation because the time series diverges. When I used the Rössler model and changed σ_{2}, the differences between the forecast errors of the proposed method and the delay coordinates were mostly negative [Figs. 14(c) and 14(d)], meaning that the proposed method tended to show smaller forecast errors. Therefore, although I have to grant that the improvements by the proposed method might be small, its tendency is steady.
The strengths for the proposed method compared with the ones in the existing literature are that (i) one does not have to assume that the dynamical noise changes slowly (see Refs [18–24]), (ii) one does not have to have the model equation [25], (iii) instances for the dynamical noise are estimated (for example, see Refs [26] and  [27] for estimating the level of dynamical noise only), (iv) the distribution for the dynamical noise is not assumed (see, for example, Ref [28]), and (V) one can use the method with a short time series [see, for example, Ref [29]; also see Fig. 14(a)]. Therefore, the proposed method may be applied in the wider contexts.
To overcome the non-stationarity of parameters, the method of over-embedding has been proposed [12,16]. Whether we should reconstruct time-varying parameters explicitly or implicitly must be examined with more depth in the future communications.
Non-stationarity for a given time series should be investigated in the future. Here, Fig. 15 shows that the Ikeda map is driven by a random walk as
where
and
Even in this case, the forecast errors have been improved significantly for up to four steps ahead forecasts. Thus, my method seems to have some hope for a non-stationary case.
The proposed method may be combined better with the method of Ref [30], where they assume to have a partial model for the underlying dynamics. This direction is probably a promising future direction of research.
For generating the results shown in Figs. 2–15, I needed almost 2 days of simulations using a computer with 2 CPUs of 2.66 GHz 6-Core Intel Xeon and 64GB memory. Thus, how to reduce the computational costs is another remaining problem.
In sum, I proposed to combine the essential ideas of the embedding theorems by Muldoon et_al [1] and Stark et_al [2] for explicitly reconstructing latent multi-dimensional dynamical noise and exploiting the reconstruction for forecasting the future values of observable better.
One can roughly classify dynamic systems into 4 classes depending on the two axes: whether the systems are deterministic or stochastic and whether the systems are linear or nonlinear. Although considerable research has explored linear deterministic systems, linear stochastic systems, and nonlinear deterministic systems, nonlinear stochastic systems have not been investigated well. Here, I employ essential ideas of two embedding theorems for reconstructing dynamical noise [1] and using the reconstruction for forecasting the future values of an observable [2]. The key idea is to regard multiple predictions as different observables and construct a coordinate system, which I call prediction coordinates. I test the proposed method using the Hénon map [3], the Ikeda map [4], the Rössler model [5], and the Lorenz model [6] driven by auto-regressive models [7] or the independent Gaussian noise.
A typical problem in time series analysis is to forecast the future values of observable given its past series. When we restrict ourselves to a deterministic system, the embedding theorems by Takens [8] and Sauer et_al [9] ensure that, generally, one can reconstruct the states for the underlying dynamics from these restricted observations by delay coordinates, and thus one can forecast its future based on the reconstructed states. When a system is a linear stochastic system, one may use the auto-regressive linear model [7] to forecast the future values for the observable. Thus, a remaining problem is how to forecast the future values when a time series is generated from a nonlinear stochastic system. Namely, my goal is to reconstruct the underlying states as well as past dynamical noise realizations based on the limited observations for forecasting the future observable values more accurately. Therefore, I do not intend to predict the current dynamical noise itself. I rather try to estimate the previous dynamical noise so that I can improve time series forecasts for the future observables.
A nonlinear stochastic system might be modelled, in general, as a nonlinear system on an m-dimensional manifold with parameters generated according to a stochastic process. As far as I have noticed, there exist two embedding theorems that can be used under such a circumstance: One of the embedding theorems is by Muldoon et_al [1], within which one can consider more than 2m-dimensional observations at two separated times to reconstruct the n-dimensional dynamical noise and m-dimensional state; the other one is by Stark et_al [2], within which one can forecast the future values of the observable given the past series of observable and the reconstructed dynamical noise. But, suppose here that we can observe a scalar time series only, and thus we cannot have access to (2m + 1)-dimensional observations directly. Under such a circumstance, I propose to create such observations by using (2m + 1) or more different time series predictions, which we call prediction coordinates. This point is the key for the rest of the story.
I start this paper by describing my setup. Let f:M×N→M be a dynamical system, on the m-dimensional manifold M, depending on a parameter on the n-dimensional manifold N. Letting p(t)∈N be realization of a parameter at time t, we have z(t + 1) = f(z(t),p(t + 1)). Let g:M→R be an observation function for the dynamical system. We denote the observation at time t by x(t) = g(z(t)). For convenience, I use z(t + 1) = f_{p}_{(}_{t}_{+ 1)}(z(t)) and z(t+b)=f_{p(t+b)p(t+b−1)⋯p(t+1)}(z(t))=f_{p(t+b)}(f_{p(t+b−1)}(⋯(f_{p(t+1)}(z(t)))⋯)). Then, delay coordinates here can be written by
Under mild technical conditions, it is a generic property that Φ_{f,g} is embedding [2]. This theorem means that one can reproduce z(t) by observing the sequence of observables if the noise realization of {p(t)} is given. Because we assume that f(z, p) is a diffeomorphism in terms of z when p is fixed, z(t) has one-to-one correspondence with z(t+d) given {p(t)}. Thus, in the later part, we describe delay coordinates backward. Therefore, if one can identify dynamical noise {p(t)}, one can better forecast the future values of the observable based on its past values.
Thus, to use this theorem, it is important to reconstruct a series of dynamical noise {p(t)}. For this purpose, I use the following theorem by Muldoon et_al [1] Let v:M→R^{d} be another “high-dimensional” observation of z(t). I also assume that f(·,p) is a diffeomorphism for each p∈N and f(z,·) be an embedding for each z∈M. Then, it is generic that
is an embedding [1]. Furthermore, if we fix any z∈M and consider a generic projection π:R^{2d}→R^{d}, then π(Θ(z,·)):N→R^{d} becomes an embedding.
The problem here is how to construct the function v. My solution is to employ multiple predictions. In this context, I found that there is a paper which reconstructs a one-dimensional driving force by taking a difference between a one-step prediction and the truth [10]. My difference with this existing literature is that I use multiple predictions so that I can accommodate multi-dimensional dynamical noise.
Here is a recipe of the proposed method. See Fig. 1 for the zoomed picture of the proposed method. We assume that we observe a scalar value x(t) sequentially. Let T be the length of time series and q be the maximum forecast steps for the resulting final forecasts. Then, the following calculation is conducted at each time t, which increases monotonically along the time. First, we prepare a set of one-step time series predictions x̂{i}(t) using infinite-dimensional delay coordinates (InDDeCs) [13]. By the analogy of Ref [12], this InDDeCs also reconstructs state variables as well as values for the parameter, simultaneously [14]. The InDDeCs can be defined as
where I inserted x(s) = 0 when s≤0. The distance between time points s→{i}(t_{1}) and s→{i}(t_{2}), in the L_{1}-norm, can be written as
In this paper, I use various decaying factors λ_{i}=i/(I+1)∈(0,1) for i=1,2,…,I. Based on the definition, the distance d(s→{i}(t_{1}+1),s→{i}(t_{2}+1)) for a step ahead can be written as
Thus, we can use this formula for calculating distances by recycling the previous distances. I also use a method of analogue [15] based on the information up to time t to generate prediction coordinates. (When the algorithm is started, I set d(s→{i}(τ),s→{i}(0))=0 for −T/4≤τ<0.) Namely, we look up K = 10 nearest neighbors, if not mentioned, and average their time successors to predict the future values of observable x(t). If I use a mathematical expression, the prediction can be written as
where J_{K}(t) represents a set of time indices for K nearest neighbors between time period of [t−T/4,t−1] in the above L_{1} norm of the InDDeCs with the decaying factor λ_{i}. Such distance sequences can be stored as
and updated as
for u=1,2,…,T/4. Second, we array each one-step prediction {x̂{i}(t)} for time t and {x̂{i}(t+1)} for time t + 1 to form a 2I-dimensional prediction coordinates y→(t) of
By Casdagli [16] and Hegger et_al [12], the delay coordinates with a large embedding dimension can hold the information of states as well as dynamical noise. Together with the embedding theorem by Whiteney [17] or Muldoon et_al [1], it is natural to consider that y→(t) contains the information of the underlying state as well as the recent sequence of dynamical noise {p(τ)|τ≤t}. Third, we combine the reconstructed dynamical noise described by the 2I-dimensional prediction coordinates y→(t) with delay coordinates v→(t)=(x(t−d+1),x(t−d+2),…,x(t)) of the actual observations {x(s)|s=t,t−1,…,t−d+1} to form combined coordinates of W(t)={v→(t),1ay→(t)} inspired by Stark et_al [2] so that W(t), in general, uniquely identifies z(t– d + 1) given the history of {p(t−s)|s=0,1,…,d−2}. Here, a is a constant for the reconstructed dynamical noise. I use I = 19 and a = 2I if not mentioned. I choose the parameter a in this way so that the effect of dynamical noise is in the same order as one of delay coordinates. If there is serial dependence among {p(t)}, W(t) would help us to forecast the future values of observable x(t) better. Even if there is no serial dependence on {p(t)}, estimating the past parts of {p(t)} would help us to forecast the future values of the observable better as I will discuss later. Thus, last as the fourth step, we use a series of W(t) to forecast the future values of x(t + s), where s > 0 by a method of analogue using L = 10 nearest neighbors. Namely, a final s steps ahead forecast x̂(t+s|t) for s = 1, 2,…,q at time t is given by
where J_{L}(t) denotes a set of nearest neighbors chosen in the L_{1}-norm between the time period of [T/4, t – q] in combined coordinates W(t) for time t. Notice that in the first step, I use the term predict, while in the fourth step, I use the term forecast. Throughout the paper, I am distinguishing these two terms consistently.
Previously, a similar framework has been used by Monroig et_al [11] to estimate the states. A big difference between their work and the current work is that I prepare a set of predictions to obtain a coordinate system described by y→(t), which eventually encodes the information of time varying parameter p(t). Thus, I regard different predictions as forming different coordinates to obtain the 2I-dimensional vector.
Because we are using the embedding theorem by Stark et_al [2] we should also have d≥2m+1.
Let us look at some numerical examples. I first consider the following Hénon map [3] driven by a source of dynamical noise p_{0}(t) which is now generated by the auto-regressive linear model [7]:
where η_{0}(t) follows the Gaussian distribution with the mean 0 and the standard deviation 1. In addition, I set σ_{1} = 0.07 if not mentioned. I generated a time series of length 10 000 by observing z_{1}(t). For each time, I started to use the first quarter of time points as an initial database to issue predictions for the later three quarters, construct prediction coordinates, and thus reconstruct the past dynamical noise. When I look at the values of prediction coordinates subtracted by the corresponding actual values, they were correlated with the original dynamical noise (see Fig. 2). In the hundred examples tested, the means for the means and the standard deviations for the correlation coefficients between the original dynamical noise and its 19 elements of y_{i}(t) – z_{1}(t) for i=1,2,…,19 were –0.3688 ± 0.1097, which is significantly different from 0 (P < 0.001). Thus, when I used the prediction coordinates combined with delay coordinates and forecast the future values for the observable in the second half of the time series, the time series forecasts tended to show the smaller forecast errors than the case where I only used the delay coordinates for forecasting the future values for the observable [see Figs. 3(a) and 3(b)]. For example, when I compare the forecast time series with the original as shown in Fig. 4, the local minima exhibited at the 8983th, 8987th, and 8993th points look much closer to the truth in the proposed method than in the three-dimensional delay coordinates, which correspond to an over-embedding [12] in the best time interval [Fig. 4(a)], while in the worst time interval, there was not much difference between the proposed method and the over-embedding [Fig. 4(b)].
My second example is the Ikeda map [4] driven by an auto-regressive linear process
where
and
I observed z_{1} to generate scalar time series.
When I used a one-step time series prediction by the InDDeCs, I could reconstruct the dynamical noise as shown in Fig. 5. The means for the means and the standard deviations between the absolute values for the correlation coefficients between the actual dynamical noise and its reconstruction y_{i}(t) – z_{1}(t) for i=1,2,…,19 were –0.0707 ± 0.0140, which is also significantly different from 0 (P < 0.001). But, the difference between the actual value and its one-step forecast could not be a good index for evaluating the accuracy for the reconstruction of dynamical noise because the reconstruction might be valid only locally, and thus may not have good correlation with the actual values globally.
When I forecast the future values in the second half of the time series, I could see some improvements by the proposed method compared with the three-dimensional delay coordinates [Figs. 6(a) and 6(b)]. When I looked at the best example of one step forecasts, the proposed forecasts have been improved, especially at the 9816th, the 9832th, and the 9837th points [Fig. 7(a)], while in the worst example, there was not much difference between the proposed method and the over-embedding [Fig. 7(b)]. Therefore, the results seem to be consistent with the first case of the Hénon map. Hence, our reconstruction for past dynamical noise could be valid locally sufficiently to improve time series forecasts.
My third example is the following Ikeda map [4] driven by two sources of dynamical noise:
where
and
where η_{1}(t) and η_{2}(t) follow the Gaussian distribution with the mean 0 and the standard deviation 1. I observe z_{1}(t) to forecast its future values.
The results are presented in Figs. 8(a) and 8(b). As similar to the first and second examples, the forecasts have been improved for the short-term forecasts.
My fourth example is the Rössler model driven by an auto-regressive linear model
and
where η_{3}(t) follows the Gaussian distribution with mean 0 and standard deviation 1. In addition, I set Δt = 0.01 and sample z_{1}(tΔt) every 0.2 unit time to generate scalar time series. Furthermore, I set σ_{2} = 0.03 initially.
The results are shown in Figs. 9(a) and 9(b). In the Rössler model as well, the forecast errors tend to be smaller for one step ahead forecasts in the proposed method than those obtained in the four-dimensional delay coordinates, which should also be regarded as an over-embedding [12] case. For this example, it seems that longer step forecasts are not so skillful for the proposed method compared with the over-embedding.
My fifth example is the Lorenz model driven by, also, an auto-regressive linear model
and
Here, η_{4}(t) follows the Gaussian distribution with mean 0 and standard deviation 1. Moreover, I set Δt = 0.01 and sample z_{1}(tΔt) every 0.05 unit time for obtaining scalar time series.
The results are shown in Figs. 10(a) and 10(b). I can see the tendency that the forecast errors by the proposed method tend to be smaller than those by the four-dimensional delay coordinates in this example of the Lorenz model as well. Since the difference did not start converging at 10 steps ahead, we probably could forecast further steps more accurately with the proposed method.
My results did not change match even when I replaced the auto-regressive models of {p_{i}(t)} for i = 0,1,2,3,4 with independent Gaussian noise of mean 0 and standard deviation 1 as shown in panels (c) and (d) of Figs. 6 and 8–10 except for the Hénon map example [see Figs. 3(c) and 3(d)]. Even when {p_{i}(t)} for i = 1, 2, 3, 4 are the independent Gaussian noise, I can still improve the forecast errors in the examples of the Ikeda map, the Rössler model, and the Lorenz model because by estimating the dynamical noise and reflecting the estimation in the time series forecast, I can reduce the uncertainties for the past values of the observable for one step before or older.
Here is an intuitive analytic explanation on why the forecast has been improved. Let G(z(t),{p(τ)|τ≤t}) be d-dimensional delay coordinates as
In addition, we define infinite-dimensional delay coordinates G_{λ}(z(t),{p(t)}) as
In the proposed method, we have the following diagram:
Here F_{λ} represents one step ahead prediction by the method of analogue in the space of the InDDeCs with λ. Therefore, if F_{λ}°G_{λ}(z(t_{1}),{p(τ)|τ≤t_{1}}) and F_{λ}°G_{λ}(z(t_{2}),{p(τ)|τ≤t_{2}}) are close for various λ, then z(t_{1}) and z(t_{2}) are close, while the recent past {p(τ)|τ≤t_{1}}) and {p(τ)|τ≤t_{2}} are also close.
Under these “equivalences”, we approximate the first component of G°f_{p(t2+1)}°G^{−1}(G(z(t_{2}),{p(τ)|τ≤t_{2}})) by the Taylor expansion as
Thus, |G_{1}°f_{p(t2+1)}(z(t_{2}),{p(τ)|τ≤t_{2}})−G_{1}°f_{p(t1+1)}(z(t_{1}),{p(τ)|τ≤t_{1}})| can be upper bounded as
I note that the second term on the right hand side of Eq. (28) cannot be bounded tightly when there is no correlation in dynamical noise because for this sake we need the information of the future observables. However, the first and the third terms can be bounded better due to the above equivalences, and hence the uncertainty for the forecast would be reduced in general. Thus, if ∂G_{1}°f_{p(t+1)}∂p_{j}(t−k)(z(t_{1}),{p(τ)|τ≤t_{1}})≠0, or a generic case, estimating the past dynamical noise would bound the forecast errors more tightly due to the third term for the right hand side of Eq. (28), and thus could improve the forecasts better. An exception is the case of the Hénon map shown in Figs. 3(c) and 3(d), where
[observe the first element of Eq. (11)] and the estimation for the previous dynamical noise in the third term for the left hand side of Eq. (28) does not affect the accuracy of the forecast. Judging from the results in Figs. 3(c) and 3(d), the additional information by the proposed method rather aggravated the time series forecasts in the Hénon map example.
My results are robust even if I change the length of time series or I add some observational noise. To show this, let me go back to the model of Eqs. (16)–(19). When I looked at the one-step forecast errors, I found that the one-step forecast errors of the proposed method tended to become smaller than those of the reconstruction using only the delay coordinates [see Figs. 11(a) and 11(b)] when the length of time series is more than or equal to 500. When I compared the proposed method with the InDDeCs with λ_{1}, the proposed method shows the better forecast performance consistently [Figs. 11(a) and 11(b)].
When I set the length of time series to 10 000 and added observational noise, the proposed method showed the smaller forecast errors than the delay coordinates except for the case under which the signal-to-noise ratio is 1 [Figs. 11(c) and 11(d)].
The most important part could be how to choose the parameter I, which is the number of time series predictions for constructing prediction coordinates. When I varied the parameter I for the model of Eqs. (16)–(19), I found that the forecast errors have improved until I = 2, but later the forecast performance was stable and almost constant [Figs. 11(e) and 11(f)]. This finding is consistent with the fact that I am currently using two dimensional dynamical noise.
Even if the embedding dimension d is varied, I keep obtaining the robust results that the proposed method tends to yield the smaller forecast errors than the usual delay coordinates [Figs. 12(a) and 12(b)]. For example, although the difference between the proposed method and the delay coordinates becomes smaller when the embedding dimension becomes 3 or higher, the difference is negative and different from 0 statistically significantly (P < 0.001). In addition, see Fig. 13 for the examination on this topic with the other systems, where I obtained the similar results.
In addition, when I changed the numbers of neighbors K and L for the predictions and forecasts, I obtained similar results as shown in Figs. 12(c)–12(f), respectively.
Furthermore, when I changed the level of dynamical noise σ_{1} in the above Hénon map, I found that the proposed method is more effective when the level is stronger [see Figs. 14(a) and 14(b)]. When σ_{1}≥0.08, I could not run the simulation because the time series diverges. When I used the Rössler model and changed σ_{2}, the differences between the forecast errors of the proposed method and the delay coordinates were mostly negative [Figs. 14(c) and 14(d)], meaning that the proposed method tended to show smaller forecast errors. Therefore, although I have to grant that the improvements by the proposed method might be small, its tendency is steady.
The strengths for the proposed method compared with the ones in the existing literature are that (i) one does not have to assume that the dynamical noise changes slowly (see Refs [18–24]), (ii) one does not have to have the model equation [25], (iii) instances for the dynamical noise are estimated (for example, see Refs [26] and  [27] for estimating the level of dynamical noise only), (iv) the distribution for the dynamical noise is not assumed (see, for example, Ref [28]), and (V) one can use the method with a short time series [see, for example, Ref [29]; also see Fig. 14(a)]. Therefore, the proposed method may be applied in the wider contexts.
To overcome the non-stationarity of parameters, the method of over-embedding has been proposed [12,16]. Whether we should reconstruct time-varying parameters explicitly or implicitly must be examined with more depth in the future communications.
Non-stationarity for a given time series should be investigated in the future. Here, Fig. 15 shows that the Ikeda map is driven by a random walk as
where
and
Even in this case, the forecast errors have been improved significantly for up to four steps ahead forecasts. Thus, my method seems to have some hope for a non-stationary case.
The proposed method may be combined better with the method of Ref [30], where they assume to have a partial model for the underlying dynamics. This direction is probably a promising future direction of research.
For generating the results shown in Figs. 2–15, I needed almost 2 days of simulations using a computer with 2 CPUs of 2.66 GHz 6-Core Intel Xeon and 64GB memory. Thus, how to reduce the computational costs is another remaining problem.
In sum, I proposed to combine the essential ideas of the embedding theorems by Muldoon et_al [1] and Stark et_al [2] for explicitly reconstructing latent multi-dimensional dynamical noise and exploiting the reconstruction for forecasting the future values of observable better.
FIG. 1. 
The illustration of the proposed method for each time t. First, I use the infinite-dimensional delay coordinates (InDDeCs) to reconstruct the underlying states z(t) and recent past series of dynamical noise {p(τ)|τ≤t} to generate one-step predictions. These pieces of information are represented by prediction coordinates denoted by y→(t). In addition, I prepare the delay coordinates v→(t). Then, I combine v→(t) and y→(t) to form combined coordinates. Then, I forecast the future values x̂(t+s|t) (s=1,2,…,p) using nearest neighbors based on the combined coordinates.
FIG. 2. 
Reconstructed dynamical noise with λ_{1} plotted against the actual dynamical noise in the example of the Hénon map driven by an auto-regressive linear model.
FIG. 3. 
The forecast errors of the proposed method (red solid lines) and the delay coordinates (blue dashed-dotted lines) and their differences in up to 10 steps ahead forecasts between in the Hénon map driven by a stochastic process. The forecast errors were evaluated by the mean absolute errors. In panels (a) and (b), the results for the Hénon map driven by an auto-regressive linear model are shown. In panels (c) and (d), the results for the Hénon map driven by Gaussian noise are shown. If the values for the differences are negative in panels (b) and (d), then the proposed method is better than the delay coordinates. I obtained the error bars by the means and the standard deviations over 100 numerical experiments with different initial conditions as well as different noise realizations. In the other figures, I obtained the error bars similarly as well. I note that to generate panels (c) and (d), I removed 3 experiments among the 100 numerical experiments because the corresponding generated time series escaped from the attractor and had diverged.
FIG. 4. 
(a) Best and (b) worst examples of one step forecasts for the proposed method (red dashed line), compared with the delay coordinates (blue dashed-dotted line), for the Hénon map driven by an auto-regressive linear model. The truth time series is shown in the black solid line. Here, the best (the worst) means that the forecast errors summed over 30 time points for the over-embedding subtracted from those for the proposed method are negative and the smallest (positive and the largest), respectively.
FIG. 5. 
A similar figure as Fig. 2 except that here I used the Ikeda map driven by an auto-regressive linear model as defined in Eqs. (13)–(15).
FIG. 6. 
Similar figure to Fig. 3 except that the Ikeda map is driven by a stochastic source. In panels (a) and (b), the stochastic source is an auto-regressive linear model, while in panels (c) and (d), the stochastic source is independent Gaussian noise.
FIG. 7. 
(a) Best and (b) worst examples of one step forecasts for the proposed method (red dashed line) compared with the delay coordinates (blue dashed-dotted line), for the Ikeda map driven by an auto-regressive linear model. The truth time series is shown in the black solid line. See the caption of Fig. 4 to interpret the results.
FIG. 8. 
Similar figure to Fig. 3 except that the Ikeda map is driven by two different stochastic sources. In panels (a) and (b), the two stochastic sources are from two auto-regressive linear models, while in panels (c) and (d), the two stochastic sources are two independent sources of Gaussian noise.
FIG. 9. 
Similar figure to Fig. 3 except that the driven system is the Rössler model. In panels (a) and (b), I show the results assuming that the stochastic source is an auto-regressive linear model, while in panels (c) and (d), the stochastic source is generated from independent Gaussian noise. Although the difference between the proposed method and the delay coordinates for one step forecasts looks small in panels (a) and (c) because each of 100 time series varies to a great extent, the difference for one step ahead tends to be consistently negative as shown in panels (b) and (d).
FIG. 10. 
Similar figure to Fig. 3 except that the Lorenz model is driven. In panels (a) and (b), the stochastic source is an auto-regressive linear model, while in panels (c) and (d), the stochastic source is independent Gaussian noise.
FIG. 11. 
The first half for the sensitivity analysis for the obtained results in the Ikeda model of Eqs. (16)–(19). In panels (a) and (b), the dependence on the length of time series is shown. The red solid and blue dashed-dotted error bars correspond to the proposed method and the delay coordinates, respectively, while the green dashed error bars show the differences between the proposed method and the infinite dimensional delay coordinates with λ_{1}. In panels (c) and (d), the effect of observational noise was examined. In panels (e) and (f), the effect of the number of predictions for the prediction coordinates was investigated. In panels (b), (d), and (f), the differences with the results by the delay coordinates are shown.
FIG. 12. 
The second half of sensitivity analysis for the obtained results in the Ikeda model of Eqs. (16)–(19). In panels (a) and (b), the effect of the embedding dimension for delay coordinates is shown. In panels (c)–(f), I show that the results do not depend much on the numbers of neighbors K and L, respectively, for either predictions for prediction coordinates or final forecast, where I set the other numbers L = 10 and K = 10 of neighbors. In panels (b), (d), and (f), the differences between the proposed method and the delay coordinates are shown.
FIG. 13. 
Similar panels as Figs. 12(a) and 12(b), except that panels (a) and (b) are for the Hénon map driven by an auto-regressive linear model, panels (c) and (d) are for the Rössler model driven by an auto-regressive linear model, and panels (e) and (f) are for the Lorenz model driven by an auto-regressive linear model.
FIG. 14. 
Dependence on dynamical noise level shown in one step forecasts. In panels (a) and (b), the results of the Hénon map are shown, while the results of the Rössler model are shown in panels (c) and (d). In panels (a) and (c), the forecast errors are shown for the proposed method (red solid line) and the delay coordinates (blue dashed-dotted line) are shown, while in panels (b) and (d), their differences are shown.
FIG. 15. 
The results similar to Fig. 6 except that the driver is a random walk.
