First results of the multi-purpose real-time processing video camera system on the Wendelstein 7-X stellarator and implications for future devices
A special video camera has been developed for the 10-camera overview video system of the Wendelstein 7-X (W7-X) stellarator considering multiple application needs and limitations resulting from this complex long-pulse superconducting stellarator experiment. The event detection intelligent camera (EDICAM) uses a special 1.3 Mpixel CMOS sensor with non-destructive read capability which enables fast monitoring of smaller Regions of Interest (ROIs) even during long exposures. The camera can perform simple data evaluation algorithms (minimum/maximum, mean comparison to levels) on the ROI data which can dynamically change the readout process and generate output signals. Multiple EDICAM cameras were operated in the first campaign of W7-X and capabilities were explored in the real environment. Data prove that the camera can be used for taking long exposure (10–100 ms) overview images of the plasma while sub-ms monitoring and even multi-camera correlated edge plasma turbulence measurements of smaller areas can be done in parallel. These latter revealed that filamentary turbulence structures extend between neighboring modules of the stellarator. Considerations emerging for future upgrades of this system and similar setups on future long-pulse fusion experiments such as ITER are discussed.
I. INTRODUCTION
Video camera systems are one of the basic overview diagnostics on magnetic fusion devices [1]. Cameras operating in the visible range typically at a 50 Hz frame rate give an overview for the operator on the plasma shape, position, or enhanced plasma-wall interaction during the whole discharge, while infrared cameras monitor the temperature of plasma facing components. Additionally, special high-frequency (>100 kHz) cameras have been used during short time intervals for imaging plasma turbulence and instabilities at the edge [2,3]. Traditionally, the recorded video streams are analyzed off-line after the plasma discharge. With the increase of plasma kinetic energy and heating power and the installation of more vulnerable metal plasma facing components, the need has arisen to monitor the video streams on-line, detect hot-spots, and feed this information into the control system. On Tore Supra [4,5], the images of infrared video cameras have been processed real-time to monitor the surface temperature of several plasma facing components. Similar systems have been installed on the Axial Symmetric Divertor EXperiment Upgrade (ASDEX Upgrade)  [6] and the Joint European Torus (JET) [7] using industrial analog video cameras sensitive to the visible and Near Infra-Red (NIR) wavelength ranges. Although the NIR cameras can measure only higher temperatures, they offer advantages concerning dynamic range, errors from emissivity, and absorption by windows [6] which are considered as a source of problem on IR systems [5]. Considering their lower price and broader availability, visible/NIR cameras seem to be a better choice for overview and general protection systems, while IR cameras are used for measurements in the divertor and other high heat flux regions in greater detail.
Wendelstein 7-X [8] (W7-X) is a fully superconductive modular stellarator experiment which started operation in Greifswald, Germany in 2015. It is the first example of future magnetic fusion devices where the plasmas will be operated in long pulses, in the case of W7-X up to 30 min. Such long pulses and the high heating power call for a real-time monitoring camera setup, where disturbances can automatically be detected and rectified by the control system. Additionally, the extremely complicated geometry of the device limits diagnostic access to the plasma; therefore, the available views should be used for as many purposes as possible; in an optimal case overview, hot-spot detection and high-frequency physics measurements would be combined. It was found that commercial camera solutions are not suitable to fulfil the conflicting requirements of long exposure overview, fast monitoring, high-frequency physics measurements, and real time response; therefore, a special camera was designed and built for this purpose. This paper describes the Event Detection Intelligent Camera (EDICAM) camera system and first experiences during the 2015-2016 (OP1.1) campaign of W7-X. It is believed that this unique development establishes a technology which might find its application on the next generation of fusion devices, most notably JT-60SA and ITER.
The paper is organized as follows. Section II describes the optical and mechanical considerations and outlines the implementation of the EDICAM system. The data acquisition considerations and schemes are investigated in Sec. III, while the first experiences in the real experiment are documented in Sec. IV. The paper ends with a comparison with other solutions, outlook for possible upgrades of the W7-X system, and implications for future long-pulse fusion experiments.
II. GEOMETRICAL AND OPTICAL CONSIDERATIONS, HARDWARE IMPLEMENTATION
W7-X is a modular stellarator constructed of 5 identical modules. In each of them, two narrow tangential ports (labeled AEQ) are allocated for the overview video diagnostic as shown in Fig. 1. From the AEQ ports, nearly the whole vacuum vessel interior can be observed; therefore, they provide an ideal view on the plasma and plasma facing components. For image resolution, 2 mm was set as the target, as it enables observation of the plasma shape, wall tiles, hot spots, and edge physics phenomena. This spatial resolution necessitated a roughly 1 Mpixel image sensor.
The AEQ ports extend over more than 2 m from the first wall to the outside vacuum boundary of the cryostat. The vacuum boundary is located at the plasma end of the port; therefore, the tube is on air so as to allow sensitive optical and electronic components to be replaced without opening the machine vacuum. The vacuum window posed a special problem as in the final phase of the machine operation about 50 kW/m^{2} heat load is expected there. Cooling problems of the windows resulted in the decision to install a water-cooled 0.4 cm diameter pinhole in front of the window. The pinhole and a small hydrogen gas flow through the pinhole limit carbon deposition on the window. This way an acceptable window transmission is expected to be maintained even throughout an experimental campaign with long pulse operation. The pinhole, however, seriously limits the amount of detectable light.
During cooling of the superconducting coil system, the vacuum vessel and the cryostat move relative to each other. To allow this movement, one part of the AEQ ports is built from bellows; thus, it is not a rigid structure. Additionally, the port is also not straight as it has to pass by a coil. Due to these limitations, it is very difficult to build an imaging optics through the AEQ ports. Various options have been studied and finally a decision was made to, at least for the first campaigns, install a specially built camera (EDICAM) in the front part of the tube. The camera is mounted into a capsule which docks into a well-defined holder in front of the window. The capsule is pushed through the bent port by bellows and cooled by compressed air flow. In this solution, the camera needs to be operated up to 3 T magnetic field, which needs a somewhat special design and careful selection of materials. An alternative solution has also been developed where an imaging fiber array is installed in the port and a camera is located outside the port.
A special lens [9] was designed and built for the W7-X camera system with its entrance pupil being located outside the lens exactly at the location of the pinhole. This lens maintains a quasi-constant spatial resolution of about 2 mm over the entire plasma vessel wall; the viewing distance ranges from 2 m to 7 m. It also offers the possibility of using an optical filter in a specially designed parallel light section of the optic to define the measured wavelength although in most cases this is not used. Further details of the mechanical and optical setup of the system are described in Ref [9].
Due to the proximity of the camera to the plasma and the high magnetic field, only the most essential electronics is located in the port: the sensor, digitizers, and a small-capacity Field Programmable Gate Array (FPGA) which communicates with an Image Processing and Control Unit (IPCU) through a fast 10 Gbit/s optical link. The IPCU is located in a Personal Computer (PC) and communicates with it via an 8-lane Peripheral Component Interconnect Express (PCIe) bus. This way the data transmission bandwidth from the sensor to the computer exceeds the data rate of the sensor and its capabilities can be fully made use of. Details of the software and hardware implementation are described in Refs [10] and  [11].
The sensor module was tested for magnetic field hardness up to 3 T fields and 250 mT/min change rate in a gyrotron magnet at the Karlsruhe Institute of Technology and operated in the port of the ASDEX Upgrade tokamak in magnetic fields of similar values than in W7-X. Radiation testing in research reactors was done up to 1.7 × 10^{12}n/cm^{2}, which corresponds to about 10% of the maximum annual dose calculated for the camera location in the high-power operation phase of W7-X. The results indicated a considerable increase of the sensor leakage current and number of bad pixels but no failure of the electronics.
It is expected that at least before the final high-power operation of W7-X in the 2020s, EDICAM can be operated in the port, provided the real-time data processing handles bad pixels and radiation induced noise. Further radiation testing and modeling is planned to determine whether it should be moved out of the port using an imaging fiber array for light transmission. However, it has to be noted that optical imaging fiber bundles are manufactured by industry only from standard glass types which rapidly lose their transmission by exposure to ionizing radiation during Deuterium plasma operation. Heating a strongly darkened fiber bundle from ASDEX-Upgrade at 120 °C for days resulted in a 15%–50% recovery of its transmission, mostly in the red visible range [12]. If fiber arrays are needed special radiation-hard silica fiber bundles must be built. Continuously keeping such fiber bundles with a heated jacket at elevated temperatures of 120 °C would most likely be sufficient to maintain a reasonable optical transmittance. However, building 10 such special high-resolution fiber arrays would be a considerable technical challenge and would most likely be outside of the available budget.
III. DATA ACQUISITION CONSIDERATIONS
Wall protection camera systems rely typically on 50 Hz frame rate cameras as the thermal response time of wall elements does not necessitate better time resolution. The W7-X camera system is designed primarily as an edge plasma overview system; therefore it operates at visible light, where changes might occur at a faster time scale. For example, the breakdown process and Edge Localized Modes (ELMs) happen on a sub-ms time scale and their spatial and temporal changes are of interest for the physics research. Increased plasma-wall interaction areas would also show up on visible light before a real “hot spot” forms on the wall element. The W7-X video overview system would also be in a unique position to observe edge plasma instabilities like scrape-off layer blobs (filaments) which necessitates even better, about 10 μs time resolution [13].
For a good overview image, about 1–2 mm spatial resolution was considered as necessary, translating to about 1 Mpixel sensor resolution. Running the video overview system at 100 kHz frame rate with the full 1 Mpixel resolution would result in about 1000 Gbit/s data rate, not supported by today’s technology neither at the sensor nor at the data acquisition (DAQ) side. In most commercially available fast cameras, the image readout can be limited to certain small Regions-Of-Interest (ROIs); thus, the data rate can be fit into available bandwidth even for several 100 kHz frame rate. However, the parallel operation of such ROIs is in conflict with the general monitoring function of the camera system where it is expected to integrate light for 10–100 ms. To overcome this conflict of requirements, a 1.3 Mpixel CMOS sensor with “non-destructing read” (NDR) capability was selected (LUPA-1300 from Cypress). In this sensor, the image exposure and readout are decoupled which is accomplished by having a second analog storage array next to the light sensitive pixels. With a single electronic signal, the actual image data are sampled into this storage area without affecting the actual information in the light sensitive pixels. Readout can be performed from any part of the analog copy within 2.5 ms from the sampling time. The information in the light sensitive pixels can be erased with a separate reset electronic signal. Reading out the full 1.3 Mpixel information from the analog storage array takes 2.25 ms; thus, the maximum full sensor frame rate is 444 Hz. Reading only a 16 × 16 pixel area, the readout rate can be somewhat over 100 kHz. The shape of the readout areas can be programmed, and non-rectangular areas are also possible. Due to the relatively complicated pixel electronics, the sensor has only 15% peak quantum efficiency ^{*} fill factor value (QE^{*}ff) which is to some extent compensated by the relatively large, 14 μm pixel size. The spectral sensitivity range is broad with 10% QE^{*}ff between 400 and 800 nm. The pixel well is 62 500 e with 45 e readout noise, providing about 1500 peak signal to noise ratio (SNR). In order to make full use of these capabilities, we digitized pixel data to 12 bits.
With the NDR mode, one can combine long exposure with fast monitoring of certain areas. This operation is even beneficial from the point of view of maximizing the Signal-to-Noise Ratio (SNR). To illustrate this, let us compare two situations. In case 1, a faint image is exposed for 100 ms and a small area is monitored by reading it out at each 2.5 ms in the NDR mode. In case 2, without NDR, one could read the full image every 2.5 ms and construct the long exposure image by summing up 40 images. For the fast measurement, subtracting two consecutive readouts in case 1 means that the power of the sensor readout noises add, resulting in a decrease of the SNR by 2 compared to case 2 when only a single readout noise adds to the image. The situation is different for the long exposure image. In case 1, it results from a single readout; therefore, one readout noise adds to the image. In case 2, the image is a sum of 40 readouts. The power of the 40 readout noise adds, resulting in 40 (square root of the number of summed images) times higher readout noise amplitude and 40 times higher signal amplitude. This means that the SNR is decreased by a factor of 40 compared to case 1.
Operating the sensor in the NDR mode, one can perform measurements on various time scales in parallel. The operation scheme is shown in Fig. 2. The signal in the light-sensitive pixels is reset periodically which defines the exposure sequence. After the sensor reset, the signal in the sensor pixel increases proportionally to the integrated light intensity. In order to enable real-time response to changes in the image, the NDR sensor readout operations are not run with some predefined timing but controlled by the IPCU which analyses data and initiates all sensor read operations. The building blocks of the IPCU are “ROI Processes” (ROIPs) and “events.” Each ROIP describes a periodic sequence of readouts for a single ROI. ROIPs generate a sensor read request transmitted from the IPCU to the sensor module. In addition to the ROI shape and timing description, the ROIP also has two additional state flags which can also be changed during operation: “active” and “send data.” The first flag enables/disables ROIP operation. The “send data” flag determines what happens to the ROI data received from the sensor module. If this flag is set, the data block is transferred to the PC memory without any modification. This way a sequence of ROI data blocks appears in the PC memory, each block containing the full description of the data including both timing and spatial information. If “send data” is not set, the ROI data are processed in the IPCU by event operations but it is not sent to the PC.
The ROI readout is completely independent of the exposure cycle; it is also possible to read data when the pixels are reset. As the ROI readout operation takes a certain time, it may happen that the sensor is busy at the time specified in the next read request. In this case, two behaviors are possible, determined by ROI settings. “Persistent” ROIs will wait for the next possible time and read the sensor then. If this feature is not set, then the read request will be cancelled by the sensor module. It has to be noted that if consecutive read requests specify the same time (like ROI2 and ROI3 in Fig. 2) it is still possible to provide data as the image data are available in the analog storage array. This way multiple small ROIs can be sampled exactly at the same time, but no image monitoring is possible while a larger ROI is being read out (∼2 ms for a full frame ROI).
The above operation mode has one major deficiency, namely, the readout intensity of the monitored area represents the integrated light intensity since the start of the exposure, and the instantaneous intensity is not known. To handle this problem, an additional ROIP feature (differential ROI) has been implemented and being tested in the laboratory where the IPCU subtracts two consecutive images and event processing is based on the difference image. This operation mode was simulated offline on the first W7-X data and results are presented below.
As data are directly sent during the readout process to the IPCU, it can analyze it and make decisions how to perform subsequent readouts. The decision making is done via logical elements called “event.” They take multiple 1-bit digital inputs, have a 1-bit state, and perform actions in response to their state changes. Inputs can be derived from various sources:
• data in a rectangular part of a ROI (sub-ROI) are analyzed and the input is set/reset when the mean or minimum/maximum is above/below a threshold;
• state of another event;
• state of external input signal;
• time passes a certain value;
• bit set by the PC software.
The inputs for an event can be enabled/disabled/inverted and combined by a logical AND operation to yield the event state which controls the actions. Actions at present can set/reset or control (change continuously according to the event) the “active” and “send data” state of the ROIPs or produce a digital output signal. Additional possibilities are considered in the future like sending interrupt to the PC or an event to a real-time control system.
Using ROIPs and events, the camera can respond to changes in the image autonomously, even during an exposure cycle. This functionality has been demonstrated in the laboratory [11] but was not used in the first (OP1.1) operation phase of W7-X.
The final long-term aim of the EDICAM system is to use a two-level processing concept. Low level is done by setting up an appropriate scheme using the ROIP and event elements described above. With this, the camera can respond autonomously to simple changes in the scene even during an exposure and optimize the use of the available bandwidth. At the second level, the data arriving to PC memory will be processed and parameters of the ROI and event setup will be modified. Inter-camera communication can also be done at two levels. At low level, one event sets an output transistor-transistor logic (TTL) signal which is the input to an event on another camera. At the second level, the processing PC sends a message to another PC and that changes the settings attached to its camera. At present the second level processing is not implemented, and only a real-time image stream is sent to the W7-X control system. The multi-ROI data stream is stored in the PC memory and saved to the HDF5 file on-the-fly during the discharge using a fast Solid State Disk (SSD).
IV. EXPERIENCES IN THE FIRST (OP1.1) W7-X CAMPAIGN
In the OP1.1 experimental campaign of W7-X, nine of the 10 ports were equipped with a pinhole as on one port the panel with the pinhole was not installed. This allows in the first campaign, in combination with a low noise, higher sensitivity CCD camera, to detect any faint detailed structures in the images obtained with an electron beam for mapping of the magnetic field structure before the campaigns [14]. This will no longer be possible with the start of long pulse operation, i.e., from OP2 onward. However, this higher throughput port allowed efficient operation of a fast CMOS camera (Photron SA5) for observing details of filament movements in the plasma. This camera was installed outside the port in a magnetic shielding box, and light was coupled through modified frontend optics and a coherent fiber bundle. Such a fiber bundle was also used in a port with a pinhole but the light intensity was often too low for fast measurements.
Another AEQ port had a leak between the port and the cryostat vessel; therefore, an image guide had to be mounted in an additional metal bellow with a front-end optic and window as the vacuum boundary. This port was occasionally used in the first campaign with the fast CMOS camera. One more port contained a slow CCD camera and the remaining 7 ports were equipped with EDICAM cameras. No clock distribution was available in the OP1.1 campaign of the stellarator; therefore, each EDICAM was operated from its internal clock source. This means about 100 μs random time shift per second can be expected between cameras.
As the plasma discharges were short (maximum 6 s) and no divertor structures were installed, the main aim of the video measurements was to provide visual feedback to the machine operator on the plasma discharge location, shape, and timing. This necessitated full image readout with exposure times compatible with the radiation intensity, typically 10 ms. To avoid any interference with the overview operation, multiple ROIs were set up only in a limited number of discharges with the aim of determining signal quality and demonstrating the multi-purpose use of the system. As the real-time control system of the stellarator is not available yet, no attempt was made to detect events with EDICAM.
In this paper, we analyze measurements when two small (128 × 64 pixel) ROIs were operated in parallel to a full ROI in two EDICAM systems (AEQ40 and AEQ50) looking in the same direction in neighboring modules. These measurements were compared to fast CMOS camera measurements in a port without pinhole.
Figure 3 shows a camera image in the middle of an approximately 1 s long discharge when the plasma was steady-state for several hundred ms. The exposure cycle was 10 ms long, with 9.95 ms exposure time and 50 μs sensor reset time. Three ROIs were operated. ROI1 is the full image readout at the end of each exposure, which is operated at 100 Hz frame rate. ROI2 and ROI3 are two 128 × 64 pixel areas around the plasma lower left edge where the light intensity is expected to be higher. These ROIs are read out with a constant 5 kHz rate at identical times.
A. Signal to noise considerations
To analyze the image properties and the multi ROI operation in detail, the intensity measured in the same pixel in ROI1 and ROI2 is plotted as a function of time. Figure 4 shows the time evolution of the intensity in a single pixel approximately in the middle of ROI2 during the plasma startup phase. One can see that ROI1 is read out every 10 ms at the end of the exposure. ROI2 is read periodically every 200 μs. Just after ROI1 readout, ROI2 data are missing as the sensor is busy with the readout of ROI1 for about 2 ms. The discharge starts at about 0.05 s. The first image after that in ROI1 is saturated at about 3500 digits. The saturation process is clearly seen in ROI2; it can follow the light intensity before saturation. Later, at about 0.12 s when the discharge starts to stabilize and the light intensity does not change considerably in 10 ms, the ROI2 intensity change becomes linear in time during one exposure cycle and reaches the value of the successive ROI1 readout as expected in the case of constant light intensity.
The RMS readout noise at no light was determined in laboratory measurements and also from the data recorded before and after the discharge. The observed value is in good agreement with the temporal noise level in the sensor datasheet (45 e). The origin of this is the electronic amplifier noise and cannot be reduced. Occasionally some electronic disturbance appears additionally at comparable amplitude; its origin is being investigated.
The instantaneous light intensity in the fast ROIs can be calculated by subtracting two consecutive images and dividing by the time difference of the two readouts. This is shown in Fig. 5(a) for the same pixel as in Fig. 4 and for the mean of a 10 × 10 pixel area around it. The ROI2 signals are scaled to 10 ms exposure time to be comparable to the signal in the large ROI1 readout. (This increases the bit resolution to 50 digits as seen in the plot.) The relative RMS noise level of the fast signal in one pixel (about 10%) appears to be much higher than in the slow signal. This is due to the fact that the sensor readout noise increases by a factor 2 due to subtracting two images, while the signal intensity is a factor f_{fast}/f_{slow} lower compared to the slow ROI. From the figure, it is clear that the noise level is the same during and after the discharge, which means it is dominated by sensor readout noise and not by photon statistics. This noise level is still low enough to be able to automatically detect significant light intensity changes through the event feature of EDICAM.
The image of one pixel in the plasma at the middle of the line of sight is about 1 mm. For fast monitoring purposes, it would be enough to integrate a larger area, about 1 × 1 cm. This is shown in Fig. 5(b), where a 10 × 10 pixel area is averaged. The noise level after the discharge clearly decreases compared to 1 pixel albeit not by a factor of 10 as one would expect if the noise in different pixels was uncorrelated. The reason is that some electronic noise is present in the analog signals from the sensor. The signal from 16 consecutive pixels is simultaneously sampled; this way the electronic noise is correlated between them. During the plasma discharge, the noise in the 10 × 10 pixels is not much smaller than for one pixel. Zooming into the signal, one sees that there is a systematic tendency that during one exposure cycle the signal drops. This is caused by the slight nonlinearity of the pixel signal as a function of integrated input light. The problem will be solved in the next version of the camera firmware by correcting for the nonlinearity of the pixel values using a lookup table. In addition to this tendency, the signal also shows some systematic time evolution which will be analyzed below.
B. Measurement of fast phenomena
In this section, we demonstrate the EDICAM camera functionality for analyzing fast events by investigating the plasma breakdown. This happens on a time scale of a few ms; thus, the 100 Hz full overview ROI cannot capture details. Although the two fast ROIs were not set up specifically to measure the breakdown, they were still found useful for this measurement. Figure 6 shows an example. The first three images in the bottom row show the differential images measured by the two fast ROIs, which is light collected in 200 μs time intervals. They digitize the image exactly at the same time with 200 μs time step; therefore, they can be plotted on the same image. The light intensity changes only on a ms time scale and therefore only every 5-th image is shown. As it is seen, the light intensity shows higher intensities in the upper right and lower left corners which increase on a few ms time scale. The fourth image is the first full ROI on which the breakdown has an effect at 0.06 s. This clearly shows that the two corners are on two filaments which are on the flux surface where the electron cyclotron heating initiates breakdown. To analyze the process in somewhat more detail, a series of 13 × 13 pixel rectangular measurement points were placed into the image (marked by the red line) and the light intensity averaged in them. These signals are shown in the surface plot above the images. Indeed the intensity increases faster in the two filaments and diffuses with some delay into the area between them. Due to the complicated magnetic field structure of the stellarator, it is difficult to extract more information from these measurements, but in the next campaigns, it would be possible to place small ROIs to different places on the filaments and study the time evolution of the breakdown in more detail.
Although this measurement clearly shows how fast measurement with slow monitoring can be combined in EDICAM it has one disadvantage. During the ∼2 ms readout time of the full image, the small ROIs cannot be read out. If the breakdown happens in this time period, at least part of it will be missed by the camera. However, this can be circumvented if the full ROI is defined initially as inactive and it is switched to active by the light intensity seen by fast ROI which can be set up in the area where the breakdown is expected. With this scheme, the startup phase of the breakdown can be measured and overview monitoring started after the breakdown happened. The fast breakdown ROI can also be set up to stop after a certain time, thus not producing unnecessary data.
C. Filament measurements
During the first OP1.1 W7-X campaign, a fast CMOS camera (Photron SA5) was also installed in one of the AEQ ports at the end of an imaging light guide [15]. To maximize light intensity in the second part of the operation, the camera was relocated to the port where no pinhole was installed. Measurements with 50 kHz frame rate revealed filamentary structures [15] at the plasma edge when the light intensity was high due to local gas puffs or strongly radiating edges. The filament lifetimes were found to be 100–200 μs and they were seen to propagate poloidally. Although the origin of these structures in not clear yet, their power spectrum and spatial structure resemble poloidally propagating filaments observed in the scrape-off layer of Wendelstein 7-AS [16,17] and tokamaks.
As the EDICAM system is capable of measuring fast changes in parallel to the slow monitoring, an attempt was made to detect these filamentary structures. As they are expected to have long toroidal extent, an experiment is analyzed where two EDICAM cameras (AEQ40 and AEQ50, see Fig. 1) were operated with the same settings. The two cameras look into neighboring modules in the same clockwise direction as viewed from above the W7-X torus. Timing is the same as in the breakdown measurement above: a full ROI is read at the end of the 10 ms exposures and two fast ROIs are sampled periodically at 5 kHz. 10 × 10 pixel measurement areas are set up on both camera images inside the fast ROI areas in the inner edge of the bright edge area as shown in Figs. 7(a) and 7(b). The measurement areas are numbered from the top down on the image, and area 1 is marked.
Signals are constructed from the mean intensity in the measurement areas. The timing is the same as in Fig. 4. As the two fast ROIs are set up in the non-persistent mode, the fast readouts during the approximately 2 ms readout time of the full ROI (plus about 1.5 ms due to a problem in this version of the camera firmware) are cancelled. This means fast samples follow each other with 200 μs time difference for about 6.5 ms and no samples are present for about 3.5 ms. Power spectra are calculated for typically 100–200 ms long time intervals by dividing the full interval into about 6.5 ms pieces where a continuous signal is present (about 30 samples in each piece). A second-order polynomial is fitted and subtracted from these samples to remove the trend. Power spectra are calculated from the remaining signal and averaged for all the sub-intervals. The length of the sub-intervals and the trend removal means an effective high pass filter with about 300 Hz cutoff frequency. The Nyquist frequency of the measurement is 2.5 kHz.
Power spectra from selected measurement areas in the two cameras are shown in Figs. 7(c) and 7(d). One can identify a low frequency feature extending up to about 600 Hz and some signature of a higher frequency phenomenon. The spectral peak around 400 Hz is a result of the power increasing towards low frequencies and the effective 300 Hz high pass filter of the data evaluation method. The spectra are qualitatively similar to the spectra obtained from fast camera measurements although the amplitude ratio of the high and low frequency parts depends on the location in the plasma. For measurement areas placed outside of the bright edge region (not shown in the figures) either towards the plasma core or towards the wall, no such spectra are seen.
To demonstrate that these fluctuations are related to some physical phenomena and not of technical nature, the coherency and crossphase are calculated between signals obtained from various measurement areas in the two cameras. Significant coherency is found everywhere between neighboring measurement areas and the coherency decreases with distance. This feature is not seen after the plasma discharge or if at least one of the measurement areas is placed outside the bright edge stripe. Such coherency shows up even between certain measurement areas located in different cameras. An example is shown in Fig. 7(e). Significant coherency is found up to about 1 kHz, while above it, the coherency is around the significance level. The crossphase in Fig. 7(f) shows a clear linear change in frequency indicating about 100 μs delay between the two signals. No coherence is seen when the measurement area is moved to the upper ROI in AEQ50 although the autopower spectra in that region are similar to other regions. These observations indicate the fluctuations in the plasma have some three-dimensional structure, and they connect certain areas in the two neighboring modules. Similarities in the correlation length and power spectra indicate that the fluctuations seen by the EDICAM system most probably represent the low-frequency part of the filament activity seen in the fast camera measurement. Due to the complex geometry and large amount of data, a detailed correlation analysis is demanding and will be the subject of other publications.
V. CONCLUSIONS, COMPARISON WITH OTHER TECHNOLOGIES, AND OUTLOOK FOR FUTURE FUSION EXPERIMENTS
The first measurements with the EDICAM camera system on the W7-X stellarator confirmed that parallel operation of slow (10–100) Hz overview imaging and fast (sub-ms) monitoring of smaller areas is possible. The SNR of one monitored pixel (∼1 mm image) is about 10 which can be reduced to a few percent if image from an ∼1 cm region is integrated. This SNR is perfectly suitable for detecting hot-spots and triggering fast readout of dedicated areas which was the long-term aim of the development of EDICAM. Although such an event-related functionality has been tested in the laboratory in the first campaign of W7-X, it has not been tried yet.
Monitoring small areas with 5 kHz frame rate confirmed the capability of measuring fast phenomena like breakdown and filamentary structures at the plasma edge in agreement with dedicated fast camera measurements. Correlation of light fluctuations related to filaments has also been detected between measurements in neighboring modules clearly indicating that these structures have several meter toroidal extent. A more detailed analysis with better arranged multiple fast ROIs in many cameras should reveal the detailed geometry of these filaments. It will also be possible to increase the frame rate of the small ROIs to 10–15 kHz. The limitation for this fast imaging might be the expected lower edge radiation of the plasma with the installed divertor modules which might be to some extent overcome with localized gas puffs.
In this respect, it is worth comparing the EDICAM technology with alternative solutions, most notably splitting the light between multiple cameras and individual light sensors. One camera could be used for overview imaging, while the other one could be used for fast measurements. Cameras with several hundred thousand frame/second on small ROI are available commercially [15], which are well above the speed of the present EDICAM design. Indeed, such a solution would be appealing as much higher frame rates can be achieved if the light intensity is high enough. However, at low light levels, this would be of no use and would decrease the system flexibility. Another important aspect is that specialized fast cameras are not designed for real-time processing: data are stored in the camera memory and downloaded only after the measurements are finished. This means that the real-time reaction capability would be lost.
Based on the proven capabilities so far, several upgrades of the EDICAM firmware are already ongoing or being tested in order to be available for the 2017-2018 campaign. These involve the possibility of arbitrary shape ROIs which would allow an economical use of data bandwidth while monitoring a large portion of the plasma edge for filament activity. Differential ROI operation has been so far demonstrated offline, and it will also be available in real-time. A ROI with moving location is planned for measuring pellet injection. Concerning image quality, a nonlinearity correction through a lookup table and bad pixel and radiation effected pixel correction with median filtering is also a planned development. With these upgrades and some debugging of the camera firmware, the EDICAM system will be a basic diagnostic on W7-X providing overview of plasma shape, real-time response to increased plasma-wall interaction, and some physics measurements in parallel.
On the longer term, it would be desirable to change the sensor of the camera to improve sensitivity. Since the start of the EDICAM development about 10 years ago, CMOS sensor technology has seen tremendous improvement. Modern scientific CMOS (sCMOS) sensors have 5–20 times less noise and 3–5 times higher quantum efficiency which would hugely improve the SNR of an upgraded camera system. However, the non-destructive read operation capability, which is a key element in EDICAM, is missing from most of the modern sensors, therefore either a special sensor needs to be manufactured or the operation scheme of the camera needs to be changed. As the data transmission speeds and FPGA processing resources are also increased by factor of 5–10, it would be possible to build a new EDICAM with, e.g., 2 kHz full frame rate at 1 Mpixel or 1 kHz at 2 Mpixel. Reading the full frame at such frequencies and transmitting data over a 40–50 Gbit/s optical data link to a modern FPGA development board would allow accumulating long exposure images digitally and monitoring certain regions at the base frame rate. Although the SNR of long exposure images would be worse by factors of 3–10 than reading a single long exposure image, but the improved SNR of the sensor itself would provide a final SNR of long exposure images even better than with the present camera. Fast ROI monitoring, on the other hand, would have a much better SNR. This development process is already under consideration.
The next development step would be to add a second layer of processing on the image stream transmitted to the PC. This would be done at a higher level programming language like in the system described in Ref [18]. With this additional layer, the fast decisions would be still made by the IPCU but more complex algorithms could be implemented and modified to the changing needs by physicists without the need of complicated VHDL programming of the FPGA processor.
The first experiences with the W7-X camera system also give hints for the possible implementation and functions of similar camera systems on future long pulse fusion devices like ITER and JT-60SA. ITER is planned to have a similar equatorial overview camera system like W7-X consisting of 12–16 visible (plus the same number of infrared) cameras located in 4 ports [19]. The required pixel resolution of the visible cameras is expected to be between 2 and 8 Mpixel. 13 measurement functions are listed [19] for the visible camera system with temporal resolution requirements varying between 1 and 100 ms. Although the edge filament measurement is not considered, the first W7-X experiences clearly show that a camera system would be capable of this as well. Recently some concern has been raised [20] that filamentary transport on ITER might be in a regime where filaments travel to much longer distance and represent higher load to the low field side first wall than originally foreseen. If the light intensity allows, the ITER equatorial camera system might be capable of providing valuable information on filamentary transport. The planned setup of the ITER equatorial camera system also follows similar logic as the W7-X setup. Cameras are proposed to be installed in the port cells, where still some elevated level of radiation is expected. From there data would be transmitted to the data acquisition system located remotely. Although commercial cameras might fulfil the ITER requirements, it seems to be more reasonable to develop a special camera head for this purpose based on experiences to be gained on various presently operating systems. In this context, the W7-X overview camera system will serve as an excellent test bed.
FIG. 1. 
(a) Arrangement of the ten equatorial ports on the W7-X vacuum vessel used for the video diagnostic in Op1.1. Ports with even numbers look in the clockwise direction, while ports with odd numbers look in the counterclockwise direction. (b) Cross section of the port end.
FIG. 2. 
Example exposure and readout timing in EDICAM. The upper curve indicates signal in one pixel of the sensor as a function of time in response to a constant input light. The arrows below mark times when regions of interest (ROI1…ROI3) are sampled to analog storage registers and readout from them starts. The boxes indicate the times when the IPCU sends readout commands to the sensor and when the sensor data are read out and sent to the IPCU.
FIG. 3. 
A full image of camera AEQ50 with the 3 ROIs marked in discharge 20160310_165512. The image has 1280 columns and 1024 rows, but physically it is rotated by 90°.
FIG. 4. 
Time evolution of intensity in a single pixel during the startup phase of a discharge. The open red symbols are measured in ROI1, while the filled blue symbols are measured in ROI2. The dotted vertical lines indicate the start and stop of an exposure cycle. The solid yellow line represents the sensor reset signal (active 0).
FIG. 5. 
Time evolution of instantaneous light intensity scaled to 10 ms integration time averaged in 1 pixel (a) and 10 × 10 pixels (b) calculated from the difference of consecutive readouts. The black dots are from ROI2 data, while the red curve is from ROI1 data.
FIG. 6. 
Measurement of plasma breakdown. The pictures at the bottom show the plasma image in 1 ms time intervals. The first 3 images are from the two small ROIs, and the fourth image is the first full ROI. The red line marks a cut (series of test points) along which the light intensity is shown as a function of time on the upper plot (measurement AEQ50_edi_20160310_133037).
FIG. 7. 
[(a) and (b)] Images from two EDICAM cameras in discharge 20160310.25 at 0.3 s with the outlines of the two fast ROIs and the measurement areas. The red filled measurement areas are used for the spectrum calculations. [(c) and (d)] Power spectra of the marked measurement areas. Panels (e) and (f) show the coherency and crossphase of the signals in the measurement areas in the two cameras. The horizontal line in the coherency marks the confidence level.
