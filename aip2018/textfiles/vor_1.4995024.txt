The KAM approach to the localization in â€œhaarschâ€ quasi-periodic media
We propose a Kolmogorov-Arnoldâ€“Moser type approach to the spectral analysis of lattice SchrÃ¶dinger operators with quasi-periodic potentials. In the strong disorder regime, we prove uniform exponential localization and establish measure-theoretic bounds on the â€œresonantâ€ sets which are substantially stronger than in prior studies on localization in deterministic disordered environments.
I. INTRODUCTION
We study spectral properties of finite-difference operators, usually called lattice SchrÃ¶dinger operators (LSOs), acting in the Hilbert space H=â„“^{2}(Z^{d}),
where Ï‰ and Ï‘ are the parameters, the roles of which are as follows:
â€¢ Ï‰âˆˆÎ©â‰”T^{Î½}=R{Î½}/Z{Î½}â‰…0,1{Î½}, Î½ â‰¥ 1;
â€¢ T:Z{Î½}Ã—Î©â†’Î© is a (conservative) dynamical system;
â€¢ Ï‘ âˆˆ Î˜, where (Î˜,B,P^{Î˜}) is an auxiliary probability space.
The amplitude Îµ > 0 of the kinetic energy operator is assumed to be small.
The dynamical system T leaves the parameter Ï‘ âˆˆ Î˜ invariant, so the latter labels the operator ensembles {H_{Îµ}(Ï‰, Ï‘), Ï‰ âˆˆ Î©}. In the present paper, the function v:Î©â†’R, which we will call the hull of the deterministic potential V, is expanded in an orthogonal series over a basis {Ï•_{n}} in L^{2}(Î©), with coefficients considered as independent parameters
Then one can actually identify Ï‘ with the collection of the coefficients {c_{n}(Ï‘)} and introduce in an appropriate way the structure of the measure (e.g., probability) space in the set of all such collections. The motivation for such an approach was explained in our earlier studies [7,9]. The analysis carried out in Ref [9] strongly suggested using a direct perturbative approach to the phenomenon of exponential decay of the eigenfunctions for the operator ensembles considered there, without using first the Multi-Scale Analysis (MSA) of the Green functions. The efficiency of such a direct approach was demonstrated by Sinai [16], who used instead a variant of the Kolmogorov-Arnoldâ€“Moser (KAM) technique. The main goal of the present paper is to extend the KAM method to a class of deterministic operators featuring a very strong form of the Anderson localization, often referred to as the ULE (Uniform Localization of Eigenfunction) property.
The KAM approach to the localization analysis of quasi-periodic operators was used by Bellissard et_al [3]; it actually pre-dates the MSA (cf. Refs [17] and  [13]). Recently, Imbrie [14] used a similar KAM-type technique for the proof of Anderson localization in a random potential on a lattice Z^{d}. As in Ref [3], he makes at each induction step a unitary transformation of an approximate eigenbasis (AEB) so that every AEB is an orthogonal basis in â„“^{2}(Z^{d}). The orthogonality is of course a very welcome feature in the context of a technically involved perturbative spectral analysis. However, the quantitative measure-theoretic control of the small denominators, the well-known Achilles heel of the KAM techniques, becomes quite difficult in the situation where the new AEB is made orthogonal, for it requires to control perturbation diagrams of all orders at once, ultimately making the inductive procedure very complex. Apparently, there is no ideal solution to this dilemma; in the present paper, we follow the path laid down in Sinaiâ€™s work [16] and make a compromise: the AEBs are not required to be exactly orthogonal, but they are composed of compactly supported functions, which makes â€œlocalâ€ their dependence upon the phase variable Ï‰âˆˆÎ©=T^{Î½}. A local dependence of the approximate eigenvalues (AEVs) significantly simplifies the control of small denominators. In particular, we do not have to prove a Wegner estimate as such, for some local Hamiltonians, albeit we exploit some more elementary mechanisms which can in principle be used for a derivation of a simpler (and weaker, non-optimal) variant of the Wegner estimate (cf. Ref [8]).
Compared to the multi-scale analysis of the deterministic operators with â€œhaarschâ€ potentials, the KAM approach proposed in the present work gives stronger bounds on the measure of the unwanted subsets in the parameter space for which the localization analysis is inconclusive. Specifically, these bounds, which are akin to the more traditional probability bounds used in the MSA of random operators, rapidly decay with respect to the length scales {L_{j},jâˆˆN}. The rate of decay of such bounds as L_{j} â†’ âˆ affects the decay of the averaged eigenfunction correlators. A genuine exponential decay of the latter, as is well-known, cannot be proved by the existing techniques of the MSA; in a number of models, it requires the Aizenmanâ€“Molchanov method (or Fractional Moments Method, FMM) [1,2]. Unfortunately, the FMM does not apply to the deterministic operators (at least, no such modification is known today), so the present paper aims to fill the gap. Admittedly, we make here only a first step, and in a more general context of deterministic operators, one has to address the issue of â€œresonances,â€ as in the models with a random (e.g., an IID) potential. The non-resonant nature of the potentials considered below provides a convenient â€œlaboratoryâ€ where the functional-analytic aspects of the KAM method based on the approximate eigenfunctions can be easily illustrated.
It is instructive to compare the above results to those proved by Bourgain and Goldstein [4] for individual hulls. Assuming the hull v:T^{Î½}â†’R to be analytic in a complex neighborhood of the torus, the authors of Ref [4] proved complete localization for any fixed hull v, but for Îµâˆˆ0,Îµ{0}(v) with some Îµ_{0}(v) small enough. Our extended phaseÃ—parameter space analysis shows that without the analyticity condition, the onset of a uniform (in Ï‰ âˆˆ Î©) Anderson localization is guaranteed for P^{Î˜}-almost every choice of the Fourier coefficients of the hull v with respect to the standard Haar basis on T^{Î½}, but again for Îµ > 0 small enough. Obviously, for a fixed Îµ > 0, some hulls v (but not Ï‰) are to be excluded, as suggests the example of the Almost Mathieu operator featuring the metal-insulator transition (cf. the work by Jitomirskaya [15] and the bibliography therein). As to the phenomenon of uniform (and not just semi-uniform) decay of the localized eigenfunctions, we mention the studies by Damanik and Gan [11,12] who considered the case of the limit-periodic potentials.
A more detailed discussion of prior results and alternative techniques can be found in Ref [9]; in particular, we refer an interested reader to the studies [5,6,11,12,15].
A. Requirements for the dynamical system
For clarity of presentation, we consider only the case where the phase space of the underlying dynamical system is Î©=T^{Î½}, Î½ â‰¥ 1, although the principal technique of the small denominators analysis can be adapted to a much larger class of deterministic dynamical systems, satisfying the conditions of uniform polynomial aperiodicity [(UPA), cf. (1.2)] and tempered local divergence of trajectories [cf. condition (DIV) in Ref [9]]. We endow Î©=T^{Î½}=R{Î½}/Z^{Î½} with the distance dist_{Î©}[Ï‰â€², Ï‰â€³] inherited from the max-distance in R^{Î½},
The dynamical system T:T^{Î½}Ã—Z^{d}â†’T^{Î½} is given by the translations of the torus, T^{x}Ï‰ = Ï‰ + x_{1}Î±_{1} + â‹¯ + x_{d}Î±_{d}, Î±_{i}âˆˆT^{Î½}, xâˆˆZ^{d}, and we assume that the frequency vectors Î±_{i} are chosen so that T fulfills the uniform power-law aperiodicity (diophantine) condition of the form
(UPA)âˆƒA,C_{A}âˆˆN{*}âˆ€Ï‰âˆˆÎ©âˆ€x,yâˆˆZ^{Î½}â€‰withâ€‰xâ‰ y,
Notice that the condition (DIV) assumed in Ref [9] is trivially fulfilled since the translations of the torus are isometries. This simplifies some technical moments of the geometrical constructions in Sec. II.
B. Randelette expansions
In Ref [7], we introduced parametric families of ergodic ensembles of operators {H(Ï‰; Ï‘), Ï‰ âˆˆ Î©} depending upon a parameter Ï‘ âˆˆ Î˜ in an auxiliary space Î˜. As shown in Ref [7], it is convenient to endow Î˜ with the structure of a probability space, (Î˜,B,P^{Î˜}), in such a way that Ï‘ is, in fact, an infinite family of IID random variables (r.v.) on Î˜, providing an infinite number of auxiliary independent parameters allowing to vary the hull v(Ï‰, Ï‘) locally in the phase space Î©.
In the framework of the LSO, we proposed in Ref [7] a more specific construction where H(Ï‰; Ï‘) = H_{0} + V(â‹…; Ï‰, Ï‘), with V(x; Ï‰, Ï‘) = V(T^{x}Ï‰, Ï‘) and
where {Ï‘_{n,k}, n â‰¥ 0, 1 â‰¤ k â‰¤ K_{n}} are IID random variables on Î˜, and Ï†_{n,k} â‰” (Ï†_{n,k}), n â‰¥ 0, 1 â‰¤ k â‰¤ K_{n} < âˆ are some functions on the phase space Î© of the underlying dynamical system T^{x}. Series of the form (1.3) were called in Ref [7]randelette expansions, referring to the â€œrandomâ€ nature of the expansion coefficients and to the shape of Ï†_{n,k} reminding the wavelets (â€œondelettes,â€ in French). An interesting case is where the randelettes are simply Haar wavelets with coefficients considered, formally, as independent random variables relative to an auxiliary probability space (Î˜,B,P^{Î˜}). For example, if Î©=T^{1}=R/Z, for n = 0 we set K_{0} = 1, Ï†_{0,1}(Ï‰) = 1, and for n â‰¥ 1, 1 â‰¤ k â‰¤ K_{n} = 2^{n},
where
so suppÏ†_{n,k}=C_{n,k}â‰”Cn,k+âˆªCn,kâˆ’. On the torus T^{Î½} with Î½ > 1, the functions Ï†_{n,k} are the tensor products of the one-dimensional Haarâ€™s wavelets, and C_{n,k} â‰” suppÏ†_{n,k} are cubes in T^{Î½} of side length 2^{âˆ’n}, of the form C_{n,k}=â˜“j=1Î½k_{j}2^{n},k_{j}+12^{n}. These cubes define a partition of T^{Î½} which we denote by C_{n}. Each of these cubes is partitioned into 2^{Î½} sub-cubes of side length 2^{âˆ’nâˆ’1}, {C_{n,k;i}, i = 1, â€¦, 2^{Î½}}, on which Ï†_{n,k} takes a constant value Â±1; we denote this value by s_{n,k}(Ï‰)âˆˆ{âˆ’1,+1} so that
Clearly, the cubes C_{n,k;i} are elements of the finer partition C_{n+1}. Indeed, similar to (1.4), we have
where the combinations of the shifts l_{j;i} determine sign(s_{n,k}(â‹…)).
Next, consider a family of IID random variables Ï‘_{n,k} on an auxiliary probability space (Î˜,B,P^{Î˜}), uniformly distributed in [0, 1], and let a_{n}=2^{âˆ’2bn2},nâ‰¥1,b>0, with b > 0 to be specified later, and define a function
which can be viewed as a family of functions v_{ğœ—}(â‹…)=v(â‹…,ğœ—):T^{Î½}â†’R, parameterized by Ï‘ âˆˆ Î˜ or as a particular case of a â€œrandomâ€ series of functions, expanded over the given system of functions Ï†_{n,k} with â€œrandomâ€ coefficients. Following Ref [9], we call the expansions of form (1.5) â€œhaarshâ€ randelette expansions.
C. Main result
Theorem 1. Consider a family of lattice SchrÃ¶dinger operators inâ„“^{2}(Z^{d}), H_{Îµ}(Ï‰, Ï‘) = ÎµÎ” + V(x; Ï‰, Ï‘) [cf. (1.1)], where V(x; Ï‰, Ï‘) = v(T^{x}Ï‰, Ï‘) withv(Ï‰, Ï‘) given by the expansion (1.5), and the dynamical system T satisfies(UPA). There exists Îµ_{0} âˆˆ (0, +âˆ) such that for any Îµ âˆˆ (0, Îµ_{0}), there exists a subset Î˜^{âˆ}(Îµ) âŠ‚ Î˜ withP^{Î˜}Î˜^{âˆ}(Îµ)â†‘1as Îµ â†“ 0 and with the following property: if Ï‘ âˆˆ Î˜^{âˆ}(Îµ), then foranyÏ‰ âˆˆ Î©:
(A) H_{Îµ}(Ï‰, Ï‘) has pure point spectrum;
(B) for anyxâˆˆZ^{d}, there is exactly one eigenfunction Ïˆ_{x}(â‹…; Ï‰; Ï‘) such that
i.e., Ïˆ_{x}has the â€œlocalization centerâ€ x, so there is a natural bijection between the elements of the eigenbasis {Ïˆ_{x}(â‹…; Ï‰, Ï‘)} and the latticeZ^{d};
(C) for allxâˆˆZ^{d}, the eigenfunctions Ïˆ_{x}decay uniformly away from their respective localization centers
We will derive the assertions of Theorem 1 from the results of the KAM scale induction, in Sec. IV.Note that the simplicity of spectrum in our model was established in Ref [9].
II. PHASE SPACE ANALYSIS AND SPECTRAL SPACINGS
Similar to the studies [3,9], we establish a complete localization of the eigenfunctions of H_{Îµ}(Ï‰, Ï‘) for every (and not just almost every) phase point Ï‰âˆˆÎ©â‰¡T^{Î½}. As stated in the inductive hypothesis K(L_{j}) (cf. Sec. III), each induction step can be carried out for all Ï‰ âˆˆ Î© but only outside a subset of Î˜ of small P^{Î˜}-measure: the smaller Ïµ > 0, the smaller is the measure of the excluded subset of Î˜. In other words, for P^{Î˜}-almost every Ï‘ âˆˆ Î˜, there exists Ïµ_{â—‹}(Ï‘) > 0 such that for Ïµâˆˆ0,Ïµ_{â—¦}(ğœ—), the operator ensemble H_{Îµ}(â‹…, Ï‘) on the phase space of the ergodic dynamical system T features a uniform (and not just semi-uniform) complete Anderson localization with unimodal [cf. assertion (C) of Theorem 1], exponentially decaying eigenfunctions.
In the present section, we prepare the ground for the main measure-theoretic estimate (in the parameter space Î˜) required for the KAM induction, but it would be premature to formulate the final technical result here, in an encapsulated form, since a number of related objects will appear in Sec. III.
T-covariance. Below we often refer to the following notion.
Definition 2.1. Let be given a dynamical system T:Z^{d}Ã—Î©â†’Î©, an arbitrary set A, and an action S of the abelian group Z^{d} on A, i.e., a homomorphism S:Z^{d}â†’Aut(A) of Z^{d} into the group of transformations of A. A mapping F:Z^{d}Ã—Î©â†’A is called T-covariant iff
Specifically, we will need the following three categories of covariant mappings:
(i) scalar functions Î»:(x,Ï‰)â†¦Î»_{x}(Ï‰)âˆˆC satisfying
(ii) vector-valued mappings f: (x, Ï‰) â†¦ f_{x}(â‹…, Ï‰) with values in â„“^{2}(Z^{d}) so that a function y â†¦ f_{x}(y, Ï‰) with fixed x and Ï‰ is square-summable and satisfies
(iii) matrix-valued mappings F:Z^{d}Ã—Î©â†’Mat(Z^{d}) constant in the first argument (ranging in Z^{d}) so that its matrix elements F_{x,y}(z, Ï‰) â‰¡ F_{x,y}(0, Ï‰) satisfy
Item (ii) corresponds to the eigenfunctions Ï•_{x}, which will be proved to be square summable, and even uniformly exponentially decaying away from their individual â€œlocalization centersâ€ xâˆˆZ^{d}; (i) corresponds to the eigenvalues Î»_{x} associated with Ï•_{x}. The last category (iii) covers the case of the deterministic matrices (Hamiltonians) H_{Îµ}(Ï‰) and various intermediate matrices used in the construction of approximate eigenbases. In fact, all three categories of covariant objects will depend upon a measurable parameter Ï‘, but since the latter is not affected by the underlying dynamical system, we do not mention it in the above definition of covariance.Local dependence and stochastic support. The starting point for the KAM procedure is an observation that the original, canonical delta-basis in Z^{d} is an approximate eigenbasis for the operator H_{Îµ} = ÎµÎ” + V, with accuracy of order OÎµ, and the approximate AEVs Î»x0=V(x;Ï‰) exhibit local dependence upon the values of the potential: each Î»x0 is measurable with respect to the sigma-algebra generated by a single r.v. V(x; Ï‰). This renders explicit and simple the control of the first-order small denominators Î»x0âˆ’Î»y0â‰¡V(x;â‹…)âˆ’V(y;â‹…) appearing in the KAM procedure, in the course of the construction of the approximate EFs of order 1.
Definition 2.2. Let be given a measurable mapping f from the space MZ^{d}diag of diagonal matrices Î›=diag(Î»_{x},xâˆˆZ^{d}) to some measurable space (A,B). The stochastic support of f, denoted S(f), is the minimal subset SâŠ‚Z^{d} such that f is measurable with respect to the sub-sigma-algebra F_{S} generated by the cylinder sets L_{x,t}â‰”{Î›âˆˆMZ^{d}diag:Î»_{x}â‰¤t}, xâˆˆS, tâˆˆR.The most important consequence of the finiteness (and uniform boundedness) of the stochastic support of the AEVs will be the following property: at each step j â‰¥ 0, the differences Î»xjâˆ’Î»yj (hence the respective small denominators) for all yâˆˆB_{CLj}(x) are invariant under the local transformations
We shall see that the latter property allows one to trace the origins of the abnormally small denominators back to the random potential, which is by far simpler a task than the analysis of highly implicit AEVs for j â‰« 1. The parametric bound on the set of the unwanted hull samples obtained in this way provides a satisfactory substitute for the usual Wegner bound.Randelette expansions. We always assume the phase space Î© of the underlying dynamical system to be the torus T^{Î½} of dimension Î½ â‰¥ 1: T^{Î½}=R{Î½}/Z^{Î½}â‰…0,1{Î½}. For each n â‰¥ 0, we have introduced the family of K_{n} = 2^{Î½n} cubes C_{n,k}, k = 1, â€¦, K_{n}, of side length 2^{âˆ’n}, and the functions Ï†_{n,k} with suppÏ†_{n,k} = C_{n,k}. For every n â‰¥ 0, the supports {C_{n,k} = suppÏ†_{n,k}, 1 â‰¤ k â‰¤ K_{n}} naturally define a partition of the phase space Î©,
These partitions form a monotone sequence: C_{n+1}â‰ºC_{n}, i.e., each element of C_{n} is a union of some elements of the partition C_{n+1}. Given n â‰¥ 0, for each Ï‰ âˆˆ Î©, we denote by k^{n}(Ï‰) the unique index such that Ï‰âˆˆC_{n,k^n(Ï‰)}. For each N â‰¥ 0, introduce the approximant of v(Ï‰, Ï‘) given by (1.3),
the truncated potential V_{N} and the truncated Hamiltonian HÎµ(N),
For any N â‰¥ 0, denoting â€–fâ€–{âˆ}â‰”supÏ‰âˆˆÎ©â€–f(Ï‰,â‹…)â€–{L^{âˆ}(Î˜)}, we have
It is important that the RHS is much smaller than the width (a_{N}) of the distribution of random coefficients a_{N}Ï‘_{N,k}, 1 â‰¤ k â‰¤ K_{N} (recall: Ï‘_{N,k} âˆ¼ Unif[0, 1]). (This is why we assumed a_{n} to be decaying faster that exponentially.) Set
with AÌƒ>0 chosen so that 2^{âˆ’NÌƒ(L)}=2^{âˆ’AÌƒlnL}<CAâˆ’1L^{âˆ’2A}. Then for any uâˆˆZ^{d} and Ï‰ âˆˆ Î©, all the phase points {T^{x}Ï‰,xâˆˆB_{L^{2}}(u)} are separated by the elements of the partition C_{NÌƒ(L)} (of size 2^{âˆ’NÌƒ(L)}) since by (UPA) and the choice of AÌƒ and NÌƒ,
For further use, introduce the sigma-algebras BNâŠ¥ generated by the r.v.,
Conditional on BNâŠ¥, each value of the potential V(Ï‰, Ï‘) with a fixed Ï‰âˆˆT^{Î½} is an affine function of some Ï‘_{n,k} with k = k(Ï‰). This significantly reduces the randomness in V(Ï‰, Ï‘) but renders much simpler and transparent the analysis of regularity of its probability measure.Fix a length scale L_{j}, j â‰¥ 0, let
and partition Î©=T^{Î½} into a union of N_{Rj} adjacent cubes Q_{Rj}(Ï‰_{i}), iâˆˆã€š1,N_{Rj}ã€›, of size R_{j} with centers Ï‰_{i} forming a periodic grid including 0âˆˆT^{Î½}. Similarly, partition Î© into adjacent cubes Q_{rj}(Ï‰Ìƒ{i^{â€²}}) of size r_{j}=Lj6A{âˆ’1}.
Lemma 2.1. Fix any j â‰¥ 0. The boundaries of the cubesT^{âˆ’z}Q_{Rj}(Ï‰_{i})withzâˆˆB_{Lj2}(0)partition each cubeQ_{rj}(Ï‰Ìƒ{i^{â€²}})into at most 2^{Î½}parallelepipedsQ^{j,i^{â€²},k}, 1â‰¤kâ‰¤K^{j,i^{â€²}}â‰¤2^{Î½}.
Proof. (cf. Fig. 1) Let S_{a}={Ï‰âˆˆT^{Î½}:Ï‰_{a}â€‰modâ€‰R_{j}=0},1â‰¤aâ‰¤Î½. Equivalently, S_{a} is the union of the faces of all cubes Q_{Rj}(Ï‰_{i}) parallel to the a-th coordinate hyperplane in the torus (with identification T^{Î½}â‰…0,1{Î½}âŠ‚R{Î½}). Let us show by contraposition that (UPA) implies that for each aâˆˆã€š1,Î½ã€› the images {T^{âˆ’z}S_{a}} cannot hit more than once any given cube of size R_{j}.
Assume otherwise; then there are two distinct points x^{â€²},x^{â€³}âˆˆB_{Lj2}(0) such that T^{âˆ’xâ€²}S_{a}, T^{âˆ’xâ€³}S_{a}âˆˆQ_{Rj}(Ï‰) for some Ï‰. Consequently, for some KâˆˆZ,
hence with the integers M^{â€²}=Rjâˆ’1xaâ€², M^{â€³}=Rjâˆ’1xaâ€³, M â‰” Mâ€² âˆ’ Mâ€³ â‰  0, |M|â‰¤2Lj2, we have MÏ‰_{a} = Ï± + K, where KâˆˆZ and
On the other hand, by (UPA) we have
which contradicts (2.2) (for L_{0} large enough). Thus Î½ (or less) hyperplanes partition a cube into a union of at most 2^{Î½} parallelepipeds.
With Lâ†¦NÌƒ(L)=AÌƒlnL, introduce the integers
Let P_{j,l},1â‰¤lâ‰¤Ljâ€²â‰”âˆ‘_{i^{â€²},k}K^{j,i^{â€²}} be the collection of all partition elements Q^{j,i^{â€²},k} with a fixed j, numbered in some way. For each fixed zâˆˆB_{Lj2}(0) and P_{j,l}, the phase point T^{z}Ï‰ staying inside a given parallelepiped P_{j,l} cannot cross the boundary of any cube Q_{j,i^{â€²}}. Therefore, we come to the following simple
Corollary 2.1. For anyjâˆˆN, there exists a finite measurable partition ofÎ©=T^{Î½}, P_{j}=P_{j,l},1â‰¤lâ‰¤L_{j}such that for each element P_{j,l}, the collection of random variables indexed byzâˆˆBL_{j}2(0),
is constant (as a collection-valued function of Ï‰) on P_{j,l}.One can formulate the above result in the following way. Pick one representative Ï„_{j,l} âˆˆ P_{j,l} per element P_{j,l}. Then we see that there are a finite number of possible random functions
Lemma 2.2. Let be given L_{j}and two functionalsa^{â€²},a^{â€³}:Vâ†¦Ron the functionsV:Z^{d}â†’Rsatisfying for some finite subsetsÎ›^{â€²},Î›^{â€³}âŠ‚Z^{d},
Assume that Î›â€² âˆ© Î›â€³ = &emptyv;andÎ›^{â€²}âˆªÎ›^{â€³}âŠ‚B_{Lj4}(0). Let V(x; Ï‰, Ï‘) = v(T^{x}Ï‰, Ï‘), xâˆˆZ^{d}, and consider two r.v.Î¶^{â€²}(Ï‰,ğœ—)=a^{â€²}[V(â‹…;Ï‰,ğœ—)], Î¶^{â€³}(Ï‰,ğœ—)=a^{â€³}[V(â‹…;Ï‰,ğœ—)]. Then for some C, C_{1} âˆˆ (0, +âˆ), one has
Proof. Let Î˜_{j,Ïµ} be the event figuring in (2.6), then it follows from (2.4) that
Fix any point Ï„_{i,l}âˆˆT_{j}, so the only randomness left is due to Ï‘ âˆˆ Î˜. The sample V_{Î›^{â€²}}={V(x;Ï„_{i,l},â‹…),xâˆˆÎ›^{â€²}} (relative to the probability space Î˜) is independent from a similarly defined sample V_{Î›^{â€³}}. Each of the two samples has independent, albeit possibly differently distributed, random variables (r.v.). By construction, each r.v. v_{NÌƒ}(T^{z}Ï„_{i,l},ğœ—) has a uniform distribution on an interval of length a_{NÌƒ}. In other words, the probability distribution of the sample V_{Î›^{â€²}} is a normalized Lebesgue measure on a cube of side length a_{NÌƒ} in R^{Î›â€²}. Let
and similarly define Î¾â€³(Ï‘), Î·â€³(z, Ï‘) replacing Î›â€² by Î›â€³. It is readily seen that the distribution of Î¾â€² conditional on (Î·â€²(z, Ï‘), z âˆˆ Î›â€²} is again a uniform distribution on Î·â€²-dependent interval, except for the degenerate cases where the interval in the question is reduced to a single point or is empty.Next, conditional on V_{Î›^{â€³}}, thus rendering a^{â€³}(Ï‰) non-random. Then (2.5) implies that a^{â€²}, as a functional of Î¾â€² and of Î·â€², satisfies a^{â€²}(ğœ—)=c^{â€²}[Î·^{â€²}(ğœ—)]+Î¾^{â€²}(ğœ—) so with a^{â€³}, Î·â€² fixed by conditioning, and some conditionally non-random cÌƒ,
Now the claim follows from Lemma 2.3.
Lemma 2.3 (Cf. Ref [10], Lemma 6.1). Let be given IID random variables X_{1}, â€¦, X_{n}with uniform distribution Unif[0, â„“], â„“ > 0 and denoteÎ¾_{n}â‰”n^{âˆ’1}âˆ‘i=1nX_{i}, Î·_{i} â‰” X_{i} âˆ’ Î¾_{n}, iâˆˆ[[1,n]], Î·(Ï‰) = (Î·_{1}(Ï‰), â€¦, Î·_{n}(Ï‰)). For any Borel functionÎ»:R{n}â†’R, one has
Remark 1. We state Lemma 2.3 the way it is given in Ref [10], but it easily adapts to a more general case where X_{i} are independent random variables with individual uniform distributions Unif[a_{i}, a_{i} + â„“], with arbitrary a_{i}âˆˆR. Indeed,
â€¢ the transformation X_{i}â†¦XÌƒ{i}=X_{i}âˆ’a_{i}, Y_{i} = Î·_{i} âˆ’ Î·_{n}, iâˆˆã€š1,nâˆ’1ã€›, gives IID random variables distributed in [0, â„“];
â€¢ all the differences Y_{i} = Î·_{i} âˆ’ Î·_{n}, iâˆˆã€š1,nâˆ’1ã€› remain invariant;
â€¢ the families of random variables {Î·_{1}, â€¦, Î·_{n}} and {Y_{1}, â€¦, Y_{nâˆ’1}} generate the same Ïƒ-algebra since Î·_{1} + â‹¯ + Î·_{n} = 0.Therefore, any measurable function of Î·(Ï‰) is also a measurable function of Y(Ï‰) = (Y_{1}(Ï‰), â€¦, Y_{nâˆ’1}(Ï‰)) and vice versa.It is worth noticing that some technical calculations, required in the case of uniformly distributed IID samples, become unnecessary in the prototypical case of Gaussian IID samples, for in this case the r.v. Î¾ is independent of Î·_{1}, â€¦, Î·_{n} [so we can condition on Î· in (2.7)] and it has a Gaussian density bounded by On^{1/2}, resulting in an even stronger Lipschitz-type bound than (2.7). This simple observation made in Ref [8] was the initial motivation for Ref [10].
III. THE KAM INDUCTION
We use the norms defined for the functions on Z^{d} and for the matrices A_{x,y} with entries indexed by x,yâˆˆZ^{d},
Note that for fixed m > 0, all the weighted norms âˆ¥â‹…âˆ¥_{m,x} are equivalent, and one has â€–â‹…â€–{m,x}â‰¤â€–â‹…â€–{m^{â€²},x} for 0 â‰¤ m â‰¤ mâ€². With m = 0, we obtain the conventional norm of â„“^{2}(Z^{d}). The use of such norms in the KAM approach to localization goes back to Ref [3].
Apart from the m-norm for matrices (Ayx){y,xâˆˆZ^{d}} measuring the decay of their entries away from the diagonal, we shall also use sometimes a cruder characteristic of finite-band matrices which we call the spread of a matrix A, denoted SPRA,
If A is not a finite-band matrix, its spread is infinite, but we do not encounter such situations. This meaning of the word â€œspreadâ€ is not traditional (usually it refers to the distances between the respective eigenvalues), but we use it here occasionally, solely for the sake of terminological brevity.
We work with a sequence of growing length scales {L_{j},jâˆˆN} of the form L_{j} = L_{0}Y^{j}, YâˆˆN{*}, and introduce a rapidly decaying positive sequence
measuring the accuracy of the approximate eigenfunctions and eigenvalues. The small denominators will be controlled with the help of another sequence Î´_{j}â†“ 0. The techniques of Sec. II allow us to assume, at the price of choosing the disorder amplitude |g| large enough, that Î´_{j}â‰¥Ïµja with an arbitrarily small a > 0. We often make use of popular notations such as A = t^{b+} and B = t^{bâˆ’}, for t â‰ª 1 or t â‰« 1, meaning that A can actually be replaced by Const t^{a+Î±} with Î± > 0 that can be chosen as close to 0 as one pleases; respectively, B can be replaced by Const t^{bâˆ’Î±} with an arbitrarily small Î± > 0. With this notation, Î´_{j}â‰¥Ïµj0+. A rapid decay of the size of tolerated â€œresonancesâ€ is a distinctive and valuable feature of the KAM procedure.
Now we shall list the inductive hypotheses; this list is rather long, which is not unusual for the KAM method, but it has the advantage to provide a constructive two-page summary of the proof of the main result, along with a detailed technical information that can be used in further studies.
Recall: AEV and AEF stand for â€œapproximate eigenvalue(s)â€ and, respectively, â€œapproximate eigenfunction(s).â€
Inductive hypothesis K(L_{j}): For all 0 â‰¤ i â‰¤ j, there exists a measurable subset [18]Î˜Ìƒ{i}âŠ‚Î˜ with P^{Î˜}Î˜Ìƒ{i}â‰¥1âˆ’Ïµi0+ such that for all ğœ—âˆˆÎ˜^{j}â‰”âˆ©i=0jÎ˜Ìƒ{i} are well-defined the following objects:
(K1) a T-covariant vector-valued mapping Ï•â€¢i:Z^{d}Ã—Î©Ã—Î˜^{i}â†’â„“^{2}(Z^{d}),
(K2) a T-covariant real-valued mapping Î»â€¢i:Z^{d}Ã—Î©Ã—Î˜^{i}â†’R,
(K3) a T-covariant vector-valued mapping Ïˆâ€¢i:Z^{d}Ã—Î©Ã—Î˜^{i}â†’â„“^{2}(Z^{d}),
(K4) The matrix with columns given by the vectors Ï•â€¢i,
has the form U^{j}=1+D^{j}Ìƒ, with
U^{i}(Ï‰, Ï‘) is therefore boundedly invertible by the Neumann series, and so its column vectors {Ï•xi,xâˆˆZ^{d}} form a Riesz basis in â„“^{2}(Z^{d}).The following relations hold, for all 0 â‰¤ i â‰¤ j:
(K5) the vectors Ï•xi(Ï‰,ğœ—) form an approximate covariant eigenbasis (ACE) for the operator H_{Îµ}(Ï‰, Ï‘), with AEV Î»xi(Ï‰,ğœ—) and discrepancy Ïˆxi(Ï‰,ğœ—),
Equivalently, the matrix U^{i}(Ï‰, Ï‘) satisfies the identity
where Î›yxiâ‰”Î´_{xy}Î»yi,Î¨yxiâ‰”Ïˆxi(y), i.e., the x-th column of the matrix Î¨^{i} is given by the vector Ïˆxi.
(K6) For i = 0, one has [19]Ï•00(Ï‰,ğœ—)=1_{{0}}, Î»00(Ï‰,ğœ—)=v(Ï‰,ğœ—). For all 1 â‰¤ i â‰¤ j, the objects Î»xi,Ï•xi,Ïˆxi are determined by the matrix Î›^{(0)}. Denoting by â€¢[Î›] the dependence of an object â€¢ upon Î›, one has
(K7) The discrepancy terms Î¨â€¢i satisfy
(K8) Ïˆxi is â€œalmost orthogonalâ€ to the basis vector Ï•xi,
(K9) The AEFs Ï•xj have compact support, of size uniformly bounded in x,
and since H is a second-order finite-difference operator, this implies
(K10) The approximate spectral spacings admit the following lower bound:
(K11) The objects Î»xi,Ï•xi,Ïˆxi have finite stochastic supports,
(K12) For all 0 â‰¤ i â‰¤ j âˆ’ 1, one has
The exponent 7/4 figuring in the inductive hypotheses is chosen so that a quantity of order of Ïµj7/4 be small enough even compared to Ïµ_{j+1} since Ïµj7/4=Ïµ_{j+1}â‹…Ïµj+11/6â‰ªÏµ_{j+1}.
Apart from the operator family H_{Îµ}(Ï‰, Ï‘), the fundamental objects are Î›^{i} and Î¦^{i}, while U^{i}, Î¨^{i}, and F^{i} are derived from Î›^{i}, Î¦^{i}, and H.
Remark 2. The finiteness of the stochastic supports extends (K6) to a stronger property: the same t-dependence of Î»xi, Ï•xi, and Ïˆxi holds true with the local perturbations of the matrix Î›^{(0)}, viz. Î›yy(0)â†¦Î›yy(0)+t1_{BCLi(x)}(y). In fact, this is the main raison dâ€™Ãªtre of our variant of the KAM scheme with approximate AEFs. The principal motivation for this choice is the achieved local dependence of the AEVs upon the values of the potential, resulting in an effective control of the small denominators, and this is of course the crucial point for any KAM induction.
Remark 3. We will start the induction step by showing that U^{i} is â€œalmost orthogonal,â€ so the Gram matrix C^{i}=(Ui){âŠ¤}U^{i} of the basis Ï•â€¢i is close to 1,
Perhaps it would be instructive to add (3.11) to the list of the inductive hypotheses, but it actually will be derived from (K4) and (K10).
A. The base of induction
As stated in (K6), we start with the covariant nonrandom AEF Ï•x0(Ï‰,ğœ—)=1_{{x}}, xâˆˆZ^{d}, and their respective covariant random AEV Î»x0(Ï‰,ğœ—)=V(x;Ï‰,ğœ—)=v(T^{x}Ï‰,ğœ—). By the definition (1.1) of the lattice Laplacian Î”, we have
so that Ïˆâ€¢0 is nonrandom [constant in (Ï‰, Ï‘)] and obviously covariant. Also, (Ïˆx0,Ï•x0)â‰¡0, which is a stronger form of (K8) for j = 0, valid for any Ïµ_{0} > 0.
Owing to the (Ï‰, Ï‘)-independence of Ï•â€¢0 and of Ïˆâ€¢0, as well to the explicit dependence Î»x0(Ï‰,ğœ—)=v(T^{x}Ï‰,ğœ—), one has the relations (3.7) for i = 0.
Now we turn to the m-norm estimates of the discrepancy functions [cf. (3.8) in (K8)]. By covariance of the latter, it suffices to check (3.1) with x = 0: by (3.12), one has
Setting m=âˆ’12ln2dÎµ, we get Îµ=12de^{âˆ’2m}, thus
Therefore, by taking Îµ > 0 in (1.1) sufficiently small, one can have both Ïµ_{0} > 0 as small as one pleases and the m-norm base estimate (3.8) with m > 0 as large as one pleases.
B. The inductive step
Below, we sometimes use for brevity the notation a(j) â‰² b(j) for quantities dependent upon the scale L_{j}, meaning that a(j) â‰¤ Cb(j) for some finite constant C and all j â‰¥ 0. The subscript Îµ in H_{Îµ} will be often omitted, firstly, for brevity, and secondly, to avoid using in the same formulae the amplitude Îµ from (1.1) and the smallness parameters Ïµ_{j} depending upon it.
Theorem 2. For any j â‰¥ 0,K(L_{j})impliesK(L_{j+1}).
Proof. Fix j â‰¥ 0 and assume K(L_{j}).
Step 1. The Gram matrix. Let us show that the Gram matrix of the Riesz basis {Ï•â€¢j}, C^{j}=(Uj){âŠ¤}U^{j}, is close to 1, viz. C^{j}=1+D^{j},â€–D^{j}â€–{m}=OÏµj1âˆ’. It will imply the convergence of Neumannâ€™s series for 1+D^{j}{âˆ’1}, so
To this end, note that by symmetry of H,
hence
For all x â‰  y, we have two alternatives:
â€¢ either, for x and y too far apart [when the supports of the compactly supported functions figuring in (3.13) are disjoint], one has
â€¢ or, by virtue of (K10) providing a lower bound on |Î»xjâˆ’Î»yj|,
 (K12) and (K6) imply that â€–Ï•xjâ€–{m,x}â‰¤1+âˆ‘_{i}Ïµi1âˆ’â‰¤2, and Ïˆâ€¢j obey the decay bound (K7), so it follows by a simple calculation that for |x âˆ’ y| â‰¤ CL_{j},
As to larger distances |x âˆ’ y|, (3.13) shows that C^{j} has finite spread, and for CL_{j}â‰¤|xâˆ’y|â‰¤Lj2 (which suffices for our purposes) we have (3.14), hence
By normalization, Cxxj=â€–Ï•xjâ€–{2}=1. Thus C^{j} = 1 + D^{j}, where
It follows from the identity (Uj){âŠ¤}âˆ’(Uj){âˆ’1}U^{j}=C^{j}âˆ’1=D^{j} that
By (K4), the matrix U^{j}=1+DÌƒ{j} is invertible by Neumann series, and
hence
Note that the Gram matrix, determined by the AEFs, has the same t-independence as the AEFs [cf. (3.7)].
Step 2. Expansion ofÏˆâ€¢jin the AEFsÏ•â€¢j. By (K5), {Ï•yj,yâˆˆZ^{d}} is a Riesz basis, so we have a norm-convergent expansion
for some matrix A^{j}=(Ayxj). The basis {Ï•yj,yâˆˆZ^{d}} is almost orthogonal, and so one can obtain more explicit approximate formulae for the entries Ayxj, with accuracy sufficient for our purposes. Specifically, denote QÌƒzxjâ‰”(Ï•zj,Ïˆxj), then
or in a matrix form, QÌƒ{j}=C^{j}A^{j}. On the other hand, from (3.20) and by construction of U^{j} and Î¨^{j} [cf. (3.4) and (3.6)], we get
hence QÌƒ{j}=(Uj){âŠ¤}Î¨^{j} and it obeys [cf. (3.8)]
We have shown at step 1 that C^{j} = 1 + D^{j} with â€–D^{j}â€–=OÏµ_{j}, hence
and for the discrepancies Ïˆxj, we obtain the decomposition
Due to the m-norm estimates on Ï•_{â€¢}, for any given C_{Ï•}, arbitrarily large C > 0, arbitrarily small Î³ > 0 and m large enough (m â‰¥ m(C, c_{Ï•}, Î³)), one has for |x âˆ’ y| > Î³c_{Ï•}L_{j},
Let Q^{j} be obtained from QÌƒ{j} by the cutoff
so that Q^{j} has a finite spread,
Set C = 2 > 7/4 in (3.22), then we infer from (3.21) and (3.22) that
so QÌƒâ€¢j can be replaced in further estimates with Qâ€¢j, with accuracy OÏµj2. By hypothesis (K8) [cf. (3.9)], |Qxxj|=|(Ï•xj,Ïˆxj)|=OÏµj7/4, so we come to the decomposition
where the correction term fxj+1 satisfies
Owing to the cut-off estimate (3.24), we can use the approximate coefficients Qyxj of Ïˆxj, instead of the exact (but implicit) ones, Ayxj. Collecting (3.5), (3.19), and (3.21)â€“(3.26), we obtain a convenient representation for the discrepancies,
where
Each function fxj+1 has a compact support,
since
Furthermore, the stochastic supports S(fxj+1) are uniformly bounded in diameter. Indeed, as shown in (3.25), fxj+1 is a measurable function of the variables
so by virtue of (3.23), it suffices to retain in the above collection only yâˆˆB_{Î³cÏ•Lj}(x). By the inductive hypothesis (K11),
while for Qyxjâ‰¡(Ï•yj,Ïˆxj) we have, for all y with |y âˆ’ x| â‰¤ Î³c_{Ï•}L_{j},
Similarly,
Thus with a fixed Y > 1 and c_{Ï•}, c^{Ïˆ} small enough, compared to Y âˆ’ 1, we have
Step 3. Construction of the new ACE. Introduce a matrix M^{j+1} by
The matrix elements Myxj+1 are well-defined, thanks to the small denominator bound (3.10) [hypothesis (K10)]. M^{j+1} defines an operator in the space of compactly supported functions on Z^{d}, and we have [cf. (3.10) and (3.27)]
Now define a matrix UÌƒ{j+1} by
The columns of UÌƒ{j+1} give the new basis vectors (possibly non-normalized)
We shall perform normalization of the approximate EFs later, at step 7, and then obtain a matrix U^{j+1} satisfying all the hypotheses of the step j + 1.Recall that we denote by SPRâ‹… the â€œeffective widthâ€ of finite-band matrices [cf. (3.3)]. By (3.28) and (3.23), SPRM^{j+1}=SPRQ^{j}â‰¤Î³c_{Ï•}L_{j}, thus
For further use, note that for all z â‰  x,
By expansion in the Neumann series, convergent by (3.29), we have
so the inverse (1+Mj+1){âˆ’1} can be safely replaced in subsequent calculations by 1âˆ’M^{j+1}+(Mj+1){2}, with accuracy Oâ€–M^{j+1}â€–m3. This is one of the key points of our procedure, allowing one to keep the AEVs and AEFs locally dependent upon the values of the potential.By construction, Ï†xj+1 is determined by the variables
where Qâ€¢j are, in turn, defined through Ï†â€¢j and Ïˆâ€¢j, so applying the inductive hypotheses (K6), (K11) and the estimate (3.23), we come to the following upper bound on the stochastic support of Ï†â€¢j+1,
Step 4. Action of the Hamiltonian on the new ACE. From the inversion formula (3.34) and the hypothesis (K5), we infer
where
It follows that
with
thus, due to the identity (3.37) and SPRABâ‰¤SPRA+SPRB,
since SPRH=1 and SPRÎ›Ìƒ{j+1}=0. We see that, although the exact inversion formula gives rise to the perturbation terms of all orders, hence to an infinite spread, the finite-distance cutoff performed in the definition of F^{j+1} results in a finite-spread correction to the terms quadratic in M^{j+1} (which also have finite spreads).Equivalently, the column vectors Ï†â€¢j+1 of the matrix UÌƒ{j+1}, defined in (3.31), are covariant approximate eigenvectors of H,
with covariant approximate eigenvalues
and the new discrepancy terms
or in vector form, on account of (3.36),
Now we can check (K8),
The above almost orthogonality condition will be preserved by the normalization of Ï•â€¢j+1 at step 8.
Step 5. Estimates of the new discrepancy. It follows from (3.36) that
so by (3.39), the norms of Ïˆâ€¢j+1 obey an upper bound
Further, the norms of the diagonal matrices Î›^{j} are uniformly bounded, by induction in j, due to the boundedness of the potential V providing the AEV Î»^{(0)} [cf. (K6)] and the inductive perturbation bounds on Î»^{i+1}âˆ’Î»^{i} [cf. (K12)]. Therefore,
The higher-order terms collected in Z^{j+1} are negligible with respect to the quadratic terms, for we have
Step 6. m-norm of the perturbation Ï†â€¢j+1âˆ’Ï•â€¢j.The vector Ï•xj+1 is the x-th column of UÌƒ{j+1}=U^{j}(1+M^{j+1}), so
Step 7. Normalization of the ACE. This is only a matter of convenience, but it is not difficult to see that the normalization of Ï†â€¢j+1 is actually a small-norm perturbation. Indeed, â€–Ï•xjâ€–=1 by inductive hypothesis, and
and therefore,
Introduce the normalized AEF
then by (3.42), we have â€–Ï•xj+1âˆ’Ï•xjâ€–â‰¤Ïµj1âˆ’, and from (3.40), we infer
The normalization preserves the almost-orthogonality properties of the new AEFs, and it does not change the stochastic support of Ï†xj+1,
Step 8. The condition (K8). It follows from the norm perturbation estimate on the new ACE that
Therefore, the inductive assumption (K8) is fulfilled at the step j + 1.
Step 9. The new spectral spacings. It follows directly from the explicit formulae (3.31) and (3.38) for the new AEFs and AEVs, along with the linear growth rate bound on the diameters of the stochastic supports of the AEF/AEV, that the local deformations of the potential of the form
leave invariant the AEFs Ï†yj+1 and the discrepancies Ïˆyj+1 with |yâˆ’x|â‰²Lj2, while the AEVs are affine functions of t undergoing under (3.45)
Fix a pair x, y with |xâˆ’y|â‰¤Lj+12 and consider the two possible cases:(I)|xâˆ’y|â‰¤Lj2. Then the required lower bound on the spectral spacing follows immediately from a similar lower bound for Î»xj and Î»yj, combined with the exponential upper bound on the perturbations |Î»xj+1âˆ’Î»xj| and Î»yj+1âˆ’Î»yj|.(II)Lj2<|xâˆ’y|â‰¤Lj+12. Then it follows from (UPA) that the finite trajectories indexed by the balls B_{Lj+12}(x) and B_{Lj+12}(y) do not overlap; moreover,
Conditional on the Ïƒ-algebra BNÌƒ{j}âŠ¥ [cf. (2.1) and (2.3)] and with Ï‰ fixed, the samples V(T^{z}Ï‰,ğœ—),zâˆˆBL_{j+1}2(x) and V(T^{z}Ï‰,ğœ—),zâˆˆBL_{j+1}2(y) become independent and take the form
where vÌƒ{z}(â‹…) is BNÌƒ{j}âŠ¥-measurable, hence rendered non-random by the conditioning, while Î¶_{x} and Î¶_{y} are independent random variables uniformly distributed in individual intervals of length 2^{âˆ’NÌƒ(Lj)}. On account of the affine dependence (3.46) of the AEVs, the required probabilistic bounds (K10) on the spectral spacings can be derived from Lemma 2.2: taking in (2.6) Ïµ=Ïµj+1Îº, Îº > 0, and setting
we obtain
By covariance, it suffices to consider only the case x = 0. Therefore, the claim follows by counting the number of pairs (0, y) with yâˆˆB_{Lj2}(0).The estimates (K7) and (K8) for i = 0 have been established in Sec. III A.Summary of the inductive step. For the readerâ€™s convenience, we provide below the references to the stages in the proof where each of the inductive hypotheses (K1)â€“(K12) is proved.Recall also that the estimates required for the base of indiction (i = 0) have been established in Sec. III A, where we showed that arbitrary small Ïµ_{0} > 0 and arbitrarily large decay exponents m > 0 can be obtained by letting the amplitude Îµ > 0 of the Laplacian (1.1) be small enough.
IV. PROOF OF THE MAIN RESULT
None
None
(K1) step 3	(K2) step 4	(K3) step 4
(K4) step 8	(K5) independent of j	(K6) step 9
(K7) step 5 (3.41)	(K8) step 4 (3.43) + step 9	(K9) step 3 (3.32)
(K10) step 9	(K11) step 7 (3.44)	(K12) step 5 (3.35)
FIG. 1. 
Example for Lemma 2.1; Î½ = 2. The right portion of the picture shows the torus T^{Î½} in a larger scale. Dotted lines are boundaries of some R_{j}-cubes. Hitting some of them by the images T^{x}Q_{rj}(Ï‰_{i^{â€²}}) (on the right picture) and T^{y}Q_{rj}(Ï‰_{i^{â€²}}) produces division hyperplanes (on the left picture) in the construction of the partition elements P_{j,l} inside the cube Q_{rj}(Ï‰_{i^{â€²}}). The existence of two or more division hyperplanes of the same direction contradicts the aperiodicity condition (UPA). Therefore, there can be at most Î½ internal boundaries, hence at most 2^{Î½} partition elements inside Q_{rj}(Ï‰_{i^{â€²}}).
