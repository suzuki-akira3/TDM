A new three-dimensional nonscanning laser imaging system based on the illumination pattern of a point-light-source array
One of the most important goals of research on three-dimensional nonscanning laser imaging systems is the improvement of the illumination system. In this paper, a new three-dimensional nonscanning laser imaging system based on the illumination pattern of a point-light-source array is proposed. This array is obtained using a fiber array connected to a laser array with each unit laser having independent control circuits. This system uses a point-to-point imaging process, which is realized using the exact corresponding optical relationship between the point-light-source array and a linear-mode avalanche photodiode array detector. The complete working process of this system is explained in detail, and the mathematical model of this system containing four equations is established. A simulated contrast experiment and two real contrast experiments which use the simplified setup without a laser array are performed. The final results demonstrate that unlike a conventional three-dimensional nonscanning laser imaging system, the proposed system meets all the requirements of an eligible illumination system. Finally, the imaging performance of this system is analyzed under defocusing situations, and analytical results show that the system has good defocusing robustness and can be easily adjusted in real applications.
I. INTRODUCTION
The lidar technique is widely used in various fields, such as target recognition, vehicle navigation, robotics, and environmental measurement [1–4]. Three-dimensional (3D) laser imaging systems can generally be divided into scanning and nonscanning types according to the basic imaging principle [5,6]. The imaging efficiency of scanning laser imaging systems is low due to the existence of mechanical scanning structures [7]. Furthermore, image deformation occurs when the object moves at very high speed. The nonscanning laser imaging system can avoid the above problems [8,9]. Many 3D nonscanning laser imaging systems can simultaneously obtain range and intensity images. The intensity images are very useful when carrying out data processing for range images. In Refs [10] and  [11], the background of range images is suppressed using intensity images. In Ref [12], intensity images are used to assist in extracting the targets’ regions of range images. Not only can the performance of illumination systems in 3D nonscanning laser imaging systems affect the quality of intensity images, but it can also affect the maximum detectable range of every pixel in range images. Therefore, the illumination system plays an important role in whole 3D nonscanning laser imaging systems.
Generally, most lasers can transmit a beam with a Gaussian profile [13], and semiconductor lasers can transmit a beam with an astigmatism and elliptical profile [14]. However, all these lasers cannot directly meet the requirements for an eligible illumination system. Therefore, how to shape the illuminated laser spots in the illumination system of 3D nonscanning laser imaging systems is an important research direction [14–16]. At present, various laser beam-shaping methods exist, such as interception, diffractive optics, refractive optics, and microlens. The interception approach uses a diaphragm to intercept Gaussian beams to reserve the relatively homogeneous part in the center of the beams [13]. This approach causes huge loss of laser energy, and its homogeneity is poor. The diffractive approach is based on a computer-generated hologram and is associated with coherent point spread function engineering combined with the incoherent imaging of a laser active structure [16]. This approach requires a very complex design of diffractive optics, and its damage threshold is low. Compared with diffractive optics, refractive optics have great advantages and is widely used for its higher transmission efficiency and better homogeneity. The refractive optics can keep a flat-top beam shape for a wide distance range [15]. The free-form refractive microlens can be used to transform laser beams into the best shape for single and multi-mode laser beams [17]. However, the manufacture of free-form refractive microlens is very difficult and expensive. In Ref [18], a number of common methods were presented, which can be used to correct the astigmatism of a semiconductor laser.
Numerous research studies have been conducted to improve the quality of illuminated laser spots in laser imaging systems. However, most of the previous research studies mainly focused on how to improve the homogeneity among laser spots. Few research studies on the production of a controllable laser illumination pattern and improvement of the utilization rate of laser energy have been done. The three important requirements for an eligible illumination system in the regular laser imaging system are as follows [15]: (1) The scope of illuminated areas should be equal to that of the field of view (FOV) of the receivers; (2) The laser intensity distribution of illuminated areas should be homogeneous at any distance in the FOV; and (3) The utilization rate of laser energy should be as high as possible. An additional requirement for an eligible illumination system in the 3D laser imaging systems using time of flight (TOF), which is the intensity of illuminated lasers corresponding to each pixel of the detectors should be independently controllable to avoid the situation in which the intensity of the reflected laser signals at certain pixels is saturated and others are too weak. However, attaining these four requirements at the same time is very difficult. To the best of our knowledge, no laser can realize this desired illumination pattern directly. In Ref [19], the authors used a diffractive optical element from MEMS to realize the illumination pattern of a point-light-source array. This illumination method can only meet the first two requirements but cannot meet the last two requirements. The manufacture of the diffractive optical element is very difficult, and the diffractive efficiency of the diffractive optical element is low. In addition, this system cannot be applied when the reflectivity on the surface of the target sharply changes.
In this paper, we design a new 3D nonscanning laser imaging system based on the illumination pattern of a point-light-source array. Its illumination system is improved by using a fiber array connected to a laser array with independent control circuits at each laser. This system uses an imaging process of Point-to-Point (PP), which is realized by using the exact corresponding optical relationship between the point-light-source array and a linear-mode avalanche photodiode (APD) array detector. In this system, we use a single transmit/receive aperture instead of the two-independent apertures, which allows the reduction of the system size and other benefits [20]. The complete working process and mathematical model of the proposed system are described in detail. A simulated contrast experiment and two real contrast experiments which use the simplified setup without a laser array prove that the proposed system meets all the requirements for an eligible illumination system, whereas the conventional 3D nonscanning laser imaging system does not. Finally, the analysis on the imaging performance of this system under defocusing situations shows that this system has good defocusing robustness and can be easily adjusted in real applications.
The paper is organized as follows. In Sec. II, we first review the basic structure of an entire imaging system, and then we establish its mathematical model. In Sec. III, a simulated contrast experiment and two real contrast experiments are performed. In Sec. IV, the imaging performance of this system under defocusing situations is analyzed. Finally, in Sec. V, several conclusions based on the previous experiments are drawn.
II. RELATED THEORY
A. Imaging system
The exemplary schematic of the proposed 3D nonscanning laser imaging system is shown in Fig. 1. The basic imaging principle of this laser imaging system is TOF. The target is illuminated by short laser pulses emitted from a pulsed laser source, and the distance values of every pixel in range images are obtained by calculating the total return time of the laser pulses. Supposing light speed is c and the total return time is t, the distance then can be obtained by L = ct/2 [21].
This system includes a pulsed laser array, fiber array, transmitting optical lens, mirror, receiving optical mirror, linear-mode APD array detector, and linear-mode APD unit detector, as well as a processor and controller. The pulsed laser array contains n × n + 1 lasers with independent control circuits, and all these unit lasers can transmit narrow-pulsed beams with different laser intensities simultaneously after receiving a trigger signal. The fiber array is spliced using n^{2} fibers, and its back-end is arranged using the n × n pattern, which is used to make the point-light-source array. The transmitting optical lens is an imaging lens, and it can project the back-end of the fiber array onto the object. The mirror has an inclined angle of 45° versus the optical axes of the transmitting optical lens and the receiving optical mirror; thus, this lens and this mirror partially share a common optical axis. The receiving optical mirror is a kind of a reflecting telescope with long focal length and large aperture, and it can project the object onto its image plane. The linear-mode APD array detector is used to receive the reflected laser signals from the object, and the linear-mode APD unit detector is used to collect the reference laser signal to count the total return time. The processor and controller are used to process the electrical pulse signals from the linear-mode APD array detector and the linear-mode APD unit detector. They are also used to control the operation time sequence of this system. To make this system operate normally, all these components should have good compatibility.
The working process of this system can be divided into two imaging subprocesses: a process from the laser array to the desired object and a process from the desired object to the APD array detector. The first subprocess is as follows. When the pulsed laser array receives a trigger signal from the controller, all the unit lasers transmit n × n + 1 laser beams simultaneously. Then, n × n laser beams are sent to the fiber array to form a point-light-source array. Then, this point-light-source array is projected onto the desired object by the transmitting optical lens. The rest of the laser beam is received by the APD unit detector to produce an electrical pulse signal. Then, this electrical pulse signal is sent to the processor and becomes the reference signal for measuring the total return time. The second subprocess is as follows. The back-scattering laser from the object is collected by the receiving optical mirror and then forms an image on the surface of the APD array detector. All electrical pulse signals from the APD array detector are then sent to the processor to reconstruct the range image and the intensity image of the desired object. Then, a cycle of imaging process is completed, and the controller can begin to arrange the next cycle of the imaging process.
B. Constraint equation on transverse magnification
In the PP imaging principle, every laser point on the fiber array corresponds to a sole pixel on the APD array detector. Thus, the total number of laser points on the fiber array is equal to that of pixels on the APD array detector. To realize the PP imaging process, the following parameters need to meet a mathematical constraint equation: d_{fiber} and d_{senser} (the distance between two adjacent fibers’ centers on the fiber array and the distance between two adjacent pixels’ centers on the APD array detector, respectively), as well as f_{t} and f_{r} (the focal length of transmitting optical lens and the focal length of receiving optical mirror, respectively). The physical explanations of most mathematical symbols used in this paper are presented in Fig. 1.
As mentioned above, this imaging system contains two imaging subprocesses. In general, any imaging process can be represented using the Gaussian imaging equation. Therefore, the first imaging subprocess from the laser array to the object can be represented as
where l_{t} is the object distance from the fiber array to the transmitting optical lens and L is the image distance from the transmitting optical lens to the object.
The second imaging subprocess from the object to the APD array detector can be represented as
where l_{r} is the image distance from the receiving optical mirror to the APD array detector and L is the object distance in Eq. (2).
The transverse magnification of this imaging system can be written as
where β_{t} is the transverse magnification of the first imaging subprocess and β_{r} is the transverse magnification of the second imaging subprocess. Given that in the application of this imaging system, L ≫ l_{r}, we can obtain l_{r} ≈ f_{r}. Therefore, substituting the above result back into Eq. (3) gives
Therefore, to realize the PP imaging process, this imaging system needs to meet the following mathematical constraint equation:
C. Constraint equation on optical aperture
To increase the utilization rate of laser energy, all laser beams from the fiber array are required to totally pass through the transmitting optical lens. Therefore, this imaging system also needs to meet the following mathematical constraint equation:
where n is the number of fibers in every row or column of the fiber array, NA is the numerical aperture of fibers, and D_{t} is the aperture of the transmitting optical lens.
Furthermore, to increase the total received energy of the reflected laser, the aperture D_{r} of the receiving optical mirror must meet the following mathematical constraint equation:
where D_{m} is the aperture of the mirror. Combining Eqs. (6) and (7) gives
D. Constraint equation on spatial resolution
In many cases, we also have certain requirements for the spatial resolution of imaging systems on the surface of the object. For example, we hope that the spatial resolution is less than d_{target} when the object is located at a distance of L. Given that in the application of this imaging system, L ≫ l_{t}, we can obtain l_{t} ≈ f_{t}. Therefore, this new constraint equation can be described using
To make this imaging system operate normally and exhibit good performance, it must meet the above three constraint equations Eqs. (5), (8), and (9) at the same time.
E. Range equation
One of the most important evaluation criteria for a laser detection system is its range equation. To simplify this problem, we need to assume that the laser transmission in the atmosphere conforms to the principle of geometrical optics; the atmosphere is homogeneous and isotropic; the object belongs to Lambert reflectors; the distribution of laser energy on the surface of the desired illuminated area is uniform; and no noise and interference exist in the system.
The conventional 3D nonscanning laser imaging system uses the illumination pattern of a single light source, and it can form a single circular laser spot to cover the whole desired illuminated area. Its schematic is similar to that shown in Fig. 1 except the illumination pattern. Its illumination system contains a laser only, without laser and fiber arrays. Therefore, this system is not an exact imaging process but a defocused imaging process or a process of compressing the angular divergence when the single laser beam illuminates the desired illuminated area. The range equation of the conventional 3D nonscanning laser imaging systems using the single laser beam illumination pattern can be written as [22]
where τ_{r} is the transmission efficiency of the receiving optical mirror and the photoelectric conversion efficiency of the detector, τ_{a} is the atmosphere transmission factor, R_{r} is the radius of the receiving optical mirror, R_{m} is the radius of the mirror, ρ_{r} is the reflectivity of the target surface, A_{r} is the effective receiving area of the detector, which is the minimum between the receiving area of the detector and the illuminated area of the laser, P_{t} is the laser transmitting power, L is the range length between the detector and the object, θ_{t} is the angular divergence of transmitting laser beams, which is a 2D angle, Ω_{r} is the angular dispersion of the object surface, which is a solid angle, and P_{conventional} is the output power of the detector in the conventional 3D nonscanning laser systems.
However, for the proposed imaging system, the illuminated area of every unit laser is less than the receiving area of every pixel of the detector; thus, the effective receiving area of the detector A_{r} is equal to the illuminated area of every unit laser. Then the range equation of the proposed imaging system can be written as
According to the above analysis, we can establish the mathematical model of the proposed imaging system as
III. EXPERIMENT
A. Simulated contrast experiment on distant detection
The mathematical model of the entire imaging system is established in Eq. (12). To compare the proposed system with the conventional 3D nonscanning laser imaging system in terms of the utilization rate of laser energy at different distances, this simulated experiment was organized. We simulated the imaging processes of the proposed system and the conventional 3D nonscanning laser imaging system using Eqs. (10) and (11). Then we analyzed the effect of different imaging systems and different detection ranges on the total output power of the imaging systems. All the parameters used in this experiment are shown in Table I. Given that the illuminated area of the laser is circular and the receiving area of the detector is square in the conventional 3D nonscanning laser imaging system, the receiving area of the detector must be less than the illuminated area of the laser A_{i} to make every pixel on the detector receive laser energy; thus, the effective receiving area of the detector A_{r} is equal to the receiving area of the detector. We define the area ratio (AR) to be equal to A_{r}/A_{i}. Then in the conventional 3D nonscanning laser imaging system, the maximum AR is approximately equal to 2/π, corresponding to the inscribed square of a circle.
The final experimental results are shown in Fig. 2. The abscissa is the distance between the detector and the object, and the ordinate is the output power of the imaging systems. We can find that the red curve is larger than the green curve and the green curve is larger than the blue curve at any distance in Fig. 2, which indicates that the proposed nonscanning imaging system in this paper has an obvious advantage in terms of the utilization rate of laser energy when the object is located at different distances, and the output power of the conventional 3D nonscanning laser imaging system declines as the AR decreases. We can also find that all these three curves dramatically decline as the abscissa increases, which shows that the total output power of all these three imaging systems dramatically decline as the detection range increases. Therefore, we conclude that compared with the conventional 3D nonscanning laser imaging system, the proposed nonscanning imaging system in this paper has a higher utilization rate of laser energy, which meets the third requirement for an eligible illumination system. In this experiment, we suppose that all these three systems use the same total laser transmitting power. However, in real application, the proposed imaging system has a bigger total laser transmitting power because the proposed imaging system uses many unit lasers at the same time. Therefore, the proposed imaging system has a farther detectable distance.
B. Real contrast experiment
The effectiveness of the proposed imaging system must be validated by experiments in real cases. Considering the restriction of cost and difficulty in the real experiments, we used a laser and a fiber splitter instead of using a laser array to form a point-light-source array. We used a receiving optical lens instead of using a receiving optical mirror to receive the reflected laser energy from the object in this real experiment. Therefore, the basic schematic in this real experiment is similar to that in Fig. 1, except these two different points. The function of the fiber splitter is to divide the laser beam from a laser into n × n + 1 laser beams to connect to the fiber array. The real contrast experiments in this paper contain two contrast experiments, which correspond to intensity and range data. All the parameters used in these two experiments are shown in Table II. The transmitting optical lens and the receiving optical mirror are spherical, and the mirror is flat. The linear-mode APD array detector is a commercial product from FirstSensor Germany, and the CCD is a commercial product from DALSA Canada.
1. Real contrast experiment on intensity data
To certify the feasibility of the proposed imaging structure, this contrast experiment was organized. We compared the proposed imaging system with the conventional 3D nonscanning laser imaging system in terms of intensity data collection capability, and we analyzed the effect of different illumination patterns on the intensity data. In this experiment, the proposed imaging system used the illumination pattern of a point-light-source array, whereas the conventional 3D nonscanning laser imaging system used the illumination pattern of a single light source. In this experiment, the continuous visible laser beam with a wavelength of 650 nm was used as the light resource. The position of every laser spot was traced by using CCD rather than the APD array detector. The size of each pixel on the CCD is known; thus, we can compute the distance between two adjacent laser spots according to the number of pixels between them.
The experimental results are shown in Fig. 3. Figure 3(a) shows the image collected by the proposed imaging system, and Fig. 3(b) shows the image obtained by the conventional 3D nonscanning laser imaging system. The red pixels can describe the intensity of laser energy, and the size of the green square frame is equal to that of each pixel on the APD array detector. Although the distribution of all the laser spots in Fig. 3(a) is not regular because of the manual manufacture of the fiber array, we can find that every laser spot is located at the corresponding square frame, which indicates that every laser spot can be projected onto the corresponding pixel on the APD array detector when the APD array detector replaces the CCD at the same position. The illuminated scope of every unit laser is less than the receiving scope of every pixel on the APD in the proposed imaging system. Therefore, we can conclude that the optical structure of the proposed imaging system is feasible, and this system meets the first requirement for an eligible illumination system. We can also find that the size of every laser spot is not the same in Fig. 3(a). This observation can be attributed to the inconsistency of the fiber section in front of the fiber array, which is caused by the manual cut. In Fig. 3(b), we can find that the distribution of laser energy belongs to Gaussian distribution, which is similar to its illumination pattern. The illuminated scope of the laser is larger than the receiving scope of the APD array detector in the conventional 3D nonscanning laser imaging system. Therefore, we can conclude that the conventional 3D nonscanning laser imaging system does not meet the first requirement for good illumination systems. We can also find that the proposed imaging system has some sharp peaks of laser energy, whereas the conventional imaging system has none. This occurrence is because that the process from the laser points on the point-light-source array to the laser spots on the surface of the object in the proposed imaging system is an exact imaging process, which reduces the size of every laser spot and sharply changes the laser intensity. The process from the single laser source to the laser spots on the surface of the object in the conventional imaging system is a defocused imaging process or a process of compressing the angular divergence of the transmitting laser beam, which enlarges the laser spot, gradually changing the laser intensity. Although the maximum laser energy in Fig. 3(b) is less than that in Fig. 3(a), the total laser energy in Fig. 3(b) is larger than that in Fig. 3(a).
To analyze the distribution of laser energy in Fig. 3, we computed the total laser energy in every green square frame and drew Fig. 4 using these values. The abscissa is the position coordinates line by line, and the ordinate is the total sum of all pixel values in every green square frame. We use the fluctuation ratio (FR) to evaluate the fluctuation of curves in Fig. 4. The FR is defined by
We can find that the FR of the conventional 3D nonscanning laser imaging system is considerably larger than that of the proposed imaging system, which shows that the proposed imaging system has a better homogeneity in terms of laser energy distribution. Therefore, compared with the conventional 3D nonscanning laser imaging system, the proposed imaging system has better homogeneity in terms of laser energy distribution, which meets the second requirement for an eligible illumination system.
Therefore, based on the above analysis, we can conclude that the proposed imaging system meets the first two requirements for an eligible illumination system, whereas the conventional 3D nonscanning laser imaging system does not.
2. Real contrast experiment on range data
To analyze the range data collection capability of the proposed imaging system, this contrast experiment was organized. We used the proposed imaging system and the conventional 3D nonscanning laser imaging system to collect the range images of the same object and analyze the effect of different illumination patterns on the range images. In this experiment, the proposed imaging system used the illumination pattern of a point-light-source array, whereas the conventional 3D nonscanning laser imaging system used the illumination pattern of a single light source. In this experiment, the infrared pulsed laser with a wavelength of 850 nm, and a pulsed width of 5 ns was used as the light source. The range data were recorded by using the linear-mode APD array detector. The schematic and systematic prototype of this experiment and the object are shown in Figs. 5 and 6, respectively.
The final experimental results are shown in Fig. 7. Figure 7(a) is the range image collected by the proposed imaging system, and Fig. 7(b) is the range image collected by the conventional 3D nonscanning laser imaging system. No visual difference was observed between these two range images. To evaluate the range accuracy of these two imaging systems, we used the difference between the positive maximum error value and the negative maximum error value as an indicator. We collected 10 range images for every imaging system and obtained its range accuracy. The range accuracy of the proposed imaging system is 6.8 cm and that of the conventional 3D nonscanning imaging system is 6.9 cm. Therefore, we can conclude that the illumination pattern does not affect range accuracy.
Finally, we must reiterate that the real experimental structure in this section is similar to the schematic shown in Fig. 1; however, two different points still exist. The first point is that we used a laser and a fiber splitter instead of a laser array to form a point-light-source array, and the second point is that we used a receiving optical lens instead of a receiving optical mirror to receive the reflected laser energy from the object. Nevertheless, this real experiment can also prove that the proposed imaging system meets the first two requirements for an eligible illumination system.
In the real application of 3D nonscanning laser imaging systems, if the reflectivity of the target surface changes dramatically and the imaging systems use the laser with the same intensity to illuminate the target, the intensity of the reflected laser signals from the target at certain pixels is saturated and others are too weak. In the proposed imaging system, the intensity of the illuminated laser beams from the laser array is independently controllable, and this system can adjust the intensity of every illuminated laser beam according to the last imaging result to avoid the above situation. Therefore, we can conclude that the proposed imaging system meets the fourth requirement for an eligible illumination system, whereas the conventional 3D nonscanning laser imaging system does not. It should be noted that in the real experiment of this paper, the intensity of the illuminated laser beams is not independently controllable because we used a laser and a fiber splitter instead of a laser array to form a point-light-source array.
IV. DISCUSSION
As mentioned in Sec. II A, the working process of the proposed imaging system can be divided into two imaging subprocesses: a process from the laser array to the desired object and a process from the desired target to the APD array detector. Therefore, discussing the effect of defocusing ranges on the intensity and range data of this imaging system is indispensable. The equivalent imaging models of this imaging system are shown in Fig. 8.
In Fig. 8(a), the entire imaging system is in the best condition, and no defocusing can be observed in these two imaging processes. Therefore, the final radius R_{f} of the laser spot on the APD array detector is 0.
In Fig. 8(b), the real distance L − Δ_{1} between the object and the imaging system is less than the hypothetical distance L used in the imaging system, which produces a defocusing range in the first imaging process. No defocusing range is observed in the second imaging process. Therefore, the final radius R_{f} of the laser spots on the APD array detector is no longer a dot without an area but a circular laser spot with an area. According to the basic principle of geometrical optics, the final radius R_{f} of the laser spot on the APD array detector can be written as
where R_{e} is the effective radius of the transmitting optical lens, l_{r} is the image distance from the receiving optical lens to the APD array detector, L is the hypothetical distance between the object and the imaging system, and Δ_{1} is the defocusing range in the first imaging process.
In Fig. 8(c), no defocusing range exists in the first imaging process, and the real image distance l_{r} − Δ_{2} from the receiving optical lens to the APD array detector is less than the correct image distance l_{r}, which produces a defocusing range in the second imaging process. Therefore, the final radius R_{f} of the laser spots on the APD array detector becomes a circular laser spot with an area. According to the basic principle of geometrical optics, the final radius R_{f} of laser spots on the APD array detector can be written as
where R_{r} is the radius of the receiving optical lens, l_{r} is the correct image distance from the receiving optical lens to the APD array detector, and Δ_{2} is the defocusing range in the second imaging process.
In Fig. 8(d), defocusing ranges were seen in the two imaging processes. According to the basic principle of geometrical optics, the final radius R_{f} of the laser spots on the APD array detector can be written as
Given that in the application of this imaging system, L ≫ l_{r}, l_{r} can be approximately represented by the f_{r}.
As we all know, to some degree, the quality of intensity images depends on the shape of the point spread functions of imaging systems in geometrical optics [23]. On the other hand, the quality of intensity images in the proposed imaging system depends on the size of the laser spot on the APD array detector. Therefore, Fig. 9 was drawn using Eq. (16), and Δ_{1} and Δ_{2} were chosen as independent variables to analyze the effect of defocusing on the intensity images in the proposed imaging system. All the parameters used in this figure are shown in Table II. We can find that when the Δ_{1} obviously changes from 0 m to 0.5 m, the total variation of the R_{f} is less than 40 μm, which is far less than the size of the pixel on the APD array detector. Moreover, the total variation of the R_{f} will decrease at a speed of the second order power function with the increase of the distance L. We can also find that when the change of the Δ_{2} is 0.1 mm, the total variation of the R_{f} is 50 μm. The above analysis shows that the defocusing range in the first imaging process has a very slight influence on the quality of intensity images in this system, whereas the defocusing range in the second imaging process largely affects the said quality. In the real application, avoiding the defocusing in the second imaging process is very easy, which has been proven by many current camera systems. Although avoiding the defocusing in the first imaging process is difficult, the result in Fig. 9 has proven that the effect of the defocusing range in the first imaging process on the quality of intensity images is minimal. Therefore, we can conclude that the proposed imaging system has a good defocusing robustness on the quality of intensity images.
As we all know, the range accuracy in range detection systems based on TOF depends on the waveform accuracy of the reflected pulsed laser beams [22]. Therefore, to analyze the effect of defocusing on the range data in the proposed system, we must analyze the effect of defocusing on the waveform accuracy. According to the Fermat principle, in an ideal imaging system, all the lights from an object point will arrive at the corresponding image point passing through the same optical path length [24]. Therefore, the pulse width of the reflected laser signals remains constant in Fig. 8(a), and the pulse width broadens in the last three conditions in Fig. 8. However, similar to previous analysis, the total variation of the R_{f} belongs to the 10-μm level when defocusing occurs in the proposed imaging system; thus, the difference of the optical path lengths among different lights from the same laser point also belongs to the 10-μm level, which is equivalent to the 10 ps level. Then, the change in the pulse width of the reflected laser signals also belongs to the 10 ps level; this change is negligible. We can conclude that the proposed imaging system has a good defocusing robustness on the range accuracy.
Based on these findings, we can conclude that the proposed 3D nonscanning laser imaging system has a good defocusing robustness on the quality of intensity images as well as range accuracy and is easily adjusted in real applications. Notably, the above analysis is suitable for the proposed 3D nonscanning laser imaging system but unsuitable for the conventional 3D nonscanning laser imaging system. The proposed imaging system contains two exact imaging processes, whereas the conventional imaging system only contains an exact imaging process. In the conventional 3D nonscanning laser imaging system, the receiving process is an exact imaging process, and the transmitting process is a process of compressing the angular divergence of the transmitting laser beam from the single laser source to the laser spots on the surface of the object. In addition, these two imaging systems have different illumination patterns; thus, the analysis on these two imaging systems differs.
V. CONCLUSION
This paper proposes a new 3D nonscanning laser imaging system based on the illumination pattern of a point-light-source array. The point-light-source array is obtained by using a fiber array connected to a laser array with each unit laser having independent control circuits. A simulated contrast experiment proves that compared with the conventional 3D nonscanning laser imaging system, this imaging system has a higher utilization rate of laser energy and a farther detectable distance. A real contrast experiment on intensity data proves that the illuminated scope of the laser is less than the receiving scope of the detector, and the distribution of laser energy on the illuminated area is more homogeneous in the proposed imaging system. The intensity of illuminated lasers corresponding to each pixel of the detectors is independently controllable in the proposed imaging system; thus, it can avoid the situation in which the intensity of reflected laser signals at certain pixels is saturated and others are too weak. Therefore, the proposed imaging system meets all the requirements for an eligible illumination system, whereas the conventional 3D nonscanning laser imaging system does not. Another real contrast experiment on range data proves that the illumination pattern does not affect the range accuracy of imaging systems. Finally, the analysis on the imaging performance of this imaging system under different defocusing situations shows that the proposed imaging system has a good defocusing robustness and is easily adjusted in real applications.
Two disadvantages are observed in the current version of the proposed imaging system. The first is that this system increases the complexity of circuits, but this disadvantage can be solved with the rapid development of integrated circuits. The second is that this system has a low spatial resolution, but this disadvantage can be solved by improving the manufacturing technique of fiber arrays and APD array detectors or applying the scanning technology of APD array detectors. Now, our research group has obtained an 8 × 8 linear-mode APD array detector. We will try to strictly follow the schematic shown in Fig. 1 to set up our system using this 8 × 8 APD array detector and apply the technology of full waveform detection to our system in future research.
TABLE I. 
Parameter values used in the simulated experiment.
TABLE II. 
Parameter values used in the real experiments.
TABLE I. -body
Parameters	Values	Parameters	Values
P_{t}	5 mJ	R_{r}	25 mm
θ_{t}	0.01	τ_{a}	1
Ω_{r}	π	τ_{r}	1
ρ_{r}	0.1	AR	2/π or 1/π
TABLE II. -body
Parameters	Values
Laser wavelength (λ_{1}|λ_{2})	650 nm|850 nm
Fiber array (d_{internal}|d_{fiber}|n|NA)	60 μm|0.9 mm|5|0.2
Transmitting optical lens (f_{t}|R_{t})	100 mm|15 mm
Mirror (R_{m})	12.7 mm
Receiving optical mirror (f_{r}|R_{r})	50.8 mm|25.4 mm
APD array detector (d_{senser}|d_{active})	500 μm|405 µm
CCD pixel size	5.2 µm
Range length (L)	5 m
FIG. 1. 
The exemplary schematic of the proposed imaging system.
FIG. 2. 
The output power as a function of detection range.
FIG. 3. 
(a) The image collected by the proposed imaging system and (b) the image collected by the conventional imaging system.
FIG. 4. 
The distribution image of laser energy.
FIG. 5. 
(a) The schematic of the real experiment system and (b) the systematic prototype of the real experiment system.
FIG. 6. 
The object used in the real experiment.
FIG. 7. 
(a) The range image collected by the proposed imaging system and (b) the range image collected by the conventional imaging system.
FIG. 8. 
(a) The imaging model without any defocusing, (b) the imaging model with defocusing in the first imaging process, (c) the imaging model with defocusing in the second imaging process, and (d) the imaging model with defocusing in the two imaging processes.
FIG. 9. 
The final radius of laser spots on the APD array detector as a function of the defocusing ranges.
