Attractor controllability of Boolean networks by flipping a subset of their nodes
The controllability analysis of Boolean networks (BNs), as models of biomolecular regulatory networks, has drawn the attention of researchers in recent years. In this paper, we aim at governing the steady-state behavior of BNs using an intervention method which can easily be applied to most real system, which can be modeled as BNs, particularly to biomolecular regulatory networks. To this end, we introduce the concept of attractor controllability of a BN by flipping a subset of its nodes, as the possibility of making a BN converge from any of its attractors to any other one, by one-time flipping members of a subset of BN nodes. Our approach is based on the algebraic state-space representation of BNs using semi-tensor product of matrices. After introducing some new matrix tools, we use them to derive necessary and sufficient conditions for the attractor controllability of BNs. A forward search algorithm is then suggested to identify the minimal perturbation set for attractor controllability of a BN. Next, a lower bound is derived for the cardinality of this set. Two new indices are also proposed for quantifying the attractor controllability of a BN and the influence of each network variable on the attractor controllability of the network and the relationship between them is revealed. Finally, we confirm the efficiency of the proposed approach by applying it to the BN models of some real biomolecular networks.
I. INTRODUCTION
Boolean networks (BNs), first introduced by Kauffman [1], can be used to describe any system of interacting elements whose states can be quantized to two levels, ON (active) and OFF (inactive). Each node of a BN is assigned a Boolean function (BF) which represents how the value of that node is updated in the next time step according to the current values of other nodes. If the BFs depend on some exogenous inputs in addition to the network variables, the system is called a Boolean control network (BCN). One of the most popular applications of BNs is for modeling and analysis of gene regulatory networks (GRNs). In fact, BNs have been shown to be appropriate tools to describe cellular regulatory networks [2]. That is why they are presently in focus of attention among researchers and scientists in the fields of biology, genetics, and system sciences.
Controllability is one of the key concepts of systems theory and has drawn extensive attention in studying Boolean (control) networks. Roughly speaking, controllability refers to the ability to steer a system from any initial state to any final state via a suitable choice of input signals. Controllability analysis is basically concerned about the possibility of its objective; hence, it is a preliminary step toward design and implementation of intervention strategies for governing the behavior of biomolecular networks modeled as BNs [3]. Designing the exact intervention method for a network and its practical aspects are the next steps after establishing its controllability. It has been shown that, in general, control problems for BCNs are NP-hard [4].
Cheng and his colleagues used the semi-tensor product (STP) of matrices [5] to convert a BN (BCN) into an algebraic state space representation [6,7]. This novel approach facilitated the analysis of BNs/BCNs and thus stimulated a series of later works to solve many control-theoretic problems such as synchronization [8–10], controllability [11–14], observability [15,16], realization theory [17], disturbance decoupling [18,19], system decomposition [20], and stability and stabilization [21–23] of BNs/BCNs. The impact of function perturbations on singular Boolean networks has also been investigated via the same approach [24].
It has been shown that the structure of a BN alone cannot characterize its controllability and that the controllability of a BN also depends on its dynamics [25]. In Ref [12], a matrix called input-state incidence matrix of a BCN is proposed. Using this matrix, a necessary and sufficient condition for controllability of a BCN is derived. In Ref [3] using the theory of symbolic computation, a method for testing reachability, controllability, and observability of BNs has been proposed and applied to some different biological networks. In Ref [11], controllability via two kinds of controls, namely, controls generated by a control Boolean network and controls as a free Boolean sequence, have been investigated and necessary and sufficient conditions have been proved for each case by constructing reachable sets. Controllability via the same two kinds of controls have also been studied for BCNs with time-invariant delays in states [13]. Controllability of temporal BNs (BNs having time-variant delays) has also been addressed using semi-tensor product of matrices [26].
In addition to the common notion of controllability for BCNs, modified versions or special cases of this concept have also been considered by researchers. Some authors addressed the problem of controllability of BCNs while avoiding some forbidden states [27–29]. Others considered partial controllability of BCNs, that is, controllability with respect to a given part of network variables [30]. Controllability of BCNs using pinning control strategies has also been recently investigated [31,32].
In most research available about control of BNs (BCNs), manipulating the behavior of the network is accomplished by exertion of a sequence of exogenous inputs whose values are determined according to certain laws [11–14,26–32]. In some others, this task is carried out by fixing some of the network variables to prescribed values [34]. These methods, though theoretically valuable, may not always be easily applied to biomolecular regulatory networks in practice. The method we use for manipulating the steady-state behavior of BNs is flipping some of the network variables just once after the network has passed its transient period and thus has settled in one of its attractors. It is obvious that this method is much easier to implement compared with most other methods used for governing BNs' behavior [8–14,26–32].
On the other hand, in applications of BNs as models of biomolecular regulatory networks, since most of the time the system resides in an attractor, the transient behavior of the network is often insignificant [25]. Therefore, in this work, we aim at governing the steady-state behavior of BNs.
In this paper, considering the above issues about the ease of application of the intervention method and importance of steady-state behavior, we define the concept of attractor controllability of a BN by flipping a subset of its nodes as the possibility of making a BN converge from any of its attractors to any other one by one-time flipping members of a subset of its nodes after the network has passed its transient stage. Using the semi-tensor product of matrices, we develop some tools and theorems for verifying attractor controllability of BNs in this sense. These theorems may be used for the following objectives: First, given a subset of network variables that can be flipped, we can determine whether the BN is attractor controllable by flipping those variables. Second, in case of BNs all whose variables can be flipped, we can find the smallest-cardinality set of network variables flipping which will result in the BN being attractor controllable.
The remainder of the paper is organized as follows: In Sec. II, some preliminaries about BNs, the semi-tensor product of matrices, and its use for matrix expression of BNs, and some matrix tools for representing perturbations are reviewed. Section III contains our main results which include definitions for some new concepts, theorems, algorithms, and indices concerning attractor controllability of BNs. In Sec. IV, the results of the application of the proposed methods to the BN models of some real biomolecular regulatory networks are presented. Section V terminates the paper by some concluding remarks and discussions.
II. PRELIMINARIES
In this section, some basic concepts are presented which are prerequisites for developing our main results.
A. Boolean networks
A Boolean network is a discrete-time logical dynamic system which is defined as 
where x_{i}∈D={0,1} are Boolean variables and f_{i}:D^{n}→D, i =1, …, n are Boolean functions.
If we denote the set of a BN's nodes by N = {1,2,…,n}, the structure of the BN can be represented by a graph, G = (N,E), where E⊆N × N is the set of edges wherein (i, j) ∈ E (meaning there is a directed edge from node i to node j) if the dynamics of node j depends on node i. Such a graph is called the interaction graph or dependency graph of the BN [33].
Example 1: Consider a simple BN with the following update functions:
Its interaction graph is depicted in Fig. 1.
The state of the BN (1) at time t is a binary vector of length n, represented as x(t) = (x_{1}(t),x_{2}(t),…,x_{n}(t)) which we succinctly denote by x = (x_{1}, x_{2}, …, x_{n}). The system of equations in (1) can be succinctly represented as
In this paper, we denote the state space of a system by χ which will be equivalent to D^{n} for a BN of n variables.
x(k,x_{0}) represents the state of the BN starting from x_{0} after k state transitions. So x(t,x_{0}), t≥0, shows the state trajectory starting from x_{0}.
For a BN defined as (2), a graph composed of all points (states) in χ as vertices, with directed edges (links) from vertices such as S_{1} to vertices such as S_{2} provided that S_{2} = f(S_{1}) is called the state transition graph of the BN. Figure 2 shows the state transition graph for the BN of Example 1.
An attractor of a BN is a state (or a series of states) that is (are) repeated in time once the network adopts it (one of them). If for P∈χ we have P = f(P), then P is called a fixed point attractor of the BN. If P_{1},P_{2},…,P_{l} are distinct points in χ for which we have P_{k+1}=fP_{k},k=1,….,l−1, and P_{1}=f(P_{l}), then C = (P{1},P_{2},…,P_{l}) is called a cyclic attractor, or a cycle for short. In this case, l is called the length of the cycle. A fixed point is in fact a cycle of length 1. A set containing all the states that converge to a specific attractor is called its basin of attraction. An attractor landscape analysis is a procedure in which the attractors of a BN and their basins of attraction are identified [34]. In the squeal, we use the term “attracting point” to refer to a fixed point or to any member of a cycle. We call the set of all attracting points of a BN its attracting set and denote it by Λ.
B. STP and the algebraic representation of BNs
In this section, we present a brief review of STP and its application in transforming a BN to an algebraic state-space form, proposed by Daizhan Cheng and his colleagues [6].
The following notations are commonly used in most papers that are based on the aforementioned approach: 
• I_{n} is the identity matrix of order n.
• δniis the i-th column of I_{n}.
• Δ_{n}={δni|i=1,2,…,n}. In the case of n = 2, we simply denote it by Δ.
• δni_{1},i_{2},…,i{k}is the sum of δni_{1}, δni_{2},…, δni_{k}.
• Row{i}Ais the i-th row of A.
• Col{i}Ais the i-th column of A.
• ColAis the set of all columns of A.
• M_{m × n} is the set of all m × n matrices.
• A ∈ M_{m × n} is called a logical matrix if ColA⊆Δ_{m}. The set of m × n logical matrices is denoted by L_{m×n}.
• Let L ∈ L_{m×n} be a logical matrix. It can be written as L = [δmi_{1},δmi_{2},…,δmi_{n}]. In this case, a more compact notation as L = δ_{m}[i_{1},i_{2},…,i_{n}] is usually used for it.
• B = (b_{ij}) ∈ M_{m×n} is called a Boolean matrix if b_{ij} ∈ D, ∀i,j.
• N = {1, 2, …, n} represents nodes of a BN.
• P_{V}is the power set of the set V.
Definition 1: Let A ∈ M_{m × n} and B ∈ M_{p × q}; their semi-tensor product (STP) is denoted by A⋉B and is defined as 
where s = lcm(n,p), i.e., the least common multiple of n and p, and ⊗ is the Kronecker product.
The STP can be considered a generalization of the standard matrix product in which the necessity for the equality of n and p is eliminated. If n = p, the STP will be equivalent to the standard matrix product. All basic properties of the standard matrix product such as associativity and distributivity over addition are also valid for STP. Thus, we may omit “⋉” if no confusion arises.
Remark 1: If x_{1}, x_{2}, …, x_{n} are column (row) vectors of size r, x_{1} ⋉ x_{2} ⋉ … ⋉ x_{n} will be a column (row) vector of size r^{n}. Specifically, if x_{1}, x_{2}, …, x_{n}∈ Δ, then x_{1} ⋉ x_{2} ⋉ … ⋉ x_{n}∈ Δ_{2^{n}}.
We use δ21 as a vector equivalent for 1 or True, and δ22 as a vector equivalent for 0 or False. By adopting this equivalence, D and Δ will be equivalent. So logical variables and their vector equivalents may be used interchangeably. However, we use x_{i}∈D(italic font) for a logical variable and x_{i}(regular font) for its vector equivalent.
Let x = (x_{1}, x_{2}, …, x_{n})∈D^{n}, equivalently x = (x_{1}, x_{2}, …, x_{n})∈Δ^{n}; the mapping X=⋉i=1nx_{i} is a bijection from Δ^{n} to Δ_{2^{n}}, i.e., every x ∈Δ{n} corresponds to one and only one X∈Δ_{2^{n}} using this mapping.
If x = (x_{1}, x_{2}, …, x_{n}) is a binary vector (e.g., a BN's state) and X=⋉i=1nx_{i}=δ2^{n}j, we call δ2^{n}j the semi-tensor product representation (STPR) of x, and denote it by x ∼δ2^{n}j or X= STPR(x) interchangeably.
Remark 2: If we consider members of D^{n} in lexicographical order, i.e., from (0,0,…,0) to (1,1,…,1), their STPRs will be from δ2^{n}2^{n} to δ2^{n}1, respectively. A simple way to obtain the STPR of a given x∈D^{n} is to consider it as a binary number and turn it into decimal format. If its decimal equivalent is d, then the STPR of x will be δ2^{n}2^{n}−d. For example, if x=(1,0,1), considering it as a binary number, its decimal equivalent will be 5 and its STPR will be δ2^{3}2^{3}−5=δ83. Conversely, if the STPR of x∈D^{n} is known to be δ2^{n}i, then the elements of x can be recovered by converting d=2^{n}−i into its binary equivalent.
Lemma 1. Let f be a logical function of n arguments. Then, there exists a unique matrix M_{f}∈L_{2×2^{n}}, called the structure matrix of f, such that 
where X=⋉i=1nx_{i}. The above form is called the multi-linear representation of a logical function [6].
In Ref [6], a method for calculating M_{f} from the structure matrices of elementary logical operations is presented. Alternatively, M_{f} can be constructed as follows:
Remark 3: The first row of M_{f} contains the truth table values of the logical function f, filled from right to left, and its second row is the negation of its first row. Equivalently, the i-th column of M_{f} will be δ21(δ22) if the (2^{n}-i + 1)-th row of the truth table contains a value of 1 (0) for f.
Example 2: If n =2 and f(x_{1},x_{2}) = ∼x_{1}∧x_{2}, its truth table will be as follows:
So using Remark 3, the structure matrix of f will be
Using Lemma 1 and the mapping X=⋉i=1nx_{i}, system (1) can equivalently be represented as 
where M_{i}∈L_{2×2^{n}}, i =1, …, n are structure matrices of f_{i}, i =1, …, n, respectively.
Multiplying the above equations and then applying some simplifications will lead to the following lemma.
Lemma 2. Consider system (1). Define X=⋉i=1nx_{i}. Then there exists a unique matrix L∈L_{2^{n}×2^{n}}, called the transition matrix of the system, such that
Equation (6) is called the algebraic form of (1).
In Ref [6], a formula for computing L from the structure matrices of the Boolean functions f_{i}, i =1, …, n, (i.e., M_{1}, M_{2}, …, M_{n}) is presented. Alternatively, L can be constructed as follows: 
where x ∼δ2^{n}jj=1,…,2^{n} and f is as defined in (2).
Remark 4: If x_{0} ∼ P and x(t,x_{0}) ∼ Q, then by successive application of (6), we have Q=L^{t}P.
Definition 2: The transient period of a BN, denoted by T_{t}, is the smallest time such that starting from any arbitrary initial state in the state space, the state trajectory will reach an attractor within T_{t} time steps.
The transient period of a BN can be calculated using the following proposition [6]:
Proposition 1: Let L be the network transition matrix of a BN. Then its transient period is the smallest positive integer, r_{0}, which satisfies L^{r0}=L^{r0+T} for some T>0.
Remark 5: Let x_{0}∈χ be any initial state in the state pace of a BN and x_{0}∼X_{0}. According to the definition of transient period, the state trajectory starting from x_{0} will always enter the attracting set within T_{t} steps; hence, if q ∼ L^{t}X_{0} and t≥T_{t}, then q∈Λ.
For more details on STP and the algebraic state-space representation of BNs using STP, please refer to Refs [6] and  [7].
As explained in Sec. I, the intervention method used in our approach is flipping the values of a subset of the network variables once (after the system has passed its transient period). This type of intervention is also referred to as a one-time gene perturbation in the context of gene regulatory networks. For instance, in Ref [37], it is stated that “a one-time gene perturbation changes the value of one or more genes, which in a binary network means that the value of one or more genes is flipped at current moment.” In Sec. II C, we show how this type of intervention can be formalized in the form of matrix multiplications [38]:
C. Matrix representation of perturbations
Suppose we have numbered the nodes of a BN from 1 to n and assigned them to Boolean variables x_{1},x_{2},…,x_{n}, respectively. Let V = x_{i1},x_{i2},…x_{iv} be a (strict) subset of {x_{1},x_{2},…x_{n}}(or alternatively V = {i_{1}, i_{2}, …, i_{v}} be a (strict) subset of {1, 2, …, n}); then, we call it a (strict) perturbation set if it represents the network variables that we can flip.
Definition 3: Let S = {i_{1},i_{2},…i_{s}} be a perturbation set for a BN of n nodes. We defined the flip function with respect to S, denoted by fS↕x, as follows: 
i.e., x¯{S} is x with its i_{1}-th, i_{2}-th, … and i_{s}-th elements flipped.
Definition 4: Let S = {i_{1},i_{2},…i_{s}} be a perturbation set for a BN of n nodes. The flip matrix (of order 2^{n}) with respect to S is denoted by f_{S}∈M_{2^{n}×2^{n}} and defined as follows:
Equation (9) can also be written as
In this way, for any x ∈ χ, with x ∼ X and x¯{S}∼X¯{S}, we have
Definition 5: Now let V = {i_{1},i_{2},…i_{v}} be a perturbation set for a BN of n nodes; then, its power set is P_{V}= {∅,i_{1},…i_{v},…,V}. The combinatorial flip matrix (of order 2^{n}) with respect to V is denoted by F_{V}∈M_{2^{n}×2^{n}} and defined as follows:
That is, (F_{V})_{ij} = 1 if there exists a subset S ∈ P_{V} such that (f_{S})_{ij} = 1. It follows that
Note that for any two distinct subsets S_{1},S_{2}∈P_{V}, S_{1}≠S_{2} results in fS_{1}↕(x)≠fS_{2}↕(x) for any x ∼δ2^{n}j. Then, from (10), it is concluded that Col_{j}(f_{S1})≠Col_{j}(f_{S2}). So, the matrices in the right-hand side of the summation (13) do not have equal j-th columns (having 1s in the same positions) for any j. Therefore, the resulting matrix will be a Boolean matrix.
Remark 6: The j-th column of F_{V} is the collection (sum) of the STPRs of all the states that can be attained from x ∼ δ2^{n}j by flipping elements of every subset of V.
For more properties of the (combinatorial) flip matrix, please refer to Ref [38].
Here, we present an illustrative example.
Example 3: Let n =3 and V = {2,3}; then its power set is P_{V}= {∅,2,3,{2,3}}, and we have 
f_{∅}=I_{2^{3}}=δ_{8}[12345678], because every x∈χ is mapped to itself if no element of x is flipped.
f_{{2}}=δ_{8}[34127856]; because if x_{2} is flipped,
x = (111) ∼δ81 turns into x = (101) ∼δ83 and vice versa,
x = (110) ∼δ82 turns into x = (100) ∼δ84 and vice versa,
x = (011) ∼δ85 turns into x = (001) ∼δ87 and vice versa, and
x = (010) ∼δ86 turns into x = (000) ∼δ88 and vice versa;
f_{{3}}=δ_{8}[21436587]; because if x_{3} is flipped,
x = (111) ∼δ81 turns into x = (110) ∼δ82 and vice versa,
x = (101) ∼δ83 turns into x = (100) ∼δ84 and vice versa,
x = (011) ∼δ85 turns into x = (010) ∼δ86 and vice versa, and
x = (001) ∼δ87 turns into x = (000) ∼δ88 and vice versa;
f_{{2,3}}=δ_{8}[43218765]; because if x_{2} and x_{3} are flipped,
x = (111) ∼δ81 turns into x = (100) ∼δ84 and vice versa,
x = (110) ∼δ82 turns into x = (101) ∼δ83 and vice versa,
x = (011) ∼δ85 turns into x = (000) ∼δ88 and vice versa, and
x = (010) ∼δ86 turns into x = (001) ∼δ87 and vice versa.
According to (13), F_{{2,3}}=f_{∅}+f_{{2}}+f{3}+f{{2,3}}; hence, F_{{2,3}}=[δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8].
The 1st column of F_{V}, for example, is δ81,2,3,4 which signifies that x ∼ δ81 can be changed to δ81, δ82, δ83 or δ84 by flipping some of the x's elements specified by subsets of V. This is in accordance with Remark 6.
We call the state transition from x to x¯{S} a perturbed state transition. Consider the state transition graph of a BN as in Fig. 2. If we add directed links to it for every perturbed state transition involving an attracting point, the resulting graph is called the attractor-perturbed state transition graph (APSTG) of the BN with respect to V. Figure 3 shows an example of an APSTG. We represent perturbed transition by dashed links to distinguish them from normal transitions.
Definition 6: Let A_{1} ∼ δ2^{n}r_{1}, A_{2} ∼ δ2^{n}r_{2}…, A_{N} ∼ δ2^{n}r_{N} be members of the attracting set of a BN (which include fixed points and cycle members); we call the matrix 
the attracting matrix of the BN.
Definition 7: Let L and T_{t} be the network transition matrix and transient period of a BN, respectively. We denote the attractor controllability matrix of the BN with respect to a given perturbation set V, by Ω_{V}, and define it as follows:
Remark 7:Ω_{V} will be a 2^{n}×N matrix. Each row (the r-th row) of this matrix corresponds to one point (x∼δ2^{n}r) in χ. Each column (the cth column) of this matrix corresponds to an attracting point (A_{c}∼δ2^{n}r_{c}) of the BN.
As we will demonstrate, this matrix can be used for inspecting attractor controllability of BNs.
In Ref [38], we introduced attractor stabilizability of a BN by flipping a subset of its nodes. We defined a BN to be attractor stabilizable to a specific attractor, called the target attractor, by flipping members of a perturbation set, V, if it can be made to converge from anyone of its attracting points to the target attractor by one-time flipping some (from none to all) members of V. In that case, V is called a stabilizing perturbation set. A stabilizing perturbation set with minimum cardinality is called the minimal perturbation set for Attractor Stabilizability (MPS-AS) or the stabilizing kernel for the target attractor.
In Sec. III, we extend our previous results to attractor controllability of BNs.
III. MAIN RESULTS
In this study, we mainly focus on controllability of BNs as models of biomolecular regulatory networks. It has been shown that attractors of BN models of biomolecular networks correspond to different cell types or cell conditions [2]. In applications of BNs as models of biomolecular regulatory networks, since most of the time the system resides in an attractor, the transient behavior of the network is often insignificant [25]. We are thus usually more interested in governing the steady-state behavior of the network, that is, finding methods to drive the network from one attractor to another which may correspond, for example, to steering a cell from a diseased to a normal phenotype [39].
A. Attractor controllability of a BN
Assume that a BN has passed its transient period and thus has entered one of its attractors. Let V = {x_{i1},x_{i2},…,x_{iv}} be a strict perturbation set. The question is whether the BN can be made to converge from any of its attractors to any other one by one-time flipping some members of V. The following definition is inspired by Ref [25].
Definition 8: Let V be a strict perturbation set for a BN whose attracting set is Λ. We say, the BN is attractor controllable by flipping members of V, if for any starting attracting point, z∈Λ, the following two conditions hold: 
(1) for any fixed point attractor, P, there exist S⊆V,T∈Z_{+} such that x(t,z¯{S})= P, ∀t ≥ T, and
(2) for any cyclic attractor, C, there exist S⊆V,T∈Z_{+}, such that x(t,z¯{S})∈C, ∀t ≥ T.
In terms of the network's state transition graph, a BN is attractor controllable by flipping elements of a subset of its nodes, V, if there is a directed path from any of its attracting points to any other attractor in the APSTG of the network with respect to V.
Theorem 1: Let V={x_{i1},x_{i2},…,x_{iv}} be a perturbation set, T_{t} be the transient period of a BN and Ω_{V} be the attractor controllability matrix defined in Definition 7; then ΩV{ij} equals the number of ways we can make the network converge from the attracting point A_{j} ∼ δ2^{n}r_{j}, to the destination point x^{d} ∼ δ2^{n}i, by one-time flipping some (from none to all) members of V and then having T_{t} state transitions.
Equivalently, ΩV{ij} counts the number of directed paths of T_{t} links (not counting the dashed link), from the attracting point A_{j}∼δ2^{n}r_{j}, to the destination point x^{d}∼δ2^{n}i, in the APSTG of the network with respect to V [38].
Proof. For any two matrices A and B, Col{j}AB=ACol{j}B; hence,
From (14), Col{j}Ω=δ2^{n}r_{j}, thus it follows 
because for any matrix A∈M_{m×2^{n}}, Aδ2^{n}i=Col_{i}A.
Multiplying both sides by L^{Tt} results in
On the other hand, from (15), we have
Comparing (16) and (17) results in
According to Remark 6, Col_{rj}(F_{V}) indicates the collection of the STPRs of all the states that can be attained from attracting point A_{j}∼δ2^{n}r_{j}, by flipping some (from none to all) elements of V. Thus, taking Remark 4 into consideration, we conclude that L^{Tt}Col_{rj}(F_{V})[which equals Col{j}Ω_{V} according to (18)] will give the sum (collection) of the STPRs of all the states that can be attained from the attracting point A_{j}∼δ2^{n}r_{j} by flipping some (from none to all) elements of V once, and then having T_{t} state transitions. So its i-th entry [which equals ΩV{ij}] gives the sum of the STPRs of all the states that reach δ2^{n}i from attracting point A_{j}∼δ2^{n}r_{j} by flipping some elements of V once, after T_{t} state transitions. In other words, it shows the number of ways we can steer the network from the attracting point A_{j}∼δ2^{n}r_{j}, to the destination point x^{d}∼δ2^{n}i, by one-time flipping some network variables which are subsets of V. For an alternative (more formulized) proof of this theorem, you may refer to Ref [38].
Note: In the sequel, we represent a cycle such as C∼(δ2^{n}r_{1},δ2^{n}r_{2},…,δ2^{n}r_{k}) by its compact form C∼δ_{2^{n}}(r_{1},r_{2},…,r_{k}).
Corollary 1: If C is a cycle, represented as δ_{2^{n}}(r_{1},r_{2},…,r_{k}), then ∑i=1k(Ω_{V}){rij} is equal to the number of ways we can make the network converge from the attracting point A_{j}∼δ2^{n}r_{j}, to (a member of) the cycle C by one-time flipping some members of V, and then having T_{t} state transitions. This is also equal to the number of directed paths from the attracting point A_{j}∼δ2^{n}r_{j}, to (a member of) the cycle C, in the APSTG of the network with respect to V [38].
We used Theorem 1 and Corollary 1 to establish necessary and sufficient conditions for attractor stabilizability of BNs [38]; in this paper, we use them to establish necessary and sufficient conditions for attractor controllability of BNs.
Considering Theorem 1 and Corollary 1 together with Definition 8, the following result can easily be inferred.
Theorem 2: Consider a BN with k fixed point attractors represented by δ2^{n}r_{1}, δ2^{n}r_{2}, …, δ2^{n}r_{k} and m cyclic attractors, C^{1}∼δ_{2^{n}}(r11,r21,…,rl_{1}1), …, C^{m}∼δ_{2^{n}}(r1m,r2m,…,rl_{m}m), with lengths l_{1}, …, l_{m}, respectively.
Let V={x_{i1},x_{i2},…,x_{iv}} be a strict perturbation set and Ω_{V} be the attractor controllability matrix with respect to V, defined in Definition 7; the BN is attractor controllable by flipping members of V if 
and
Note that for a vector or a matrix such as A, the inequality A > 0 means all elements of A are positive. So, condition (19) necessitates that all elements of the rows of Ω_{V} which correspond to the fixed point attractors be positive; this, according to Theorem 1 and Remark 7, means that there should be at least one way for steering the network from every attracting point to every fixed point attractor. Condition (20) necessitates that for any cyclic attractor, in each column of Ω_{V}, at least one of the rows which correspond to that cycle contain a nonzero value; this, according to Theorem 1 and Remark 7, means that there is at least one way for steering the network from every attraction point to (a member of) any cycle.
Note that in order to make a network converge to a cyclic attractor, it suffices to steer it to one member of that cycle.
A perturbation set satisfying (19) and (20) while having minimum cardinality is called minimal perturbation set for attractor controllability (MPS–AC) for the BN.
It should be noted that the intervention method used in this work does not modify the natural dynamics of the system. It merely resets the state of the BN to a new initial state. Therefore, the attractors of the BN remain intact under this type of intervention. In fact, the dynamics of the BN can be described by (6) both before and after applying the intervention. But its state transition is performed according to (11) at the moment of applying the intervention. Below, we study an illustrative example.
Example 4: Consider the BN of Example 1.
Its state transition graph is depicted in Fig. 2. It has three fixed point attractors (1,1,1) ∼δ81, (0,1,0) ∼δ86 and (0,0,0) ∼δ88 which we name A_{1}, A_{2}, and A_{3}, respectively. So, its attracting matrix can be represented as Ω= δ_{8}[1, 6, 8]. As we will see, the BN is attractor controllable by flipping members of the perturbation set V = {2, 3}.
As shown in Example 3, the combinatorial flip matrix with respect to V = {2, 3} is F_{{2,3}}=[δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8].
Using (7), it is easy to check that the network transition matrix for this network is L = δ_{8}[1, 6, 4, 8, 1, 6, 4, 8].
Using Proposition 1, we obtain T_{t} = 2. Now using the above F_{V} and the transition matrix, L, to calculate Ω_{V} according to (15) results in
Recalling that the attractors of this BN are A_{1} ∼ δ81, A_{2} ∼ δ86 and A_{3} ∼ δ88, condition (19) becomes Row_{1}Ω_{V}>0, Row_{6}Ω_{V}>0 and Row_{8}Ω_{V}>0 which obviously holds true. So, this BN is attractor controllable by flipping members of V = {x_{2},x_{3}}.
Figure 3 shows the APSTG for this network with respect to V = {2, 3}. State transitions to/from attracting points due to flipping every subset of V are depicted by dashed links. As it can be seen, there is a directed path from every attractor to every other attractor.
Furthermore, it can be verified from Fig. 3 that (Ω_{V}){ij} equals the number of existing directed paths (of length T_{t} = 2, not counting the dashed link), containing at most one dashed link (perturbed transition), from the attracting point A_{j}, j =1, 2, 3, to the destination point δ8i, i =1,…,8.
We now propose and prove a proposition which shows a relation between the sizes of MPS–AC and MPS-ASs of a BN.
Proposition 2: Consider a BN with m attractors, A_{1}, A_{2}, …, A_{m}, some of which might be cyclic (composed of several states). Let V be the MPS-AC for this BN, and S_{1}, S_{2}, …, S_{m} be the MPS-ASs for the target attractors A_{1}, A_{2}, …, A_{m}, respectively; then, we have 
i.e., the cardinality of MPS-AC of a BN is an upper bound for the cardinalities of MPS-ASs for all of its attractors.
Proof. We prove it by contradiction. Assume that there is an attractor A_{k}, whose MPS-AS, S_{k}, has a cardinality greater than |V|. According to the definition of MPS-AS, any perturbation set with smaller cardinality, particularly V, cannot be a stabilizing perturbation set for A_{k}. This is in contradiction to the assumption that V is the MPS-AC of the BN (considering the definition of MPS-AC). So, |S_{k}|>|V| cannot be true.
In fact, by considering the definitions of the MPS-AC and the stabilizing perturbation set, one can easily deduce that an MPS–AC for a BN is also a stabilizing perturbation set for any target attractor of that BN. Then, recalling that the cardinality of the MPS-AS for a target attractor is always less than or equal to the cardinality of any stabilizing perturbation set for that attractor, the above proposition is easily justified.
We can use Theorem 2, established in this section, to find the MPS–AC of biomolecular regulatory networks modeled as BNs. Since we are looking for sets of minimum cardinality, a forward search algorithm can be used to find the MPS–AC of BNs.
Consider a BN whose attractors are described as in Theorem 2. In the following, we summarize the procedure for identifying the MPS–AC for such a BN in the form of a step-by-step algorithm: 
• Perform an attractor landscape analysis for the given BN; then, form the attracting matrix of the BN, Ω.
• Calculate the transition matrix, L, the transient period, T_{t}, and then L^{Tt}.
• For r =1 to n–1 (since we seek strict subsets),
for V =every combination of choosing r out of n variables,
Calculate F_{V}(with respect to the candidate set V) and then Ω_{V}=L^{Tt}F_{V}Ω.
If Row{ri}Ω_{V}>0 for every fixed point, P_{i}∼δ2^{n}r_{i}, i = 1,…,k, and ∑i=1l_{j}Row{rij}(Ω_{V})>0 for every cyclic attractor, C^{j}∼δ_{2^{n}}(r1j,r2j,…,rl_{j}j), j = 1,…, m, then return V as the MPS-AC.
The algorithm may be stopped as soon as an MPS-AC is found. But, note that the MPS–AC for a BN need not be unique. So, if a set with minimum cardinality, r_{m}, is found to satisfy the conditions, we may continue to check all candidate sets of r_{m} elements if we wish to find all possible choices of MPS–ACs.
One drawback of the forward search algorithm is its relatively high computational time in the case of large BNs or BNs with large-cardinality MPS-AC. This is because this method involves the enumeration of the candidate sets until finding the MPS-AC whose possible case for identifying the minimal perturbation set is O(2^{n}) in the worst case, though it was actually much less in most cases we studied in our research. As a result, this method can be used effectively as long as the enumeration of the candidate sets until finding the MPS-AC is tractable. Hence, it cannot be used for BNs of large size and/or with large-cardinality MPS-ACs.
To obtain a measure of how large the cardinalities of the MPS-ACs of BNs typically are relative to network sizes, we identified the MPS-ACs of 480 randomly generated BNs. We tried to generate the random BNs with structures and Boolean functions similar to those prevalent in BN models of biomolecular regulatory networks. For details on how to generate such random BNs, please refer to the appendix. For each BN, we computed the ratio of the cardinality of the MPS-AC to the network size. Then, we averaged these ratios over the 480 checked cases. As a result, the mean ratio of the cardinality of the MPS-AC to the network size turned out to be about 0.4. Therefore, although in the forward search algorithm the number of candidate subsets to be checked is 2^{n}–2 in the worst case (∅ and N are excluded from the candidate sets), we have to check candidate subsets with cardinalities up to 0.4n in the average case. So, the computational time of the algorithm can be expected to be much less than the worst case mentioned above, in most of the cases. Besides, we propose three solutions to cope with the problem of high computational time for large BNs.
The first solution for expanding the applicability of the forward search method to larger networks is to apply model reduction techniques [35,36]. These methods provide simplified models of larger networks which retain the essential properties of the original networks.
To introduce the second solution, we first need to state and prove the following proposition about the cardinality of the MPS-AC of a given BN:
Proposition 3: Consider a BN with m attractors. Let V be the MPS-AC for this BN with V=v; then we have 
where a is the smallest integer greater than or equal to a. In other words, log_{2}m is a lower bound for the cardinality of the MPS-AC of the BN.
Proof. Let V be a perturbation set for this BN with V=v and Λ be the attracting set of the BN. For any x ∈ Λ the set x¯{S}=fS↕x|S∈P_{V} will have exactly 2^{v} members (Because the function fS↕x will map x to distinct values of x¯{S} for distinct subsets S∈P_{V}; and there are exactly 2^{v} subsets in P_{V}) which can converge to 2^{v} different attractors in the best case. But if V is to be an MPS-AC for this BN, according to the definition, for any x∈Λ, members of the set x¯{S}|S∈P_{V} should converge to m different attractors. This can only happen if 2^{v}≥m, or equivalently v ≥log_{2}m. Since v is assumed to be an integer, we should have v ≥log_{2}m. Q.E.D.
Using the above proposition, we can revise the forward search algorithm to decrease its computational time. To this end, we change the third step of the algorithm in the following way: 
• For r=v_{min} to n−1, ….where v_{min}=log_{2}m is the lower bound obtained in Proposition 3.
The third solution to mitigate the computational time of the forward search method will be proposed at the end of Sec. III C.
B. Quantifying attractor controllability
A question which may arise after studying the theories presented so far in this paper is that if the objective is to steer the BN from any of its attractors to any other one, and if one has to choose between several possible perturbation sets for this purpose, on what basis such a selection could be made. In answer to this question, if one (or more) of the candidate sets is an MPS-AC, it would be the best choice, since it provides full attractor controllability. Otherwise, it would be beneficial if we could have a criterion for quantifying the attractor controllability provided by a given perturbation set. To this end, we introduce an index for quantifying the attractor controllability, called percentage of attractor controllability (PAC) with respect to a specific perturbation set.
Let Λ={P_{1},P_{2},….,P_{N}} be the attracting set of a BN. If m is the number of attractors of this BN, it is obvious that N≥ m; because some attractors (i.e., cycles) may consist of more than 1 attracting points.
Let V be a perturbation set; for P_{i}∈Λ, we define R_{V}(P_{i}) to be the number of attractors reachable from attracting point P_{i}, in the APSTG of the BN with respect to V. [We say, an attractor is reachable from P_{i} if there is a directed path from P_{i} to (a member of) that attractor in the APSTG.] Thus, for every V⊆N, we have 1≤R_{V}P_{i}≤m(because at least the attractor which includes P_{i} is reachable from P_{i}). Note that R_{∅}P_{i}=1, since the only attractor reachable from P_{i} is the attractor which includes P_{i} if no variables are flipped. If V is (a super set of) an MPS-AC then R_{V}P_{i}=m.
Note: In this section, when talking about an attracting point such as P_{i}, by “other attractors,” we mean all attractors except P_{i} if P_{i} is a fixed point, and we mean all the attractors except the attractor which includes P_{i} if P_{i} is a member of cycle.
We denote the fraction of reachable attractors from the attracting point P_{i} by flipping members of V, by r_{V}P_{i} and define it to be the number of other attractors reachable from P_{i} normalized by the total number of other attractors; that is
Note that r_{∅}P_{i}=0 because in an unperturbed network the basins of attraction for various attractors are disjoint and no attractor is reachable from another attractor. If we can make the network converge to every other attractor from the attracting point P_{i}, by flipping members of V, then we have r_{V}P_{i}=1. In general, 0≤r_{V}P_{i}≤1. If r_{V}P_{i}=1 for every i =1, 2, …, N, then the BN is attractor controllable with respect to V.
Definition 9: We denote the percentage of attractor controllability (PAC) with respect to the perturbation set V, by π_{V}, and define it as follows:
It is, in fact, the average fraction of reachable attractors from all attracting points expressed as a percentage. It is obvious that if we can make the network converge from every attracting point P_{i},i =1, …N, to every other attractor by flipping members of V, then we have π_{V}=100%, which means the BN is fully attractor controllable with respect to V. It can be concluded that if a perturbation set is an MPS-AC or a superset of an MPS-AC, then its PAC is 100%. For any strict subset of an MPS-AC, PAC < 100%. But PAC is closer to 100% for perturbation sets which result in the perturbed network being closer to full attractor controllability. Hence, PAC provides a measure of how good a perturbation set is for the purpose of attractor controllability.
Example 5: Consider the BN of Example 1.
Table I indicates the PACs for each of the possible perturbation sets for this BN.
We recall from Example 4 that the MPS-AC for this BN was V = {x_{2}, x_{3}}. As it can be observed in Table I, π_{V} is 100% for this set and its superset, that is {x_{1}, x_{2}, x_{3}}, and is less than 100% for every other perturbation set.
C. Convergence influence of a network node
The PAC index, introduced in Subsection III B, quantifies how good a given perturbation set is for the purpose of attractor controllability of a BN. But, another question which may arise in studying attractor controllability of BNs is how effective (flipping) a BN variable is in steering the network from every one of its attractors to its other attractors.
To answer this question, we introduce another index which quantifies the impact of (flipping) a BN's variable on its attractor controllability.
Definition 10: Assume a BN with m attractors, A_{1}, A_{2}, …, A_{m}, some of which might be cyclic (composed of several states). Let R_{1}, R_{2}, …, R_{m} be the basins of attraction for the attractors A_{1}, A_{2}, …, A_{m}, respectively. We denote the Attraction function of a BN by Ax and define it as follows:
For z∈χ,Az = k if z∈R_{k}, i.e., ∃T∈Z_{+},xt,z=A_{k}(or xt,z∈A_{k} in the case of a cyclic attractor),∀t≥T.
Then, we denote the convergence influence of the i-th network variable by C_{i} and define it as follows: 
where x¯{{i}} is x with its i-th element flipped.
The above index indicates the fraction of attracting points in which flipping x_{i} will cause the network to converge to a different attractor.
Example 6: Consider the BN of Example 1.
The convergence influences of its nodes are calculated and presented in Table II.
If one compares Tables I and II, they realize that the perturbation sets consisting of variables with higher convergence influences usually have higher percentages of attractor controllability. It is thus reasonable to guess that there might be a special relationship between the values of the variables' convergence influences with their probability of membership in the MPS-AC. In order to verify such an inference, we computed the convergence influences of the variables of an ensembles of 480 randomly generated BNs, and then (for each network), we sorted the network variables in descending order according to their convergence influence values. We represented the sorted variables (for every BN) by x_{i1},x_{i2},…x_{in}, respectively. We also identified the MPS-ACs for all of the BNs using the method proposed at the end of Sec. III A. We then computed the percentages of membership of (the instances of) the sorted variables x_{i1},x_{i2},…,x_{in}(over all random BNs) in the MPS-ACs of their respective BNs. Figure 4 demonstrates the percentages of membership of (the instances of) each of the sorted variable x_{i1} to x_{i7}, in the MPS-ACs of their respective BNs.
As it can be seen, the 1st variables in the sorted lists, i.e., the variables with the highest convergence influences, have been a member of the MPS-AC in almost 100% of the cases (the percentage values in Fig. 4 have been rounded to the nearest integers). For the other variables in the sorted lists, those with higher convergence influences have had higher percentages of membership in the MPS-ACs of their respective BNs. This observation confirms our conjecture about the relationship between the values of the variables' convergence influences with their probability of membership in the MPS-ACs.
We also observed that for perturbation sets of equal size, those consisting of elements with higher (average or sum) convergence influences resulted in higher values of PAC in most of the cases.
We can use the results of these observations to increase the speed of the proposed algorithm for identifying the MPS-AC presented at the end of Sec. III A. That is, instead of searching through an arbitrary sequence of network variables, it is more efficient to sort the variables in descending order according to their convergence influences, and then choose the candidate sets from the sorted list. In this way, the algorithm will identify the MPS-AC in a shorter time since the variables with higher convergence influences are more probable to be members of the MPS-AC.
IV. APPLICATION TO BIOMOLECULAR REGULATORY NETWORKS
In the case of gene regulatory networks, flipping the value of a node is equivalent to down-regulation (gene silencing) or up-regulation (over-expression) of a gene using external stimuli. Various techniques have so far been proposed to this end. For example, RNA interference (RNAi) [40] and antisense oligonucleotides (ASOs) [41] are two known methods for gene silencing, and CRISPRa is a technique used to upregulate the expression of a target gene [42]. For a thorough comparison of the practical techniques for changing gene-expression state in cells (by means of external stimuli), see Ref [43].
We have investigated the attractor controllability of several biomolecular regulatory networks, by applying the algorithm proposed in Sec. III A to their BN models. These networks include (a) the Saccharomyces cerevisiae (baker's yeast) cell cycle network [44], (b) the gene regulatory network (GRN) underlying mammalian cortical area development [45] and, the (c) the GRN underlying mouse myeloid development [46]. In each case, we aimed to identify the MPS–AC of the BN.
A. Saccharomyces cerevisiae cell cycle network
We used a simplified Boolean model of the S. cerevisiae cell cycle network [44]. It consists of 11 nodes (biomolecules) whose names are abbreviated as Cln3, MBF, SBF, Cln1_2, Cdh1, Swi5, Cdc20_Cdc14, Clb5_6, Sic1, Clb1_2 and Mcm1_SFF to which we assigned indices 1 to 11, respectively. First, by performing an attractor landscape analysis, we identified the attractors of this BN. We found that the network has 7 fixed point attractors. The attracting set of this BN can be represented as
So, the attracting matrix of this BN is
Using Proposition 1, we computed the transient period of this BN which turned out to be T_{t} = 16.
It can be checked via straightforward computation that V = {x_{2}, x_{3}, x_{4}, x_{5}, x_{9}} or {“MBF,” “SBF,” “Cln1_2,” “Cdh1,” “Sic1”} satisfies (19). That is, using this V and (26) to calculate Ω_{V}=L^{16}F_{V}Ω, it can be easily verified that Row{r}Ω_{V}>0, for ∀r∈{1468,1532,1664,1980,1984,2044,2048}.
Since no perturbation set with smaller cardinality can be found to satisfy (19), this V can be declared as the MPS–AC for this BN; that is, if the values of MBF, SBF, Cln1_2, Cdh1, and Sic1 can be flipped, then the BN can be made to converge from any of its attractors to any other one by one-time flipping some of these nodes.
B. GRN underlying mammalian cortical area development
The simplified Boolean model of the GRN underlying mammalian cortical area development [45] consists of 10 nodes (5 genes and 5 proteins) whose abbreviated names are Fgf8_{g}, Emx2_{g}, Pax6_{g}, Coup_tfi_{g}, Sp8_{g}, Fgf8_{p}, Emx2_{p}, Pax6_{p}, Coup_tfi_{p}, and Sp8_{p}. We assigned these nodes to variables x_{1} to x_{10}, respectively. Our attractor landscape analysis revealed that the network has three attractors, two of which are fixed points and the third is a cycle of length 2. The attracting set of this BN can be represented as 
where the parentheses are used to distinguish the cyclic attractor. So, the attracting matrix of this BN is
We also computed the transient period of the network which was T_{t} = 8. Using (27) to compute Ω_{V} for the candidate perturbation sets and utilizing the forward search algorithm mentioned at the end of Sec. III A, one can easily check that V = {x_{1}, x_{2}, x_{5}, x_{6}, x_{7}, x_{10}} or {“Fgf8_{g},” “Emx2_{g},” “Sp8_{g},” “Fgf8_{p},” “Emx2_{p},” “Sp8_{p}”} satisfies (19) and (20). That is, using the above V in calculating Ω_{V}=L^{8}F_{V}Ω, it can be easily verified that Row{331}(Ω_{V})>0, Row{694}(Ω_{V})>0 and Row{342}Ω_{V}+Row{683}(Ω_{V})>0.
Since no perturbation set with less cardinality can be found to satisfy (19) and (20), the aforementioned perturbation set is the MPS–AC for this network.
C. GRN underlying mouse myeloid development
The simplified Boolean model of the GRN underlying mouse myeloid development [46] consists of 11 nodes whose names are abbreviated as GATA_2, GATA_1, FOG_1, EKLF, Fli_1, SCL, CEBPa, PU1, cJun, EgrNab and Gfi_1, which we numbered from 1 to 11, respectively. The attractor landscape analysis for this BN shows that it has 8 attractors, of which two are cyclic and the rest are fix points. The attracting set of this BN can be represented as 
where the parentheses are used to distinguish the cyclic attractors. So, the attracting matrix of this BN is 
The transient period of this network turned out to be T_{t} = 5.
It can easily be checked that using V = {x_{2}, x_{4}, x_{5}, x_{7}, x_{8}, x_{9}, x_{10}, x_{11}} or {“GATA_1,” “EKLF,” “Fli_1,” “CEBPa,” “PU1,” “cJun,” “EgrNab,” “Gfi_1”} together with (28) to calculate Ω_{V}, leads to the conditions (19) and (20) being satisfied. That is, 
and Row_{1248}(Ω_{V})+Row{1056}(Ω_{V})>0, and Row_{1511}(Ω_{V})+Row{1583}(Ω_{V})>0.
With no smaller set having this property, the identified set is the MPS–AC for this network.
The MPS-AS for the (primary) target attractors of the biomolecular regulatory networks studied in this section were identified in Ref [38]. Their cardinalities were 1 for the first, 2 for the second, and 3 for the third network. It can be observed that, in all of the cases, the cardinality of MPS–AC is greater than that of the MPS-AS for the (primary) target attractor. This is reasonable, since trying to steer the network to all of its attractors normally needs greater intervention than trying to steer it to one of its attractors. This is also in conformity with Proposition 2.
For the logical rules of the BNs of the cases A, B, and C, studied in this section, please refer to Refs [44–46], respectively.
V. CONCLUSION
In this paper, we focused on governing the steady-state behavior of BNs as models of biomolecular regulatory networks. To this end, the concept of attractor controllability of BNs was introduced as the possibility of making a BN converge from any of its attractors to any other one by flipping some of the network variables just one time after the network's transient period. Using a characteristic matrix, called attractor controllability matrix, necessary and sufficient conditions for the verification of attractor controllability were presented. Then, a forward search algorithm was proposed to identify the minimal perturbation set for attractor controllability (MPS-AC) of a given BN. We showed that the cardinality of the MPS-AC of a BN is an upper bound for the cardinalities of the minimal perturbation sets for attractor stabilizability (MPS-AS) for its various target attractors. Besides, a lower bound was derived for the cardinality of the MPS-AC. This lower bound was used to decrease the computational cost of the forward search algorithm. We also introduced two indices: (i) the percentage of attractor controllability, for quantifying the extent of attractor controllability achieved by a specific perturbation set and (ii) the convergence influence, for evaluating how influential each network node is in the attractor controllability of the network. It was shown that nodes with higher convergence influences are more likely to be members of the MPS-AC. The developed methods were successfully applied to several BN models of real biomolecular networks, revealing which genes (or proteins) need to be upregulated/downregulated to steer the networks from any of their attractors to any other one.
One limitation for the application of our approach is that it cannot be applied to large-scale BNs because the sizes of the involved matrices grow exponentially with the size of the network. However, this drawback is common to all approaches based on the algebraic state-space representation of BNs using semi-tensor product of matrices.
Although the forward search algorithm proposed for identifying the MPS-ACs of BNs has a high computational cost (for large BNs) in its worst case, we showed that the computational time is much less in the average case. Moreover, we proposed several solutions to mitigate the computational cost of this algorithm.
The use of BNs is quite prevalent for modeling biomolecular regulatory networks and the approach proposed in this paper can be used to identify the nodes of the BN models of real systems, by flipping which we can drive the network from any undesired steady state to any desired one. On the other hand, flipping the value of some nodes just once in a biomolecular regulatory network is easier to implement compared with most other intervention methods. Thus, our approach is quite appropriate to be used by biologists and geneticists in applications such as drug target discovery, cell reprogramming or cell fate determination, in all of which they seek to govern the steady-state behavior of the network by exerting minimum interventions on the system.
Biomolecular regulatory networks are important parts in the cells of living organisms. Governing the behavior of such networks has been an appealing objective for researchers in the fields of biology, genetics, and medicine. Boolean networks (BNs) have been shown to be appropriate tools for modeling biomolecular regulatory networks. A BN's state will eventually converge to some particular states called attractors of the BN. In application of BNs as models of biomolecular regulatory networks, attractors of the BN correspond to different cell types or different cell conditions. Hence, developing methods for governing the steady-state behavior of BNs is particularly beneficial for manipulating the condition or fate of cells. Various intervention methods have been proposed to this end. We use an intervention method which is much easier to apply to biomolecular regulatory networks compared with all other proposed methods, that is, to flip (change from ON to OFF or vice versa) the values of some network variables just one time after the network has passed its transient period. Controllability is one of the key concepts in control theory which examines the possibility of driving a system from any initial state to any final state in a finite time by applying a suitable sequence of inputs. In this paper, based on the aforementioned intervention method, we pioneer the concept of attractor controllability of BNs in a way that it best suits our intended field of application, that is, biomolecular regulatory networks. We then derive necessary and sufficient conditions for verifying attractor controllability of a BN using some new matrix tools. We use these results to identify a minimal subset of network variables that by flipping its members we can make the BN attractor controllable. We then unveil some facts about the possible sizes of such sets. We will also show how we can quantify the attractor controllability of a BN, and measure the influence of each node of a BN on its attractor controllability.
Boolean networks (BNs), first introduced by Kauffman [1], can be used to describe any system of interacting elements whose states can be quantized to two levels, ON (active) and OFF (inactive). Each node of a BN is assigned a Boolean function (BF) which represents how the value of that node is updated in the next time step according to the current values of other nodes. If the BFs depend on some exogenous inputs in addition to the network variables, the system is called a Boolean control network (BCN). One of the most popular applications of BNs is for modeling and analysis of gene regulatory networks (GRNs). In fact, BNs have been shown to be appropriate tools to describe cellular regulatory networks [2]. That is why they are presently in focus of attention among researchers and scientists in the fields of biology, genetics, and system sciences.
Controllability is one of the key concepts of systems theory and has drawn extensive attention in studying Boolean (control) networks. Roughly speaking, controllability refers to the ability to steer a system from any initial state to any final state via a suitable choice of input signals. Controllability analysis is basically concerned about the possibility of its objective; hence, it is a preliminary step toward design and implementation of intervention strategies for governing the behavior of biomolecular networks modeled as BNs [3]. Designing the exact intervention method for a network and its practical aspects are the next steps after establishing its controllability. It has been shown that, in general, control problems for BCNs are NP-hard [4].
Cheng and his colleagues used the semi-tensor product (STP) of matrices [5] to convert a BN (BCN) into an algebraic state space representation [6,7]. This novel approach facilitated the analysis of BNs/BCNs and thus stimulated a series of later works to solve many control-theoretic problems such as synchronization [8–10], controllability [11–14], observability [15,16], realization theory [17], disturbance decoupling [18,19], system decomposition [20], and stability and stabilization [21–23] of BNs/BCNs. The impact of function perturbations on singular Boolean networks has also been investigated via the same approach [24].
It has been shown that the structure of a BN alone cannot characterize its controllability and that the controllability of a BN also depends on its dynamics [25]. In Ref [12], a matrix called input-state incidence matrix of a BCN is proposed. Using this matrix, a necessary and sufficient condition for controllability of a BCN is derived. In Ref [3] using the theory of symbolic computation, a method for testing reachability, controllability, and observability of BNs has been proposed and applied to some different biological networks. In Ref [11], controllability via two kinds of controls, namely, controls generated by a control Boolean network and controls as a free Boolean sequence, have been investigated and necessary and sufficient conditions have been proved for each case by constructing reachable sets. Controllability via the same two kinds of controls have also been studied for BCNs with time-invariant delays in states [13]. Controllability of temporal BNs (BNs having time-variant delays) has also been addressed using semi-tensor product of matrices [26].
In addition to the common notion of controllability for BCNs, modified versions or special cases of this concept have also been considered by researchers. Some authors addressed the problem of controllability of BCNs while avoiding some forbidden states [27–29]. Others considered partial controllability of BCNs, that is, controllability with respect to a given part of network variables [30]. Controllability of BCNs using pinning control strategies has also been recently investigated [31,32].
In most research available about control of BNs (BCNs), manipulating the behavior of the network is accomplished by exertion of a sequence of exogenous inputs whose values are determined according to certain laws [11–14,26–32]. In some others, this task is carried out by fixing some of the network variables to prescribed values [34]. These methods, though theoretically valuable, may not always be easily applied to biomolecular regulatory networks in practice. The method we use for manipulating the steady-state behavior of BNs is flipping some of the network variables just once after the network has passed its transient period and thus has settled in one of its attractors. It is obvious that this method is much easier to implement compared with most other methods used for governing BNs' behavior [8–14,26–32].
On the other hand, in applications of BNs as models of biomolecular regulatory networks, since most of the time the system resides in an attractor, the transient behavior of the network is often insignificant [25]. Therefore, in this work, we aim at governing the steady-state behavior of BNs.
In this paper, considering the above issues about the ease of application of the intervention method and importance of steady-state behavior, we define the concept of attractor controllability of a BN by flipping a subset of its nodes as the possibility of making a BN converge from any of its attractors to any other one by one-time flipping members of a subset of its nodes after the network has passed its transient stage. Using the semi-tensor product of matrices, we develop some tools and theorems for verifying attractor controllability of BNs in this sense. These theorems may be used for the following objectives: First, given a subset of network variables that can be flipped, we can determine whether the BN is attractor controllable by flipping those variables. Second, in case of BNs all whose variables can be flipped, we can find the smallest-cardinality set of network variables flipping which will result in the BN being attractor controllable.
The remainder of the paper is organized as follows: In Sec. II, some preliminaries about BNs, the semi-tensor product of matrices, and its use for matrix expression of BNs, and some matrix tools for representing perturbations are reviewed. Section III contains our main results which include definitions for some new concepts, theorems, algorithms, and indices concerning attractor controllability of BNs. In Sec. IV, the results of the application of the proposed methods to the BN models of some real biomolecular regulatory networks are presented. Section V terminates the paper by some concluding remarks and discussions.
In this section, some basic concepts are presented which are prerequisites for developing our main results.
A Boolean network is a discrete-time logical dynamic system which is defined as 
where x_{i}∈D={0,1} are Boolean variables and f_{i}:D^{n}→D, i =1, …, n are Boolean functions.
If we denote the set of a BN's nodes by N = {1,2,…,n}, the structure of the BN can be represented by a graph, G = (N,E), where E⊆N × N is the set of edges wherein (i, j) ∈ E (meaning there is a directed edge from node i to node j) if the dynamics of node j depends on node i. Such a graph is called the interaction graph or dependency graph of the BN [33].
Example 1: Consider a simple BN with the following update functions:
Its interaction graph is depicted in Fig. 1.
The state of the BN (1) at time t is a binary vector of length n, represented as x(t) = (x_{1}(t),x_{2}(t),…,x_{n}(t)) which we succinctly denote by x = (x_{1}, x_{2}, …, x_{n}). The system of equations in (1) can be succinctly represented as
In this paper, we denote the state space of a system by χ which will be equivalent to D^{n} for a BN of n variables.
x(k,x_{0}) represents the state of the BN starting from x_{0} after k state transitions. So x(t,x_{0}), t≥0, shows the state trajectory starting from x_{0}.
For a BN defined as (2), a graph composed of all points (states) in χ as vertices, with directed edges (links) from vertices such as S_{1} to vertices such as S_{2} provided that S_{2} = f(S_{1}) is called the state transition graph of the BN. Figure 2 shows the state transition graph for the BN of Example 1.
An attractor of a BN is a state (or a series of states) that is (are) repeated in time once the network adopts it (one of them). If for P∈χ we have P = f(P), then P is called a fixed point attractor of the BN. If P_{1},P_{2},…,P_{l} are distinct points in χ for which we have P_{k+1}=fP_{k},k=1,….,l−1, and P_{1}=f(P_{l}), then C = (P{1},P_{2},…,P_{l}) is called a cyclic attractor, or a cycle for short. In this case, l is called the length of the cycle. A fixed point is in fact a cycle of length 1. A set containing all the states that converge to a specific attractor is called its basin of attraction. An attractor landscape analysis is a procedure in which the attractors of a BN and their basins of attraction are identified [34]. In the squeal, we use the term “attracting point” to refer to a fixed point or to any member of a cycle. We call the set of all attracting points of a BN its attracting set and denote it by Λ.
In this section, we present a brief review of STP and its application in transforming a BN to an algebraic state-space form, proposed by Daizhan Cheng and his colleagues [6].
The following notations are commonly used in most papers that are based on the aforementioned approach: 
• I_{n} is the identity matrix of order n.
• δniis the i-th column of I_{n}.
• Δ_{n}={δni|i=1,2,…,n}. In the case of n = 2, we simply denote it by Δ.
• δni_{1},i_{2},…,i{k}is the sum of δni_{1}, δni_{2},…, δni_{k}.
• Row{i}Ais the i-th row of A.
• Col{i}Ais the i-th column of A.
• ColAis the set of all columns of A.
• M_{m × n} is the set of all m × n matrices.
• A ∈ M_{m × n} is called a logical matrix if ColA⊆Δ_{m}. The set of m × n logical matrices is denoted by L_{m×n}.
• Let L ∈ L_{m×n} be a logical matrix. It can be written as L = [δmi_{1},δmi_{2},…,δmi_{n}]. In this case, a more compact notation as L = δ_{m}[i_{1},i_{2},…,i_{n}] is usually used for it.
• B = (b_{ij}) ∈ M_{m×n} is called a Boolean matrix if b_{ij} ∈ D, ∀i,j.
• N = {1, 2, …, n} represents nodes of a BN.
• P_{V}is the power set of the set V.
I_{n} is the identity matrix of order n.
δniis the i-th column of I_{n}.
Δ_{n}={δni|i=1,2,…,n}. In the case of n = 2, we simply denote it by Δ.
δni_{1},i_{2},…,i{k}is the sum of δni_{1}, δni_{2},…, δni_{k}.
Row{i}Ais the i-th row of A.
Col{i}Ais the i-th column of A.
ColAis the set of all columns of A.
M_{m × n} is the set of all m × n matrices.
A ∈ M_{m × n} is called a logical matrix if ColA⊆Δ_{m}. The set of m × n logical matrices is denoted by L_{m×n}.
Let L ∈ L_{m×n} be a logical matrix. It can be written as L = [δmi_{1},δmi_{2},…,δmi_{n}]. In this case, a more compact notation as L = δ_{m}[i_{1},i_{2},…,i_{n}] is usually used for it.
B = (b_{ij}) ∈ M_{m×n} is called a Boolean matrix if b_{ij} ∈ D, ∀i,j.
N = {1, 2, …, n} represents nodes of a BN.
P_{V}is the power set of the set V.
Definition 1: Let A ∈ M_{m × n} and B ∈ M_{p × q}; their semi-tensor product (STP) is denoted by A⋉B and is defined as 
where s = lcm(n,p), i.e., the least common multiple of n and p, and ⊗ is the Kronecker product.
The STP can be considered a generalization of the standard matrix product in which the necessity for the equality of n and p is eliminated. If n = p, the STP will be equivalent to the standard matrix product. All basic properties of the standard matrix product such as associativity and distributivity over addition are also valid for STP. Thus, we may omit “⋉” if no confusion arises.
Remark 1: If x_{1}, x_{2}, …, x_{n} are column (row) vectors of size r, x_{1} ⋉ x_{2} ⋉ … ⋉ x_{n} will be a column (row) vector of size r^{n}. Specifically, if x_{1}, x_{2}, …, x_{n}∈ Δ, then x_{1} ⋉ x_{2} ⋉ … ⋉ x_{n}∈ Δ_{2^{n}}.
We use δ21 as a vector equivalent for 1 or True, and δ22 as a vector equivalent for 0 or False. By adopting this equivalence, D and Δ will be equivalent. So logical variables and their vector equivalents may be used interchangeably. However, we use x_{i}∈D(italic font) for a logical variable and x_{i}(regular font) for its vector equivalent.
Let x = (x_{1}, x_{2}, …, x_{n})∈D^{n}, equivalently x = (x_{1}, x_{2}, …, x_{n})∈Δ^{n}; the mapping X=⋉i=1nx_{i} is a bijection from Δ^{n} to Δ_{2^{n}}, i.e., every x ∈Δ{n} corresponds to one and only one X∈Δ_{2^{n}} using this mapping.
If x = (x_{1}, x_{2}, …, x_{n}) is a binary vector (e.g., a BN's state) and X=⋉i=1nx_{i}=δ2^{n}j, we call δ2^{n}j the semi-tensor product representation (STPR) of x, and denote it by x ∼δ2^{n}j or X= STPR(x) interchangeably.
Remark 2: If we consider members of D^{n} in lexicographical order, i.e., from (0,0,…,0) to (1,1,…,1), their STPRs will be from δ2^{n}2^{n} to δ2^{n}1, respectively. A simple way to obtain the STPR of a given x∈D^{n} is to consider it as a binary number and turn it into decimal format. If its decimal equivalent is d, then the STPR of x will be δ2^{n}2^{n}−d. For example, if x=(1,0,1), considering it as a binary number, its decimal equivalent will be 5 and its STPR will be δ2^{3}2^{3}−5=δ83. Conversely, if the STPR of x∈D^{n} is known to be δ2^{n}i, then the elements of x can be recovered by converting d=2^{n}−i into its binary equivalent.
Lemma 1. Let f be a logical function of n arguments. Then, there exists a unique matrix M_{f}∈L_{2×2^{n}}, called the structure matrix of f, such that 
where X=⋉i=1nx_{i}. The above form is called the multi-linear representation of a logical function [6].
In Ref [6], a method for calculating M_{f} from the structure matrices of elementary logical operations is presented. Alternatively, M_{f} can be constructed as follows:
Remark 3: The first row of M_{f} contains the truth table values of the logical function f, filled from right to left, and its second row is the negation of its first row. Equivalently, the i-th column of M_{f} will be δ21(δ22) if the (2^{n}-i + 1)-th row of the truth table contains a value of 1 (0) for f.
Example 2: If n =2 and f(x_{1},x_{2}) = ∼x_{1}∧x_{2}, its truth table will be as follows:
So using Remark 3, the structure matrix of f will be
Using Lemma 1 and the mapping X=⋉i=1nx_{i}, system (1) can equivalently be represented as 
where M_{i}∈L_{2×2^{n}}, i =1, …, n are structure matrices of f_{i}, i =1, …, n, respectively.
Multiplying the above equations and then applying some simplifications will lead to the following lemma.
Lemma 2. Consider system (1). Define X=⋉i=1nx_{i}. Then there exists a unique matrix L∈L_{2^{n}×2^{n}}, called the transition matrix of the system, such that
Equation (6) is called the algebraic form of (1).
In Ref [6], a formula for computing L from the structure matrices of the Boolean functions f_{i}, i =1, …, n, (i.e., M_{1}, M_{2}, …, M_{n}) is presented. Alternatively, L can be constructed as follows: 
where x ∼δ2^{n}jj=1,…,2^{n} and f is as defined in (2).
Remark 4: If x_{0} ∼ P and x(t,x_{0}) ∼ Q, then by successive application of (6), we have Q=L^{t}P.
Definition 2: The transient period of a BN, denoted by T_{t}, is the smallest time such that starting from any arbitrary initial state in the state space, the state trajectory will reach an attractor within T_{t} time steps.
The transient period of a BN can be calculated using the following proposition [6]:
Proposition 1: Let L be the network transition matrix of a BN. Then its transient period is the smallest positive integer, r_{0}, which satisfies L^{r0}=L^{r0+T} for some T>0.
Remark 5: Let x_{0}∈χ be any initial state in the state pace of a BN and x_{0}∼X_{0}. According to the definition of transient period, the state trajectory starting from x_{0} will always enter the attracting set within T_{t} steps; hence, if q ∼ L^{t}X_{0} and t≥T_{t}, then q∈Λ.
For more details on STP and the algebraic state-space representation of BNs using STP, please refer to Refs [6] and  [7].
As explained in Sec. I, the intervention method used in our approach is flipping the values of a subset of the network variables once (after the system has passed its transient period). This type of intervention is also referred to as a one-time gene perturbation in the context of gene regulatory networks. For instance, in Ref [37], it is stated that “a one-time gene perturbation changes the value of one or more genes, which in a binary network means that the value of one or more genes is flipped at current moment.” In Sec. II C, we show how this type of intervention can be formalized in the form of matrix multiplications [38]:
Suppose we have numbered the nodes of a BN from 1 to n and assigned them to Boolean variables x_{1},x_{2},…,x_{n}, respectively. Let V = x_{i1},x_{i2},…x_{iv} be a (strict) subset of {x_{1},x_{2},…x_{n}}(or alternatively V = {i_{1}, i_{2}, …, i_{v}} be a (strict) subset of {1, 2, …, n}); then, we call it a (strict) perturbation set if it represents the network variables that we can flip.
Definition 3: Let S = {i_{1},i_{2},…i_{s}} be a perturbation set for a BN of n nodes. We defined the flip function with respect to S, denoted by fS↕x, as follows: 
i.e., x¯{S} is x with its i_{1}-th, i_{2}-th, … and i_{s}-th elements flipped.
Definition 4: Let S = {i_{1},i_{2},…i_{s}} be a perturbation set for a BN of n nodes. The flip matrix (of order 2^{n}) with respect to S is denoted by f_{S}∈M_{2^{n}×2^{n}} and defined as follows:
Equation (9) can also be written as
In this way, for any x ∈ χ, with x ∼ X and x¯{S}∼X¯{S}, we have
Definition 5: Now let V = {i_{1},i_{2},…i_{v}} be a perturbation set for a BN of n nodes; then, its power set is P_{V}= {∅,i_{1},…i_{v},…,V}. The combinatorial flip matrix (of order 2^{n}) with respect to V is denoted by F_{V}∈M_{2^{n}×2^{n}} and defined as follows:
That is, (F_{V})_{ij} = 1 if there exists a subset S ∈ P_{V} such that (f_{S})_{ij} = 1. It follows that
Note that for any two distinct subsets S_{1},S_{2}∈P_{V}, S_{1}≠S_{2} results in fS_{1}↕(x)≠fS_{2}↕(x) for any x ∼δ2^{n}j. Then, from (10), it is concluded that Col_{j}(f_{S1})≠Col_{j}(f_{S2}). So, the matrices in the right-hand side of the summation (13) do not have equal j-th columns (having 1s in the same positions) for any j. Therefore, the resulting matrix will be a Boolean matrix.
Remark 6: The j-th column of F_{V} is the collection (sum) of the STPRs of all the states that can be attained from x ∼ δ2^{n}j by flipping elements of every subset of V.
For more properties of the (combinatorial) flip matrix, please refer to Ref [38].
Here, we present an illustrative example.
Example 3: Let n =3 and V = {2,3}; then its power set is P_{V}= {∅,2,3,{2,3}}, and we have 
f_{∅}=I_{2^{3}}=δ_{8}[12345678], because every x∈χ is mapped to itself if no element of x is flipped.
f_{{2}}=δ_{8}[34127856]; because if x_{2} is flipped,
x = (111) ∼δ81 turns into x = (101) ∼δ83 and vice versa,
x = (110) ∼δ82 turns into x = (100) ∼δ84 and vice versa,
x = (011) ∼δ85 turns into x = (001) ∼δ87 and vice versa, and
x = (010) ∼δ86 turns into x = (000) ∼δ88 and vice versa;
f_{{3}}=δ_{8}[21436587]; because if x_{3} is flipped,
x = (111) ∼δ81 turns into x = (110) ∼δ82 and vice versa,
x = (101) ∼δ83 turns into x = (100) ∼δ84 and vice versa,
x = (011) ∼δ85 turns into x = (010) ∼δ86 and vice versa, and
x = (001) ∼δ87 turns into x = (000) ∼δ88 and vice versa;
f_{{2,3}}=δ_{8}[43218765]; because if x_{2} and x_{3} are flipped,
x = (111) ∼δ81 turns into x = (100) ∼δ84 and vice versa,
x = (110) ∼δ82 turns into x = (101) ∼δ83 and vice versa,
x = (011) ∼δ85 turns into x = (000) ∼δ88 and vice versa, and
x = (010) ∼δ86 turns into x = (001) ∼δ87 and vice versa.
f_{∅}=I_{2^{3}}=δ_{8}[12345678], because every x∈χ is mapped to itself if no element of x is flipped.
f_{{2}}=δ_{8}[34127856]; because if x_{2} is flipped,
x = (111) ∼δ81 turns into x = (101) ∼δ83 and vice versa,
x = (110) ∼δ82 turns into x = (100) ∼δ84 and vice versa,
x = (011) ∼δ85 turns into x = (001) ∼δ87 and vice versa, and
x = (010) ∼δ86 turns into x = (000) ∼δ88 and vice versa;
f_{{3}}=δ_{8}[21436587]; because if x_{3} is flipped,
x = (111) ∼δ81 turns into x = (110) ∼δ82 and vice versa,
x = (101) ∼δ83 turns into x = (100) ∼δ84 and vice versa,
x = (011) ∼δ85 turns into x = (010) ∼δ86 and vice versa, and
x = (001) ∼δ87 turns into x = (000) ∼δ88 and vice versa;
f_{{2,3}}=δ_{8}[43218765]; because if x_{2} and x_{3} are flipped,
x = (111) ∼δ81 turns into x = (100) ∼δ84 and vice versa,
x = (110) ∼δ82 turns into x = (101) ∼δ83 and vice versa,
x = (011) ∼δ85 turns into x = (000) ∼δ88 and vice versa, and
x = (010) ∼δ86 turns into x = (001) ∼δ87 and vice versa.
According to (13), F_{{2,3}}=f_{∅}+f_{{2}}+f{3}+f{{2,3}}; hence, F_{{2,3}}=[δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8].
The 1st column of F_{V}, for example, is δ81,2,3,4 which signifies that x ∼ δ81 can be changed to δ81, δ82, δ83 or δ84 by flipping some of the x's elements specified by subsets of V. This is in accordance with Remark 6.
We call the state transition from x to x¯{S} a perturbed state transition. Consider the state transition graph of a BN as in Fig. 2. If we add directed links to it for every perturbed state transition involving an attracting point, the resulting graph is called the attractor-perturbed state transition graph (APSTG) of the BN with respect to V. Figure 3 shows an example of an APSTG. We represent perturbed transition by dashed links to distinguish them from normal transitions.
Definition 6: Let A_{1} ∼ δ2^{n}r_{1}, A_{2} ∼ δ2^{n}r_{2}…, A_{N} ∼ δ2^{n}r_{N} be members of the attracting set of a BN (which include fixed points and cycle members); we call the matrix 
the attracting matrix of the BN.
Definition 7: Let L and T_{t} be the network transition matrix and transient period of a BN, respectively. We denote the attractor controllability matrix of the BN with respect to a given perturbation set V, by Ω_{V}, and define it as follows:
Remark 7:Ω_{V} will be a 2^{n}×N matrix. Each row (the r-th row) of this matrix corresponds to one point (x∼δ2^{n}r) in χ. Each column (the cth column) of this matrix corresponds to an attracting point (A_{c}∼δ2^{n}r_{c}) of the BN.
As we will demonstrate, this matrix can be used for inspecting attractor controllability of BNs.
In Ref [38], we introduced attractor stabilizability of a BN by flipping a subset of its nodes. We defined a BN to be attractor stabilizable to a specific attractor, called the target attractor, by flipping members of a perturbation set, V, if it can be made to converge from anyone of its attracting points to the target attractor by one-time flipping some (from none to all) members of V. In that case, V is called a stabilizing perturbation set. A stabilizing perturbation set with minimum cardinality is called the minimal perturbation set for Attractor Stabilizability (MPS-AS) or the stabilizing kernel for the target attractor.
In Sec. III, we extend our previous results to attractor controllability of BNs.
In this study, we mainly focus on controllability of BNs as models of biomolecular regulatory networks. It has been shown that attractors of BN models of biomolecular networks correspond to different cell types or cell conditions [2]. In applications of BNs as models of biomolecular regulatory networks, since most of the time the system resides in an attractor, the transient behavior of the network is often insignificant [25]. We are thus usually more interested in governing the steady-state behavior of the network, that is, finding methods to drive the network from one attractor to another which may correspond, for example, to steering a cell from a diseased to a normal phenotype [39].
Assume that a BN has passed its transient period and thus has entered one of its attractors. Let V = {x_{i1},x_{i2},…,x_{iv}} be a strict perturbation set. The question is whether the BN can be made to converge from any of its attractors to any other one by one-time flipping some members of V. The following definition is inspired by Ref [25].
Definition 8: Let V be a strict perturbation set for a BN whose attracting set is Λ. We say, the BN is attractor controllable by flipping members of V, if for any starting attracting point, z∈Λ, the following two conditions hold: 
(1) for any fixed point attractor, P, there exist S⊆V,T∈Z_{+} such that x(t,z¯{S})= P, ∀t ≥ T, and
(2) for any cyclic attractor, C, there exist S⊆V,T∈Z_{+}, such that x(t,z¯{S})∈C, ∀t ≥ T.
for any fixed point attractor, P, there exist S⊆V,T∈Z_{+} such that x(t,z¯{S})= P, ∀t ≥ T, and
for any cyclic attractor, C, there exist S⊆V,T∈Z_{+}, such that x(t,z¯{S})∈C, ∀t ≥ T.
In terms of the network's state transition graph, a BN is attractor controllable by flipping elements of a subset of its nodes, V, if there is a directed path from any of its attracting points to any other attractor in the APSTG of the network with respect to V.
Theorem 1: Let V={x_{i1},x_{i2},…,x_{iv}} be a perturbation set, T_{t} be the transient period of a BN and Ω_{V} be the attractor controllability matrix defined in Definition 7; then ΩV{ij} equals the number of ways we can make the network converge from the attracting point A_{j} ∼ δ2^{n}r_{j}, to the destination point x^{d} ∼ δ2^{n}i, by one-time flipping some (from none to all) members of V and then having T_{t} state transitions.
Equivalently, ΩV{ij} counts the number of directed paths of T_{t} links (not counting the dashed link), from the attracting point A_{j}∼δ2^{n}r_{j}, to the destination point x^{d}∼δ2^{n}i, in the APSTG of the network with respect to V [38].
Proof. For any two matrices A and B, Col{j}AB=ACol{j}B; hence,
From (14), Col{j}Ω=δ2^{n}r_{j}, thus it follows 
because for any matrix A∈M_{m×2^{n}}, Aδ2^{n}i=Col_{i}A.
Multiplying both sides by L^{Tt} results in
On the other hand, from (15), we have
Comparing (16) and (17) results in
According to Remark 6, Col_{rj}(F_{V}) indicates the collection of the STPRs of all the states that can be attained from attracting point A_{j}∼δ2^{n}r_{j}, by flipping some (from none to all) elements of V. Thus, taking Remark 4 into consideration, we conclude that L^{Tt}Col_{rj}(F_{V})[which equals Col{j}Ω_{V} according to (18)] will give the sum (collection) of the STPRs of all the states that can be attained from the attracting point A_{j}∼δ2^{n}r_{j} by flipping some (from none to all) elements of V once, and then having T_{t} state transitions. So its i-th entry [which equals ΩV{ij}] gives the sum of the STPRs of all the states that reach δ2^{n}i from attracting point A_{j}∼δ2^{n}r_{j} by flipping some elements of V once, after T_{t} state transitions. In other words, it shows the number of ways we can steer the network from the attracting point A_{j}∼δ2^{n}r_{j}, to the destination point x^{d}∼δ2^{n}i, by one-time flipping some network variables which are subsets of V. For an alternative (more formulized) proof of this theorem, you may refer to Ref [38].
Note: In the sequel, we represent a cycle such as C∼(δ2^{n}r_{1},δ2^{n}r_{2},…,δ2^{n}r_{k}) by its compact form C∼δ_{2^{n}}(r_{1},r_{2},…,r_{k}).
Corollary 1: If C is a cycle, represented as δ_{2^{n}}(r_{1},r_{2},…,r_{k}), then ∑i=1k(Ω_{V}){rij} is equal to the number of ways we can make the network converge from the attracting point A_{j}∼δ2^{n}r_{j}, to (a member of) the cycle C by one-time flipping some members of V, and then having T_{t} state transitions. This is also equal to the number of directed paths from the attracting point A_{j}∼δ2^{n}r_{j}, to (a member of) the cycle C, in the APSTG of the network with respect to V [38].
We used Theorem 1 and Corollary 1 to establish necessary and sufficient conditions for attractor stabilizability of BNs [38]; in this paper, we use them to establish necessary and sufficient conditions for attractor controllability of BNs.
Considering Theorem 1 and Corollary 1 together with Definition 8, the following result can easily be inferred.
Theorem 2: Consider a BN with k fixed point attractors represented by δ2^{n}r_{1}, δ2^{n}r_{2}, …, δ2^{n}r_{k} and m cyclic attractors, C^{1}∼δ_{2^{n}}(r11,r21,…,rl_{1}1), …, C^{m}∼δ_{2^{n}}(r1m,r2m,…,rl_{m}m), with lengths l_{1}, …, l_{m}, respectively.
Let V={x_{i1},x_{i2},…,x_{iv}} be a strict perturbation set and Ω_{V} be the attractor controllability matrix with respect to V, defined in Definition 7; the BN is attractor controllable by flipping members of V if 
and
Note that for a vector or a matrix such as A, the inequality A > 0 means all elements of A are positive. So, condition (19) necessitates that all elements of the rows of Ω_{V} which correspond to the fixed point attractors be positive; this, according to Theorem 1 and Remark 7, means that there should be at least one way for steering the network from every attracting point to every fixed point attractor. Condition (20) necessitates that for any cyclic attractor, in each column of Ω_{V}, at least one of the rows which correspond to that cycle contain a nonzero value; this, according to Theorem 1 and Remark 7, means that there is at least one way for steering the network from every attraction point to (a member of) any cycle.
Note that in order to make a network converge to a cyclic attractor, it suffices to steer it to one member of that cycle.
A perturbation set satisfying (19) and (20) while having minimum cardinality is called minimal perturbation set for attractor controllability (MPS–AC) for the BN.
It should be noted that the intervention method used in this work does not modify the natural dynamics of the system. It merely resets the state of the BN to a new initial state. Therefore, the attractors of the BN remain intact under this type of intervention. In fact, the dynamics of the BN can be described by (6) both before and after applying the intervention. But its state transition is performed according to (11) at the moment of applying the intervention. Below, we study an illustrative example.
Example 4: Consider the BN of Example 1.
Its state transition graph is depicted in Fig. 2. It has three fixed point attractors (1,1,1) ∼δ81, (0,1,0) ∼δ86 and (0,0,0) ∼δ88 which we name A_{1}, A_{2}, and A_{3}, respectively. So, its attracting matrix can be represented as Ω= δ_{8}[1, 6, 8]. As we will see, the BN is attractor controllable by flipping members of the perturbation set V = {2, 3}.
As shown in Example 3, the combinatorial flip matrix with respect to V = {2, 3} is F_{{2,3}}=[δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ81,2,3,4,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8,δ85,6,7,8].
Using (7), it is easy to check that the network transition matrix for this network is L = δ_{8}[1, 6, 4, 8, 1, 6, 4, 8].
Using Proposition 1, we obtain T_{t} = 2. Now using the above F_{V} and the transition matrix, L, to calculate Ω_{V} according to (15) results in
Recalling that the attractors of this BN are A_{1} ∼ δ81, A_{2} ∼ δ86 and A_{3} ∼ δ88, condition (19) becomes Row_{1}Ω_{V}>0, Row_{6}Ω_{V}>0 and Row_{8}Ω_{V}>0 which obviously holds true. So, this BN is attractor controllable by flipping members of V = {x_{2},x_{3}}.
Figure 3 shows the APSTG for this network with respect to V = {2, 3}. State transitions to/from attracting points due to flipping every subset of V are depicted by dashed links. As it can be seen, there is a directed path from every attractor to every other attractor.
Furthermore, it can be verified from Fig. 3 that (Ω_{V}){ij} equals the number of existing directed paths (of length T_{t} = 2, not counting the dashed link), containing at most one dashed link (perturbed transition), from the attracting point A_{j}, j =1, 2, 3, to the destination point δ8i, i =1,…,8.
We now propose and prove a proposition which shows a relation between the sizes of MPS–AC and MPS-ASs of a BN.
Proposition 2: Consider a BN with m attractors, A_{1}, A_{2}, …, A_{m}, some of which might be cyclic (composed of several states). Let V be the MPS-AC for this BN, and S_{1}, S_{2}, …, S_{m} be the MPS-ASs for the target attractors A_{1}, A_{2}, …, A_{m}, respectively; then, we have 
i.e., the cardinality of MPS-AC of a BN is an upper bound for the cardinalities of MPS-ASs for all of its attractors.
Proof. We prove it by contradiction. Assume that there is an attractor A_{k}, whose MPS-AS, S_{k}, has a cardinality greater than |V|. According to the definition of MPS-AS, any perturbation set with smaller cardinality, particularly V, cannot be a stabilizing perturbation set for A_{k}. This is in contradiction to the assumption that V is the MPS-AC of the BN (considering the definition of MPS-AC). So, |S_{k}|>|V| cannot be true.
In fact, by considering the definitions of the MPS-AC and the stabilizing perturbation set, one can easily deduce that an MPS–AC for a BN is also a stabilizing perturbation set for any target attractor of that BN. Then, recalling that the cardinality of the MPS-AS for a target attractor is always less than or equal to the cardinality of any stabilizing perturbation set for that attractor, the above proposition is easily justified.
We can use Theorem 2, established in this section, to find the MPS–AC of biomolecular regulatory networks modeled as BNs. Since we are looking for sets of minimum cardinality, a forward search algorithm can be used to find the MPS–AC of BNs.
Consider a BN whose attractors are described as in Theorem 2. In the following, we summarize the procedure for identifying the MPS–AC for such a BN in the form of a step-by-step algorithm: 
• Perform an attractor landscape analysis for the given BN; then, form the attracting matrix of the BN, Ω.
• Calculate the transition matrix, L, the transient period, T_{t}, and then L^{Tt}.
• For r =1 to n–1 (since we seek strict subsets),
Perform an attractor landscape analysis for the given BN; then, form the attracting matrix of the BN, Ω.
Calculate the transition matrix, L, the transient period, T_{t}, and then L^{Tt}.
For r =1 to n–1 (since we seek strict subsets),
for V =every combination of choosing r out of n variables,
Calculate F_{V}(with respect to the candidate set V) and then Ω_{V}=L^{Tt}F_{V}Ω.
If Row{ri}Ω_{V}>0 for every fixed point, P_{i}∼δ2^{n}r_{i}, i = 1,…,k, and ∑i=1l_{j}Row{rij}(Ω_{V})>0 for every cyclic attractor, C^{j}∼δ_{2^{n}}(r1j,r2j,…,rl_{j}j), j = 1,…, m, then return V as the MPS-AC.
The algorithm may be stopped as soon as an MPS-AC is found. But, note that the MPS–AC for a BN need not be unique. So, if a set with minimum cardinality, r_{m}, is found to satisfy the conditions, we may continue to check all candidate sets of r_{m} elements if we wish to find all possible choices of MPS–ACs.
One drawback of the forward search algorithm is its relatively high computational time in the case of large BNs or BNs with large-cardinality MPS-AC. This is because this method involves the enumeration of the candidate sets until finding the MPS-AC whose possible case for identifying the minimal perturbation set is O(2^{n}) in the worst case, though it was actually much less in most cases we studied in our research. As a result, this method can be used effectively as long as the enumeration of the candidate sets until finding the MPS-AC is tractable. Hence, it cannot be used for BNs of large size and/or with large-cardinality MPS-ACs.
To obtain a measure of how large the cardinalities of the MPS-ACs of BNs typically are relative to network sizes, we identified the MPS-ACs of 480 randomly generated BNs. We tried to generate the random BNs with structures and Boolean functions similar to those prevalent in BN models of biomolecular regulatory networks. For details on how to generate such random BNs, please refer to the appendix. For each BN, we computed the ratio of the cardinality of the MPS-AC to the network size. Then, we averaged these ratios over the 480 checked cases. As a result, the mean ratio of the cardinality of the MPS-AC to the network size turned out to be about 0.4. Therefore, although in the forward search algorithm the number of candidate subsets to be checked is 2^{n}–2 in the worst case (∅ and N are excluded from the candidate sets), we have to check candidate subsets with cardinalities up to 0.4n in the average case. So, the computational time of the algorithm can be expected to be much less than the worst case mentioned above, in most of the cases. Besides, we propose three solutions to cope with the problem of high computational time for large BNs.
The first solution for expanding the applicability of the forward search method to larger networks is to apply model reduction techniques [35,36]. These methods provide simplified models of larger networks which retain the essential properties of the original networks.
To introduce the second solution, we first need to state and prove the following proposition about the cardinality of the MPS-AC of a given BN:
Proposition 3: Consider a BN with m attractors. Let V be the MPS-AC for this BN with V=v; then we have 
where a is the smallest integer greater than or equal to a. In other words, log_{2}m is a lower bound for the cardinality of the MPS-AC of the BN.
Proof. Let V be a perturbation set for this BN with V=v and Λ be the attracting set of the BN. For any x ∈ Λ the set x¯{S}=fS↕x|S∈P_{V} will have exactly 2^{v} members (Because the function fS↕x will map x to distinct values of x¯{S} for distinct subsets S∈P_{V}; and there are exactly 2^{v} subsets in P_{V}) which can converge to 2^{v} different attractors in the best case. But if V is to be an MPS-AC for this BN, according to the definition, for any x∈Λ, members of the set x¯{S}|S∈P_{V} should converge to m different attractors. This can only happen if 2^{v}≥m, or equivalently v ≥log_{2}m. Since v is assumed to be an integer, we should have v ≥log_{2}m. Q.E.D.
Using the above proposition, we can revise the forward search algorithm to decrease its computational time. To this end, we change the third step of the algorithm in the following way: 
• For r=v_{min} to n−1, ….where v_{min}=log_{2}m is the lower bound obtained in Proposition 3.
For r=v_{min} to n−1, ….
The third solution to mitigate the computational time of the forward search method will be proposed at the end of Sec. III C.
A question which may arise after studying the theories presented so far in this paper is that if the objective is to steer the BN from any of its attractors to any other one, and if one has to choose between several possible perturbation sets for this purpose, on what basis such a selection could be made. In answer to this question, if one (or more) of the candidate sets is an MPS-AC, it would be the best choice, since it provides full attractor controllability. Otherwise, it would be beneficial if we could have a criterion for quantifying the attractor controllability provided by a given perturbation set. To this end, we introduce an index for quantifying the attractor controllability, called percentage of attractor controllability (PAC) with respect to a specific perturbation set.
Let Λ={P_{1},P_{2},….,P_{N}} be the attracting set of a BN. If m is the number of attractors of this BN, it is obvious that N≥ m; because some attractors (i.e., cycles) may consist of more than 1 attracting points.
Let V be a perturbation set; for P_{i}∈Λ, we define R_{V}(P_{i}) to be the number of attractors reachable from attracting point P_{i}, in the APSTG of the BN with respect to V. [We say, an attractor is reachable from P_{i} if there is a directed path from P_{i} to (a member of) that attractor in the APSTG.] Thus, for every V⊆N, we have 1≤R_{V}P_{i}≤m(because at least the attractor which includes P_{i} is reachable from P_{i}). Note that R_{∅}P_{i}=1, since the only attractor reachable from P_{i} is the attractor which includes P_{i} if no variables are flipped. If V is (a super set of) an MPS-AC then R_{V}P_{i}=m.
Note: In this section, when talking about an attracting point such as P_{i}, by “other attractors,” we mean all attractors except P_{i} if P_{i} is a fixed point, and we mean all the attractors except the attractor which includes P_{i} if P_{i} is a member of cycle.
We denote the fraction of reachable attractors from the attracting point P_{i} by flipping members of V, by r_{V}P_{i} and define it to be the number of other attractors reachable from P_{i} normalized by the total number of other attractors; that is
Note that r_{∅}P_{i}=0 because in an unperturbed network the basins of attraction for various attractors are disjoint and no attractor is reachable from another attractor. If we can make the network converge to every other attractor from the attracting point P_{i}, by flipping members of V, then we have r_{V}P_{i}=1. In general, 0≤r_{V}P_{i}≤1. If r_{V}P_{i}=1 for every i =1, 2, …, N, then the BN is attractor controllable with respect to V.
Definition 9: We denote the percentage of attractor controllability (PAC) with respect to the perturbation set V, by π_{V}, and define it as follows:
It is, in fact, the average fraction of reachable attractors from all attracting points expressed as a percentage. It is obvious that if we can make the network converge from every attracting point P_{i},i =1, …N, to every other attractor by flipping members of V, then we have π_{V}=100%, which means the BN is fully attractor controllable with respect to V. It can be concluded that if a perturbation set is an MPS-AC or a superset of an MPS-AC, then its PAC is 100%. For any strict subset of an MPS-AC, PAC < 100%. But PAC is closer to 100% for perturbation sets which result in the perturbed network being closer to full attractor controllability. Hence, PAC provides a measure of how good a perturbation set is for the purpose of attractor controllability.
Example 5: Consider the BN of Example 1.
Table I indicates the PACs for each of the possible perturbation sets for this BN.
We recall from Example 4 that the MPS-AC for this BN was V = {x_{2}, x_{3}}. As it can be observed in Table I, π_{V} is 100% for this set and its superset, that is {x_{1}, x_{2}, x_{3}}, and is less than 100% for every other perturbation set.
The PAC index, introduced in Subsection III B, quantifies how good a given perturbation set is for the purpose of attractor controllability of a BN. But, another question which may arise in studying attractor controllability of BNs is how effective (flipping) a BN variable is in steering the network from every one of its attractors to its other attractors.
To answer this question, we introduce another index which quantifies the impact of (flipping) a BN's variable on its attractor controllability.
Definition 10: Assume a BN with m attractors, A_{1}, A_{2}, …, A_{m}, some of which might be cyclic (composed of several states). Let R_{1}, R_{2}, …, R_{m} be the basins of attraction for the attractors A_{1}, A_{2}, …, A_{m}, respectively. We denote the Attraction function of a BN by Ax and define it as follows:
For z∈χ,Az = k if z∈R_{k}, i.e., ∃T∈Z_{+},xt,z=A_{k}(or xt,z∈A_{k} in the case of a cyclic attractor),∀t≥T.
Then, we denote the convergence influence of the i-th network variable by C_{i} and define it as follows: 
where x¯{{i}} is x with its i-th element flipped.
The above index indicates the fraction of attracting points in which flipping x_{i} will cause the network to converge to a different attractor.
Example 6: Consider the BN of Example 1.
The convergence influences of its nodes are calculated and presented in Table II.
If one compares Tables I and II, they realize that the perturbation sets consisting of variables with higher convergence influences usually have higher percentages of attractor controllability. It is thus reasonable to guess that there might be a special relationship between the values of the variables' convergence influences with their probability of membership in the MPS-AC. In order to verify such an inference, we computed the convergence influences of the variables of an ensembles of 480 randomly generated BNs, and then (for each network), we sorted the network variables in descending order according to their convergence influence values. We represented the sorted variables (for every BN) by x_{i1},x_{i2},…x_{in}, respectively. We also identified the MPS-ACs for all of the BNs using the method proposed at the end of Sec. III A. We then computed the percentages of membership of (the instances of) the sorted variables x_{i1},x_{i2},…,x_{in}(over all random BNs) in the MPS-ACs of their respective BNs. Figure 4 demonstrates the percentages of membership of (the instances of) each of the sorted variable x_{i1} to x_{i7}, in the MPS-ACs of their respective BNs.
As it can be seen, the 1st variables in the sorted lists, i.e., the variables with the highest convergence influences, have been a member of the MPS-AC in almost 100% of the cases (the percentage values in Fig. 4 have been rounded to the nearest integers). For the other variables in the sorted lists, those with higher convergence influences have had higher percentages of membership in the MPS-ACs of their respective BNs. This observation confirms our conjecture about the relationship between the values of the variables' convergence influences with their probability of membership in the MPS-ACs.
We also observed that for perturbation sets of equal size, those consisting of elements with higher (average or sum) convergence influences resulted in higher values of PAC in most of the cases.
We can use the results of these observations to increase the speed of the proposed algorithm for identifying the MPS-AC presented at the end of Sec. III A. That is, instead of searching through an arbitrary sequence of network variables, it is more efficient to sort the variables in descending order according to their convergence influences, and then choose the candidate sets from the sorted list. In this way, the algorithm will identify the MPS-AC in a shorter time since the variables with higher convergence influences are more probable to be members of the MPS-AC.
In the case of gene regulatory networks, flipping the value of a node is equivalent to down-regulation (gene silencing) or up-regulation (over-expression) of a gene using external stimuli. Various techniques have so far been proposed to this end. For example, RNA interference (RNAi) [40] and antisense oligonucleotides (ASOs) [41] are two known methods for gene silencing, and CRISPRa is a technique used to upregulate the expression of a target gene [42]. For a thorough comparison of the practical techniques for changing gene-expression state in cells (by means of external stimuli), see Ref [43].
We have investigated the attractor controllability of several biomolecular regulatory networks, by applying the algorithm proposed in Sec. III A to their BN models. These networks include (a) the Saccharomyces cerevisiae (baker's yeast) cell cycle network [44], (b) the gene regulatory network (GRN) underlying mammalian cortical area development [45] and, the (c) the GRN underlying mouse myeloid development [46]. In each case, we aimed to identify the MPS–AC of the BN.
We used a simplified Boolean model of the S. cerevisiae cell cycle network [44]. It consists of 11 nodes (biomolecules) whose names are abbreviated as Cln3, MBF, SBF, Cln1_2, Cdh1, Swi5, Cdc20_Cdc14, Clb5_6, Sic1, Clb1_2 and Mcm1_SFF to which we assigned indices 1 to 11, respectively. First, by performing an attractor landscape analysis, we identified the attractors of this BN. We found that the network has 7 fixed point attractors. The attracting set of this BN can be represented as
So, the attracting matrix of this BN is
Using Proposition 1, we computed the transient period of this BN which turned out to be T_{t} = 16.
It can be checked via straightforward computation that V = {x_{2}, x_{3}, x_{4}, x_{5}, x_{9}} or {“MBF,” “SBF,” “Cln1_2,” “Cdh1,” “Sic1”} satisfies (19). That is, using this V and (26) to calculate Ω_{V}=L^{16}F_{V}Ω, it can be easily verified that Row{r}Ω_{V}>0, for ∀r∈{1468,1532,1664,1980,1984,2044,2048}.
Since no perturbation set with smaller cardinality can be found to satisfy (19), this V can be declared as the MPS–AC for this BN; that is, if the values of MBF, SBF, Cln1_2, Cdh1, and Sic1 can be flipped, then the BN can be made to converge from any of its attractors to any other one by one-time flipping some of these nodes.
The simplified Boolean model of the GRN underlying mammalian cortical area development [45] consists of 10 nodes (5 genes and 5 proteins) whose abbreviated names are Fgf8_{g}, Emx2_{g}, Pax6_{g}, Coup_tfi_{g}, Sp8_{g}, Fgf8_{p}, Emx2_{p}, Pax6_{p}, Coup_tfi_{p}, and Sp8_{p}. We assigned these nodes to variables x_{1} to x_{10}, respectively. Our attractor landscape analysis revealed that the network has three attractors, two of which are fixed points and the third is a cycle of length 2. The attracting set of this BN can be represented as 
where the parentheses are used to distinguish the cyclic attractor. So, the attracting matrix of this BN is
We also computed the transient period of the network which was T_{t} = 8. Using (27) to compute Ω_{V} for the candidate perturbation sets and utilizing the forward search algorithm mentioned at the end of Sec. III A, one can easily check that V = {x_{1}, x_{2}, x_{5}, x_{6}, x_{7}, x_{10}} or {“Fgf8_{g},” “Emx2_{g},” “Sp8_{g},” “Fgf8_{p},” “Emx2_{p},” “Sp8_{p}”} satisfies (19) and (20). That is, using the above V in calculating Ω_{V}=L^{8}F_{V}Ω, it can be easily verified that Row{331}(Ω_{V})>0, Row{694}(Ω_{V})>0 and Row{342}Ω_{V}+Row{683}(Ω_{V})>0.
Since no perturbation set with less cardinality can be found to satisfy (19) and (20), the aforementioned perturbation set is the MPS–AC for this network.
The simplified Boolean model of the GRN underlying mouse myeloid development [46] consists of 11 nodes whose names are abbreviated as GATA_2, GATA_1, FOG_1, EKLF, Fli_1, SCL, CEBPa, PU1, cJun, EgrNab and Gfi_1, which we numbered from 1 to 11, respectively. The attractor landscape analysis for this BN shows that it has 8 attractors, of which two are cyclic and the rest are fix points. The attracting set of this BN can be represented as 
where the parentheses are used to distinguish the cyclic attractors. So, the attracting matrix of this BN is 
The transient period of this network turned out to be T_{t} = 5.
It can easily be checked that using V = {x_{2}, x_{4}, x_{5}, x_{7}, x_{8}, x_{9}, x_{10}, x_{11}} or {“GATA_1,” “EKLF,” “Fli_1,” “CEBPa,” “PU1,” “cJun,” “EgrNab,” “Gfi_1”} together with (28) to calculate Ω_{V}, leads to the conditions (19) and (20) being satisfied. That is, 
and Row_{1248}(Ω_{V})+Row{1056}(Ω_{V})>0, and Row_{1511}(Ω_{V})+Row{1583}(Ω_{V})>0.
With no smaller set having this property, the identified set is the MPS–AC for this network.
The MPS-AS for the (primary) target attractors of the biomolecular regulatory networks studied in this section were identified in Ref [38]. Their cardinalities were 1 for the first, 2 for the second, and 3 for the third network. It can be observed that, in all of the cases, the cardinality of MPS–AC is greater than that of the MPS-AS for the (primary) target attractor. This is reasonable, since trying to steer the network to all of its attractors normally needs greater intervention than trying to steer it to one of its attractors. This is also in conformity with Proposition 2.
For the logical rules of the BNs of the cases A, B, and C, studied in this section, please refer to Refs [44–46], respectively.
In this paper, we focused on governing the steady-state behavior of BNs as models of biomolecular regulatory networks. To this end, the concept of attractor controllability of BNs was introduced as the possibility of making a BN converge from any of its attractors to any other one by flipping some of the network variables just one time after the network's transient period. Using a characteristic matrix, called attractor controllability matrix, necessary and sufficient conditions for the verification of attractor controllability were presented. Then, a forward search algorithm was proposed to identify the minimal perturbation set for attractor controllability (MPS-AC) of a given BN. We showed that the cardinality of the MPS-AC of a BN is an upper bound for the cardinalities of the minimal perturbation sets for attractor stabilizability (MPS-AS) for its various target attractors. Besides, a lower bound was derived for the cardinality of the MPS-AC. This lower bound was used to decrease the computational cost of the forward search algorithm. We also introduced two indices: (i) the percentage of attractor controllability, for quantifying the extent of attractor controllability achieved by a specific perturbation set and (ii) the convergence influence, for evaluating how influential each network node is in the attractor controllability of the network. It was shown that nodes with higher convergence influences are more likely to be members of the MPS-AC. The developed methods were successfully applied to several BN models of real biomolecular networks, revealing which genes (or proteins) need to be upregulated/downregulated to steer the networks from any of their attractors to any other one.
One limitation for the application of our approach is that it cannot be applied to large-scale BNs because the sizes of the involved matrices grow exponentially with the size of the network. However, this drawback is common to all approaches based on the algebraic state-space representation of BNs using semi-tensor product of matrices.
Although the forward search algorithm proposed for identifying the MPS-ACs of BNs has a high computational cost (for large BNs) in its worst case, we showed that the computational time is much less in the average case. Moreover, we proposed several solutions to mitigate the computational cost of this algorithm.
The use of BNs is quite prevalent for modeling biomolecular regulatory networks and the approach proposed in this paper can be used to identify the nodes of the BN models of real systems, by flipping which we can drive the network from any undesired steady state to any desired one. On the other hand, flipping the value of some nodes just once in a biomolecular regulatory network is easier to implement compared with most other intervention methods. Thus, our approach is quite appropriate to be used by biologists and geneticists in applications such as drug target discovery, cell reprogramming or cell fate determination, in all of which they seek to govern the steady-state behavior of the network by exerting minimum interventions on the system.
APPENDIX: THE METHOD USED FOR GENERATING RANDOM BOOLEAN NETWORKS
We generated a number of random Boolean networks by varying the network parameters as follows:
We used 3 different network sizes, 2 different average in-degrees, 2 different proportions of inhibitory links, 2 different types of update functions (logical rules for state transitions), and 20 randomizations (of link positions) which resulted in a total number of 480 BNs. The following two update rules were used as logical functions for state transitions:
Update rule No. 1: In this rule, all activatory inputs to a node are combined using “OR” and the complement of all inhibitory inputs are combined using “AND.” [47] Thus, the value of a node will be ON at the next time step if at least one of its activatory inputs is ON and all of its inhibitory inputs are OFF at the present time step.
Update rule No. 2: In this rule, all activatory inputs to a node and the complement of all inhibitory inputs are combined using “AND.” [34] Thus, the value of a node will be ON at the next time step if all of its activatory inputs are ON and all of its inhibitory inputs are OFF at the present time step.
TABLE I. 
The percentage of attractor controllability for various perturbation sets for the BN of Example 5.
TABLE II. 
The convergence influences of the network variables for the BN of Example 6.
TABLE I. -body
Perturbation set (V)	PAC (π_{V})
∅	0%
{x_{1}}	0%
{x_{2}}	50%
{x_{3}}	33.3%
{x_{1}, x_{3}}	33.3%
{x_{1}, x_{2}}	50%
{x_{2}, x_{3}}	100%
{x_{1}, x_{2}, x_{3}}	100%
TABLE II. -body
Network variable (x_{i})	Convergence influence (C_{i})
x_{1}	0
x_{2}	1
x_{3}	0.667
FIG. 1. 
Interaction graph for the BN of Example 1.
FIG. 2. 
State transition graph for the BN of Examples 1, 4.
FIG. 3. 
The APSTG for the BN of Example 4 with respect to the perturbation set V = {x_{2}, x_{3}}. (Dashed links represent perturbed state transitions resulting from flipping the network variables displayed next to them in braces.)
FIG. 4. 
Percentages of membership of (the instances of) the first seven variables with highest convergence influences in the MPS-ACs of their respective BNs, computed over 480 randomly generated BNs.
