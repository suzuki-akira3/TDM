Improved spatial resolution of luminescence images acquired with a silicon line scanning camera
Luminescence imaging is currently being used to provide spatially resolved defect in high volume silicon solar cell production. One option to obtain the high throughput required for on the fly detection is the use a silicon line scan cameras. However, when using a silicon based camera, the spatial resolution is reduced as a result of the weakly absorbed light scattering within the camera's chip. This paper address this issue by applying deconvolution from a measured point spread function. This paper extends the methods for determining the point spread function of a silicon area camera to a line scan camera with charge transfer. The improvement in resolution is quantified in the Fourier domain and in spatial domain on an image of a multicrystalline silicon brick. It is found that light spreading beyond the active sensor area is significant in line scan sensors, but can be corrected for through normalization of the point spread function. The application of this method improves the raw data, allowing effective detection of the spatial resolution of defects in manufacturing.
I. INTRODUCTION
Photoluminescence (PL) and Electroluminescence (EL) imaging of silicon (Si) has become an integral part of material and device characterization at various stages of the silicon solar cell production. Since its inception [1,2], it has been highlighted that when a Si charge coupled device (CCD) is used to measure the band-to-band luminescence signal of silicon, the resulting image is blurred by photon spread within the charge coupled device (CCD) [3]. This spread occurs when photons incident on a particular pixel travel inside the CCD and are absorbed in a different pixel. Image blurring due to this “light spreading” is a fundamental problem caused by the materials low absorptance of its own luminescence.
This issue does not occur if a Si CCD is used to image the luminescence of other semiconductor materials of higher than silicon's bandgap such as for the luminescence from perovskites [4] and other solar cell absorber materials (e.g., CIGS, CdTe) [5,6].
To illustrate light spreading, we consider the case where light is incident only on one pixel [see Fig. 1(a)]. Light that is not totally absorbed within the first pixel, transfers into adjacent pixels before finally being absorbed. This situation is shown in Fig. 1(b) and reflects the convolution of the incident signal with an imaging system's point spread function (PSF). Note that for this illustration the PSF is taken as an exponential decay.
The effects of light spreading can be reduced by deconvolving the measured data with the PSF of the detection system. Several methods exist to determine the PSF of a PL imaging system: The first method determined the PSF via direct measurement [7]. This was achieved by placing a pinhole aperture over a luminescence source, such as solar cell with EL excitation. However, the signal to noise ratio of the directly measured PSF is limited to a radial distance of typically less than 10 pixels, as shown in Fig. 2. Repeat measurements of larger aperture sizes can be performed to increase the dynamic range of the measurement, but the fitting of the data across various apertures is prone to inaccuracy due to the difficulty in finding the correct normalization. A more recent method [8] demonstrated that the PSF can be determined to over 6 orders of magnitude from a single luminescence image, as shown in Fig. 2. The PSF was not directly measured, but rather calculated from the measurement of an edge spread function (ESF). An ESF is the decay from the edge of a uniformly emitting object, such as the edge of a solar cell. Measurement of an ESF provides a higher signal to ratio than a direct measurement.
PSF deconvolution has been shown to significantly reduce the image blur caused by light spreading in square area sensors [8–11]. However, it is impractical to use these cameras to inspect silicon blocks, and modules on a moving conveyor belt. It has recently been demonstrated that silicon line scan cameras are suitable for this purpose [12,13]. This manuscript establishes a method for deriving and applying the PSF to a line scan camera. Such cameras comprise multiple silicon line sensors that together make a narrow rectangular sensor, where the charge is transferred from line to line in sync with the moving sample. This effectively increases the exposure time and thus the signal-to-noise of the final image.
This manuscript describes the theoretical derivation of the PSF of the line scan luminescence imaging system demonstrated elsewhere [12]. The system uses a silicon line scan camera with charge transfer. This manuscript expands the relationship between a PSF and ESF for square area sensors to encompass line scan sensors. We propose a normalization of a PSF for a line scan camera to account for light spreading-off the narrower line scan sensor, and compare it to the normalization of an area scan system. This procedure is used to determine the PSF for our experimental PL imaging line scanning system. The effectiveness for image improvement is then demonstrated and compared to a square area sensor used in BT Imaging LIS-R1. Comparison between the sensors is made through analysis of the modulation transfer function (MTF) from as-measured images and deconvolved images. The MTF quantifies an imaging systems ability to resolve image details of varying spatial frequency and signal amplitude.
II. BACKGROUND THEORY
The procedure for determining the PSF from a measurement of the ESF via a line-spread function (LSF) has recently been demonstrated for a common Si area sensor [8,11]. A LSF is defined as the response of an imaging system to an infinitely long and infinitely thin line signal, and also the derivative of the ESF, as shown in Eq. (5). Two methods have been used to determine the PSF from the LSF. Teal and Juhl [8] proposed the use of backwards substitution to determine the PSF from the LSF, while Breitenstein et_al [11] introduced an iterative approach. Both methods rely on a known relationship between the ESF and the PSF, which is described in this section. After describing the relationship between the PSF and ESF for a square area CCD sensor, this relationship is extended to be compatible with a rectangular line sensor. Note that the presented mathematics uses quantized rather than continuous notation to reflect the measurement of discrete pixels/points.
Starting with the impact of a PSF on an image, the image's intensity I_{CCD}x,y at the xth and yth pixel is related to a radially symmetric PSF and the incident photon flux (N_{γ}) via
where X and Y are the total number of pixels in the CCD in the x and y directions, respectively, and r is the radial distance between the pixel the light is incident on (p, q) and the pixel in which the light is absorbed (x, y)
For measurement of an ESF, it is required to image an object of uniform intensity. Here, we describe the incident photon flux as imaging a sample that fills half the sensor in the x direction and the total sensor in the y direction, representing a 50% coverage of the sensor in the imaging plane
where C is the intensity of the uniform luminescence. Substitution of Eq. (3) into Eq. (1) provides the definition of an ESF
The LSF of a line extending in the x-dimension is equal to the derivative of the ESF perpendicular to the intensity step [8], i.e., along the y-axis
The line spread function is then related to the PSF via substitution of Eq. (4) into Eq. (5)
where r_{2} is given by 
The relationship between the ESF, LSF, and PSF has been derived for a square area sensor. This theory is extended and applied to a rectangular line scan camera in the following.
III. EXTENSION OF THEORY TO LINE SCANNING PRINCIPLE
Unlike a stationary image camera, the line scan camera has a high aspect ratio sensor, charge transfer, and there is constant motion between the sensor and the object being imaged. These three differences change the relationship between the PSF and the ESF. By considering the physical system at each time step, the relationship between N_{γ}x,y,t, the PSF, and I_{CCD}x,y can be found. For each individual time step, a camera with charge transfer acts like a stationary I_{CCD}; thus, Eq. (1) holds. However, due to relative motion between the camera and the object, the limits of the summation along the x-axis must change between each time step. Incorporating the impact of charge transfer along the x-axis into Eq. (1) results in
The charge transfer within the camera occurs at the same rate as the motion of the camera. This means that the total number of time steps (T) is equal to the total number of pixels along the x-axis (X) minus 1
Equation (9) can be simplified further by considering the contribution of certain rows of pixels at each time step. If we expand the summation over time in Eq. (9), we find that the contribution of N_{γ}p=1,q,tPSF(r) to I_{CCD}x,y occurs only once as N_{γ} leaves the field of view of the camera after one time step. Similarly, the contribution of N_{γ}p=2,q,tPSF(r) to I_{CCD}x,y occurs for two time steps. This pattern continues until we reach p=X, which corresponds to the last pixel in the initial image taken at t = 0. After this point, the summation begins to decrease linearly until p=2X−1. Point spread from row 2X-1 impacts I_{CCD}x,y for one charge transfer step. Using this pattern and Eq. (10), we can rewrite Eq. (9) independent of time
The resulting PSF can be thought of as a radially symmetric function that has a linear scaling factor applied along its x-axis (short axis) or a non-radially symmetric function. Comparison of Eq. (11) with Eq. (1) allows the definition of an effective point spread function in the form
where X is the number of pixels along the short axis of the image sensor and m is the distance from the maximum PSF value along the x-axis, i.e., m=x−(X+1)/2.
A. Describing the ESF in terms of the PSF
The relationship between the acquired image and PSF has been derived for a line camera. The same procedure that is used for an area camera is now used to determine the relationship between the PSF and ESF. Substitution of the incident photon flux from Eq. (3) into Eq. (11) provides
The LSF of a line scan camera is then found using Eq. (5)
The PSF along the y-axis is determined using the numerical procedure outlined by Breitenstein et_al [11], while the PSF along the x-axis is calculated using the following steps:
1. Generate a 1D PSF estimate [Eq. (1), Breitenstein et_al [11]].
2. Create a 2D PSF estimate.
3. Calculate LSF from 2D PSF estimate, using Eq. (14) of this paper.
4. Calculate an error term [Eq. (3), Breitenstein et_al [11]].
5. If any value of the error term is larger than some predefined tolerance, then re-estimate PSF 1D using the Eq. (4), Breitenstein et_al [11], and repeat steps 2 and 4.
6. If the error term is smaller than some predefined tolerance then, the derived PSF is accurate.
B. PSF normalization
The PSF of an imaging system is usually normalized such that the average number of counts does not change after the deconvolution process, i.e., the integral of the PSF is unity. This normalization procedure assumes that the light incident on the square area CCD is absorbed within the CCD, and will not exit through the edge of the CCD. The magnitude of this normalization does not impact the results of a standard PL image; however, it is crucial to the results of methods based on comparison of two luminescence images taken with two different spectral filters [3,14], each filtered image has a different PSF, and hence different normalization/scaling factor.
To account for such effects a relative fraction of light detected by the sensor (f_{m}) can be determined from the PSF by
The fraction of light detected was calculated for a center row of pixels (x = 512) for a standard CCD (1024 × 1024) and along the y-axis for the line scan camera (128 × 2048) and is shown in Fig. 3.
An important distinction here is that light “captured” by the camera denotes any light that does not spread beyond the edge of the camera's sensor. PSF deconvolution can only correct for the effects of point spread if that light is measured at some location on the sensor.
Figure 3 show simulated light loss from a uniformly illuminated square CCD (dashed line), and a high aspect ratio line sensor (solid blue line), assuming the same PSF characteristics. The simulation shows that the center of the square area CCD captures 100% of the incident light, while the line scan camera only captures <80% of the incident light. The luminescence intensity of the line scan camera will be lower as a result of light escaping along the short axis of the line scan camera. Thus, all other things being equal, the recorded intensity will be higher for measurements from a square CCD compared to a line scan CCD.
Filtering of the line sensor changes the fraction of light that is detected by the sensor. Calculation and inclusion of such a normalization factor to the PSF deconvolution process is crucial if measurements of a different part of the luminescence spectrum are used for quantitative analyses [3,12,14].
IV. EXPERIMENTAL DEMONSTRATION
To demonstrate the application of PSF correction to an image captured with a line scan camera, we derive the PSF for a line scan PL imaging system [12] and perform point spread correction on a series of PL images. The ESF of the line scanning imaging system was determined by measurement of a bare 800 μm thick polished monocrystalline silicon wafer, which emits a homogenous PL intensity across the field-of-view. The measured long axis ESF is shown in Fig. 4(a). It provides the input data to extract and calculate both long and short axis PSF using the above outline procedures. The normalized PSF was determined using the procedure given in Sec. III A and is shown in Fig. 4(b) for both long and short-axis. The signal-to-noise of the single ESF image is sufficient to derive the PSF over more than six orders of magnitude extending over most of the long axis up to 700 pixels. Further, we extended the PSF from 700 to 1024 pixel radius via exponential fitting [7,9]. The short axis of the point spread function is calculated using Eq. (12). Its resultant PSF for the short axis is much steeper than the PSF for the long axis, as the narrow geometry of the camera's sensor limits the spread of light inside the CCD.
A common way to ascertain the accuracy of the derived PSF is to re-create the ESF from which it was derived. This was done by convolving a step function with the PSF, including its extension, and comparing it to measured data. The result of this process is shown in Fig. 5. There is an excellent match between the measured ESF's and reconstructed ESF for both axes. While the excellent match for the long axis is not surprising as it follows the standard process, the excellent match for the short axis is a new result and validates the presented method of deriving the short axis of the PSF on a charge transfer line-scanning camera.
We further investigate the effectiveness of the point spread deconvolution by applying the derived PSF on each the measured ESF's using MATLAB's conv2 function. This procedure would ideally result in the incident photon flux on the sensor, i.e., a step function edge. Using the Wiener deconvolution algorithm implemented in MATLAB, we find the PSF deconvolution process to improve the edge contrast significantly for both long and short axis (see Fig. 6). A step in signal intensity of 3 orders of magnitude in signal intensity is achieved within 3 pixels for both axes. The noise floor is found more than 3 orders of magnitude below the signal level at the top of the edge in both cases.
V. EVALUATING IMAGING PERFORMANCE
The impact of deconvolution with a PSF on an image can be observed visually through comparison of the image before and after the Wiener deconvolution process. The impact of deconvolution with the derived PSF is seen in the comparison between the original and deconvolved PL images of a multicrystalline silicon block shown in Figs. 7(a) and 7(b). An intensity profile, indicated by the dashed white arrow, is shown in Fig. 7(c). The deconvolution is found to redistribute the signal and to increase the image contrast noticeably.
Quantification of the impact of the PSF deconvolution can be obtained through analysis of the images modulation transfer function (MTF). The MTF describes a systems ability to accurately record the spatial contrast of an object. The MTF is defined as the modulus of the Fourier transform of the point spread function
Hence, the MTF describes the system's performance in the spatial frequency domain (e.g., line pairs per pixel), while the PSF gives a measure of performance in the spatial domain. Note that the MTF after deconvolution is estimated in this study by deconvolving the PSF with itself using the Richardson-Lucy method (as implemented in MATLAB) with 4 iterations.
The MTFs for both axes of the line scan sensor and a square area sensor are shown in Fig. 8(a). A line pair per pixel represents a step function (0 to 1 modulation) of incident light over a number of pixels. For example, a line pair per pixel value (resolution) of 0.10 means that the step function has a high intensity for a distance of 5 pixels followed by a low intensity for a distance of another 5 pixels, thus totaling 10 pixels per line pair. The corresponding MTF value is the amplitude that the system records, i.e., a MTF of 1 means the system can fully resolve that spatial frequency (line pair per pixel) without intensity blur across the modulation. We find the line scan camera to have a higher MTF than the square area sensor on the raw as-measured images prior to deconvolution in agreement with our expectation. However, after point spread correction, we estimate both line- and area imaging sensor's MTFs to be noticeably improved and converged, especially at high spatial frequencies.
An alternate approach to deconvolution is to reduce the impact of image blurring by placing an optical shortpass filter in front of the camera [3]. We quantify the impact of this approach via the systems MTF by placing a 1000 nm shortpass filter in front the camera [see Fig. 8(b)]. The MTF of such filtered imaging system reveals a more accurate reproduction of high spatial frequencies. The combination of shortpass filtering and deconvolution results in the best system MTF, in agreement with previously reported results for standard cameras [8]. However, if only one method is to be implemented, then deconvolution is the superior method. Note that the uncertainty in the estimated PSF corrected MTF increases towards high spatial frequencies. This prevents the comparison of standard and short pass filtered images at spatial frequencies above 0.1 line pairs per pixel. The root cause for the latter may be the limited accuracy in the derivation of the shortpass filtered PSF, which is relatively small and localized in comparison to the non-filtered PSF.
To measure the improvement in resolution (line-pairs per pixel value) of the imaging system by point spread deconvolution, we consider that the maximum resolution obtainable with any imaging system is by a system's MTF of one all the way up to the highest spatial frequency of 0.5 line pairs per pixel. With a high MTF of the corrected image extending as far as 0.05 line pairs per pixel (20 pixels per line pair), the system is only one order of magnitude away from the absolute resolution limit of the imaging system in measuring the location where luminescence's exits the sample (see Fig. 8).
VI. CONCLUSION
This paper has presented a mathematical method to determine the PSF for a line scan camera. In addition, the requirement of PSF normalization has been highlighted and a method for correcting this issue has been proposed. The normalization accounts for the light loss from the narrow edge of the CCD due to spreading beyond the physical dimensions of the sensor and helps to improve the accuracy of quantitative spectral PL analyses.
Analysis was performed on an experimental line scan PL imaging system with the effectiveness and accuracy of PSF correction determined. Significant improvement in spatial resolution was demonstrated quantitatively in the spatial and Fourier (spatial frequency) domain. PSF deconvolution has been found to provide a more accurate representation of the original image especially in areas of strong signal variations on PL images detected by Si line cameras. A combination of PSF deconvolution and shortpass filtering has been found to provide the best possible MTF, with PSF deconvolution providing the largest improvement in image contrast. A line scan PL imaging system was found to be able to resolve signals of high spatial frequency down to 0.05 line pairs per pixel, and showing an improved MTF compared to an area sensor PL system.
FIG. 1. 
Signal recorded when light is incident on a single pixel of a CCD, where (a) the light is completely absorbed within the pixel it is incident on and (b) the light is only partially absorbed within the pixel it is incident on. Note that illustration represents the situation on a rectangular CCD with charge transfer, which is the type of sensor discussed in paper.
FIG. 2. 
The PSF determined from a single measurement of a point source (red dots) and calculated from a measured ESF (blue squares).
FIG. 3. 
Relative fraction of light detected by the sensor as a function of position along the y-axis for an area sensor and line camera. Note that the y-axis of the line sensor has twice as many pixels than the area sensor though both sensors' pixels are the same physical size.
FIG. 4. 
(a) Measured long axis ESF using monocrystalline silicon wafer. (b) Derived corresponding PSF for both axes. The long axis was extended via exponential fitting.
FIG. 5. 
Measured long and short axis ESFs are compared to the reconstructed ESF. The reconstruction was performed by convolution of a step function with the derived and extended PSF.
FIG. 6. 
Comparison of a measured and a point spread corrected ESF's for (a) long and (b) short axis of the sensor. Wiener deconvolution was used (MATLAB implementation, NSR = 0.01). Note, the PL counts in the deconvolved remained positive.
FIG. 7. 
PL image of a section of a mc-Si block: (a) as-measured and (b) after Wiener point spread deconvolution. Both images are shown on the same color scale. (c) Line scan across (a) and (b) as indicated on (a). (a) As-measured. (b) Point spread corrected. (c) Cross-sections.
FIG. 8. 
(a) Comparison of MTF for line scan and area cameras for both as-measured images and after PSF deconvolution. (b) MTF of the line scan camera with and without short pass filtering applied.
