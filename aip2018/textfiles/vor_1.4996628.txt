A robust cloud registration method based on redundant data reduction using backpropagation neural network and shift window
A robust coarse-to-fine registration method based on the backpropagation (BP) neural network and shift window technology is proposed in this study. Specifically, there are three steps: coarse alignment between the model data and measured data, data simplification based on the BP neural network and point reservation in the contour region of point clouds, and fine registration with the reweighted iterative closest point algorithm. In the process of rough alignment, the initial rotation matrix and the translation vector between the two datasets are obtained. After performing subsequent simplification operations, the number of points can be reduced greatly. Therefore, the time and space complexity of the accurate registration can be significantly reduced. The experimental results show that the proposed method improves the computational efficiency without loss of accuracy.
I. INTRODUCTION
In the last decade, there has been a rapid development in three-dimensional sensing techniques, which make it feasible to efficiently obtain detailed geometric information of complex surfaces. Owing to its increased computing capacity and high sampling rate, three-dimensional object digitization has been widely used in many areas such as reverse engineering [1], object recognition [2], and reconstruction [3]. However, because of unavoidable limitations existing in data acquisition such as limited field of view, data points are often captured from different viewpoints. As a consequence, data registration techniques have attracted increasing attention in recent years.
According to the initial position of datasets, matching methods are generally categorized into two classes: rough registration [4,5] and fine registration [6,7]. Rough registration is aimed at obtaining a coarse estimation between two point sets without any initial alignment. Diez et_al [8] summarized the state of the art of existing coarse registration methods and compared the difference between relevant algorithms. Diez et_al [9] accelerated the coarse matching process based on hierarchical normal space sampling by adapting to different shape descriptors and searching classes. The most common methods to construct a fine registration are based on the iterative closest point (ICP) algorithm [10–12], where a precise rotation matrix and a translation vector between model points and measured points are calculated. In each iteration of the method, the closest point pairs from model points relative to data points will be determined. Aiger et_al [7] introduced four-point congruent sets to align raw noisy data without filtering and denoising. Zhang et_al [13] used an ICP registration algorithm based on the least squares technique to solve the local minimum, in which an inequality constraint of the rotation angle was introduced. Bergström and Edlund [14] accomplished point cloud matching by using a robust M-estimation method and ICP method to reduce the influence of outliers and incorporate the robustness.
Because there are millions of points in each point cloud, the complexity of registration methods is very high. In this study, a coarse-to-fine registration method is proposed to register point clouds with less time and space costs. Initially, the principal component analysis (PCA) method is used to produce an original fit between two datasets, where the rotation matrix and the translation matrix are evaluated by analyzing the distribution and orientation information contained in the principal axes. Then, the number of points in these datasets is reduced through a simplification operation, and contour points are retrieved using a two-dimensional shift window. Finally, an accurate rotation matrix and a translation vector are generated by an iteratively reweighted least squares method according to the output of the second step. The schematic of the coarse-to-fine registration process is illustrated in Fig. 1.
II. METHOD DESCRIPTION
A. Rough alignment based on PCA
Usually, PCA-based methods can be used to analyze the distribution pattern and orientation of three-dimensional objects composed of discrete points, where the information is basically reflected in the principal axes [15,16]. In the proposed method, the PCA method is employed to implement the rough alignment. Initially, two groups of principal axes are respectively evaluated by the covariance matrices of two datasets. Then, the transform relationship expressed as the rotation matrix and translation vector is derived from these principal axes.
Given two 3D point clouds P and Q, where the symbol P represents the model set and Q denotes the dataset, the detailed rough alignment procedure between point sets P and Q is described as follows:
(1) Calculate the means of P and Q using P¯=1N∑i=1NP_{i} and Q¯=1M∑i=1MQ_{i}, where N and M, respectively, denote the number of points in P and Q, and P_{i} and Q_{i}, respectively, represent the ith points in P and Q.
(2) Calculate the covariance matrices of P and Q, denoted as Cov_{P} and Cov_{Q}, respectively, which are expressed as
(3) Evaluate the principal axes of each data. For data P, the eigenvalues λ_{P,1}, λ_{P,2}, and λ_{P,3} and the corresponding eigenvectors E_{P,1}, E_{P,2}, and E_{P,3} are computed from the covariance matrix Cov_{P} by using singular value decomposition. Then, the eigenvectors are sorted in descending order of these eigenvalues, and the eigenvector matrix E_{P} is constituted. For example, if the eigenvalues satisfy λ_{3,P} > λ_{2,P} > λ_{1,P}, the eigenvector matrix is constituted as E_{P} = [E_{P,3}, E_{P,2}, E_{P,1}]. It should be pointed out that the eigenvectors E_{P,3}, E_{P,2}, and E_{P,1}, respectively, represent the three principal axes of X, Y, and Z. Similarly, another group of principal axes E_{Q} can be evaluated.
(4) Using the eigenvector matrices E_{P} and E_{Q}, the rotation matrix between P and Q can be derived as
(5) Using the means P¯ and Q¯, the translation vector, which is the distance between the centers of P and Q, is calculated as
(6) Using R_{PCA} and T_{PCA}, the measured data Q can be roughly registered with the model data P. The result can be expressed as
Although the measured data Q can be roughly aligned with the model data P by using the aforementioned process, a special case in which the directions of the model set and dataset are opposite should be solved. First, the sign of a determinant is computed. If the sign is negative, the eigenvector matrix E_{P} = [E_{P,3}, E_{P,2}, E_{P,1}] should be changed to E_{P} = [−E_{P,3}, E_{P,2}, E_{P,1}] or E_{P} = [E_{P,3}, −E_{P,2}, E_{P,1}]. Then, the rotation matrix R_{PCA} and the translation vector T_{PCA} should be updated by using Eqs. (3) and (4).
B. Data simplification based on the BP neural network
Owing to the number of redundant points existing in the point cloud data, the time and space costs and the registration algorithm complexity are increased significantly. In the proposed method, a backpropagation (BP) neural network [17,18] with two hidden layers is utilized to simplify the roughly aligned data P and Q’. For simplicity, only the simplification process of P is illustrated as shown in Fig. 2, where there are three parts including an input layer P^, two hidden layers H_{1} and H_{2}, and an output layer P̃. The input P^{i}x,yi=1,2,…,N is formulated with the X and Y coordinates of data P, while the desired output P̃{i}z is constituted with the corresponding Z coordinates. There are h_{1} and h_{2} neurons in the hidden layers H_{1} and H_{2}, respectively. The w_{ij} value is the weight coefficient between the ith input P^{i}x,y and the jth neuron of H_{1}, while w_{jk} is the weight coefficient between the jth neuron of H_{1} and the kth neuron of H_{2}. In addition, w_{kv} is the weight coefficient between the kth neuron of H_{2} and the vth output in the output layer.
The error function between the actual output P¯z and desired output P̃z is computed as
and the mean error can be represented as E¯=E/N. Another criterion function is
where Grad denotes the gradient of the Z coordinates.
In the BP network, the training process is performed by using the gradient descent algorithm to minimize the sum of the squared errors between the actual and desired output values. As a result, a large error value E means that the gradient of the error function is large. Thus, the points satisfying P¯{v}−P̃{v}≥E¯ have much steeper gradients compared to others. In order to simplify the model data, the points with small gradients are removed. In addition, the points whose gradient values of Z coordinates are larger than G are also reserved. In the same way, the roughly aligned measure data Q′ can be simplified.
C. Contour extraction using a two-dimensional shift window
From the discussion on the data simplification process, it is obvious that a large number of three-dimensional points in P and Q^{′} are removed. It should be noted that some points located in the region of contours may be oversimplified because they have low gradients. However, these points usually encompass important characteristics, which are helpful in improving the accuracy of registration between P and Q′. Therefore, it is better to identify these points and insert them into the simplified datasets. To ensure the efficiency of the proposed method, a two-dimensional shift window is designed to discriminate these points.
For simplicity, only the detection process for data P is discussed. Denoting the size of shift window as S_{w}, the detailed process can be described as follows:
(1) Sort the points of P in ascending order of X coordinates and begin the detection from the first S_{w} points.
(2) Find points with maximal and minimal value of Y and Z coordinates. Slide the shift window and detect the next S_{w} points in the same way.
(3) When all the points are processed, the detection ends.
(4) Sort the points of P in ascending order of Y coordinates and repeat the same operations as (2) and (3). Finally, there are 8 × N/S_{w} points with a local extreme value of coordinates to be received.
An obvious advantage is that the window size S_{w} is adjustable according to the point characteristics of the dataset. The determinant of S_{w} in this study is based on the number of points in the dataset. Finally, these points located in the region of contours are inserted into the simplified point set, and the simplified results after the two procedures are denoted as U and V. However, some three-dimensional points may be chosen from both the aforementioned processes. Thus, the duplicated points should be removed. Because the process reserves the outliers with extreme values in the point cloud, the fine registration should be robust to noise and outliers. The iteratively reweighted ICP algorithm based on the Cauchy function is carried out to refine the coarse matching.
D. Improved iterative closest point method
Generally, the point cloud is captured by a camera or laser sensor, where some outliers unavoidably exist in the obtained dataset. To enhance the robustness of point cloud registration against outlier points, an ICP method based on M-estimation is employed in the proposed method. The method can align two point clouds with outliers and noise in the iteration process until the optimal results are obtained. The inputs are denoted as U and V, which are obtained by coarse alignment and simplification. The initial rotation matrix and translation vector are set to the identity matrix and 0, respectively. Additionally, the numbers of points in the model data and measured data are reduced greatly after the simplified procedures, which is advantageous for implementing a rapid fine registration between the model data and measured data.
The objective of the improved ICP method is to obtain the optimal rotation matrix R and the translation vector T, which will perfectly transform the points in the measured data to the ones in the model data. The objective function can be expressed as
where D is the Euclidean distance function and is expressed as
where the operator ς is the robust criterion function. In the iterative processes, the result will converge to the optimal situation when the distance D does not decrease anymore. The process can be implemented by using Delaunay tessellation [19] or KD-tree [20].
Owing to its strong ability against the influence of outliers, the Cauchy function [14] is considered as the criterion function in this method, which can be mathematically expressed as
where r is the residual indicator and C = 2.385 is an invariant. The derivative of ς can be expressed as
and the weight function w used in the process of registration can be defined as
Then the new rotation matrix R′ and translation vector T′ can be updated as follows:
where V_{c} and U_{c} are the corresponding point pairs. The detail of the improved ICP algorithm is presented in Table I. The convergent condition can be set as the maximum number of iterations or the minimum distance error. The improved method is suitable for estimating irregularly scattered points and can resist noise and outliers efficiently.
III. EXPERIMENTAL RESULTS
In order to demonstrate the efficiency and robustness of the proposed method, a series of experiments were performed, and the results were compared with a coarse-to-fine registration constituted using PCA and conventional ICP based on the least squares technique. The experimental results are presented in Subsections III A–III C: rough alignment, data simplification, and accurate registration. Two processed models and two real point clouds were used to verify the method. The processed models are derived from the bunny and dragon models of Stanford Repository [22]. The Gaussian white noise was manually added to modify the Stanford models. The first real dataset is the bust model with two views denoted as bust 1 and bust 2 [21]. The second model is a blade obtained by a structural light system. In bunny 1 and bunny 2, the signal–noise ratios (SNRs) were set as 65 dB and 70 dB, respectively. Meanwhile, the SNRs were set as 60 dB and 55 dB in the dragon model. The registration error is used to analyze the accuracy and robustness, and the mean squared error (MSE) serves as the evaluation criterion.
A. Rough registration results
After coarse matching between the model data and measured data, the rough rotation matrix R_{PCA} and the translation vector T_{PCA} are calculated using Eqs. (3) and (4). The model data P and measured data Q are intuitively presented in Figs. 3(a) and 3(b). Figure 3(c) illustrates P and Q in the same coordinate system, and Fig. 3(d) shows the rough alignment results in which the point sets are matched coarsely.
B. Data simplification results
Next, the BP neural network was used to reduce the number of points of experimental datasets, where the first hidden layer included 11 neurons and the second hidden layer incorporated 6 neurons. The maximum number of iterations was set to 1000, and the learning rate was set to 0.05. The X and Y coordinates of points are adopted as inputs, and the Z coordinates are considered as the desired outputs. When the training number reaches the default value or when the minimum performance gradient is less than G, the training stops. The performances of the simplification process in the bunny and bust models are shown in Fig. 4. The iteration ends at the fifth training in bunny 1 and at the ninth training in bunny 2. Meanwhile, the number of iterations in the simplification of the bust models is 6 and 11, respectively.
Comparing the difference between the actual output and Z coordinate, the points whose difference is less than the mean error or whose gradient of Z coordinate is less than its average value are removed. The simplification results are shown in Fig. 5. Then the contour extraction method was executed to reserve the points located in the region of contours, and the results are shown in Fig. 6.
Figure 7 displays the final simplified results of the model datasets and measured datasets, which consist of the points reserved from the data simplification and contour extraction. Obviously, these points comprise the main feature of these data. The number of points in each simplified process is listed in Table II. From the results shown in Figs. 4–7 and Table II, the simplification method based on the BP neural network can simplify the datasets efficiently with few iterations, and the contour extraction can regain the crust of data effectively.
C. Accurate registration results
The accurate alignment results are shown in Fig. 8. The maximum iteration was set to 50, and the convergence threshold of MSE was set to 1 × 10^{−7} mm.
To verify the effectiveness of the proposed method, a comparison experiment was performed with the method constructed with the PCA and ICP based on the least squares method. The experimental results shown in Fig. 9 demonstrate that the proposed method obtains a faster convergence than the conventional coarse-to-fine registration. Even though the point cloud is simplified, the accuracy of MSE is higher. The running time is another important criterion for evaluating the different methods. The time values of the proposed method and conventional method are presented in Table III. All the programs were performed in a computer with Intel Core i5-3320M at 2.6 Hz, 4G RAM, and 64 bit. The results in Table III indicate that the proposed method is more advantageous in registering point clouds with a large number of points.
IV. CONCLUSION
In this study, a novel coarse-to-fine registration method is proposed. The initial point clouds captured from multiple views are aligned roughly by the PCA method. The rough alignment results serve as inputs to the subsequent processes, namely, data simplification based on the BP neural network and data point reservation in the region of contours. This reduces the number of points while preserving the main features. Finally, an improved ICP method based on M-estimation accurately transforms the simplified model to the simplified measured data. Various experiments demonstrated the robustness and efficiency of the proposed method.
TABLE I. 
Improved ICP algorithm based on reweighted least squares.
TABLE II. 
Number of points in each simplified process of the proposed method.
TABLE III. 
Running time of the proposed method and conventional method (unit: s).
TABLE I. -body
The reweighted ICP algorithm
1.	Initialize the rotation matrix R^{0} and translation vector T^{0} with identity
	matrix and 0.
2.	Set U^{0} = R^{0}V^{0} + T^{0} and iterative index k = 0.
3.	Repeat
4.	k = k + 1
5.	Uik−1=ϒVik−1,U, Υ denotes the closest point operator.
6.	Calculate the weight function w_{i}=wVik−1−Uik−1{2}
7.	ifw_{i} > 0
	R^{*},T^{*}=argminR,T∑i=1Mw_{i}R^{k−1}Vik−1+T^{k−1}−Uik−122
	Transform the data point set as Vik=R^{*}Vik−1+T^{*}
	Compute R^{k} = R^{*} · R^{k−1}, T^{k} = R^{*}T^{k−1} + T^{*}
	else
	Vik=Vik−1
	R^{k} = R^{k−1}
	T^{k} = T^{k−1}
	end if
8.	Calculate the mean squared error D^{k}=1M∑1MUik−1−Vik{2}
9.	Untilk is equal to the maximum number of iterations or D^{k} − D^{k−1}
	< threshold
10.	ReturnR^{k} and T^{k}
TABLE II. -body
	Bunny	Dragon	Bust	Blade
	Bunny 1	Bunny 2	Dragon 1	Dragon 2	Bust 1	Bust 2	Blade 1	Blade 2
Initial input	40 256	40 097	34 836	41 841	352 752	463 340	1 027 426	577 212
S_{w}	32	32	32	32	100	100	256	128
Simplification	23 651	22 797	23 544	24 365	252 430	341 948	757 911	427 408
Contour	7 164	7 474	6 680	7 984	22 640	27 262	24 029	25 548
Final output	30 404	28 935	29 746	31 435	270 996	355 556	778 953	451 147
TABLE III. -body
	Bunny	Dragon	Bust	Blade
Proposed method	55	34	776	2246
PCA + ICP	32	15	1263	3886
FIG. 1. 
Illustration of the proposed coarse-to-fine registration algorithm.
FIG. 2. 
Schematic of the BP neural network.
FIG. 3. 
Rough registration results: (a) model set P, (b) dataset Q, (c) P and Q, and (d) P and Q′.
FIG. 4. 
Performances of the BP neural network: (a) bunny 1, (b) bunny 2, (c) bust 1, and (d) bust 2.
FIG. 5. 
Simplification results: (a) bunny, (b) dragon, (c) bust, and (d) blade.
FIG. 6. 
Contour information: (a) bunny, (b) dragon, (c) bust, and (d) blade.
FIG. 7. 
Final simplified results: (a) bunny, (b) dragon, (c) bust, and (d) blade.
FIG. 8. 
The fine registration results of simplified datasets with different views: (a) bunny, (b) dragon, (c) bust, and (d) blade.
FIG. 9. 
Comparison results: (a) bunny, (b) dragon, (c) bust, and (d) blade.
